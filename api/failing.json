[{"council_id":"GLG","missing":false,"latest_run":{"status_code":1,"log_text":"[10:37:23] Fetching Scraper for: GLG                              handlers.py:23\n           Begin attempting to scrape: GLG                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:37:24] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 85 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 85 files in Councillors/raw                      base.py:225\n           ...found 171 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:37:25] Deleting batch no. 2 consisting of 71 files               base.py:236\n[10:37:26] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.glasgow.gov.uk/councillorsandcommittees/allMem           \n           bers.asp?sort=0&page=0&rec=100                                       \n           Server error '500 Internal Server Error' for url       handlers.py:36\n           'https://www.glasgow.gov.uk/councillorsandcommittees/a               \n           llMembers.asp?sort=0&page=0&rec=100'                                 \n           For more information check:                                          \n           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               \n           us/500                                                               \n           Finished attempting to scrape: GLG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 152, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(url, extra_headers=self.extra_headers).text\n  File \"/var/task/lgsf/scrapers/base.py\", line 56, in get\n    response.raise_for_status()\n  File \"/opt/python/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Server error '500 Internal Server Error' for url 'https://www.glasgow.gov.uk/councillorsandcommittees/allMembers.asp?sort=0&page=0&rec=100'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\n","start":"2024-04-29 10:37:23.492551","end":"2024-04-29 10:37:26.800947","duration":3}},{"council_id":"LIV","missing":false,"latest_run":{"status_code":1,"log_text":"[08:43:45] Fetching Scraper for: LIV                              handlers.py:23\n           Begin attempting to scrape: LIV                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[08:43:46] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 85 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 85 files in Councillors/raw                      base.py:225\n           ...found 171 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[08:43:47] Deleting batch no. 2 consisting of 71 files               base.py:236\n[08:43:48] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://councillors.liverpool.gov.uk/mgWebService.asmx/Get           \n           CouncillorsByWard                                                    \n[08:44:18] The read operation timed out                           handlers.py:36\n           Finished attempting to scrape: LIV                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 101, in handle_request\n    return self._connection.handle_request(request)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 143, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/http11.py\", line 113, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 186, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n  File \"/opt/python/httpcore/_backends/sync.py\", line 124, in read\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n","start":"2024-04-29 08:43:45.241682","end":"2024-04-29 08:44:18.842994","duration":33}},{"council_id":"SHE","missing":false,"latest_run":{"status_code":null,"log_text":"[11:28:20] Fetching Scraper for: SHE                              handlers.py:22\n           Begin attempting to scrape: SHE                        handlers.py:25\n           Deleting existing data...                                 base.py:234\n           Getting all files in SHE...                               base.py:186\n[11:28:21] Getting all files in SHE/json...                          base.py:186\n           ...found 30 files in SHE/json                             base.py:202\n           Getting all files in SHE/raw...                           base.py:186\n           ...found 30 files in SHE/raw                              base.py:202\n           ...found 61 files in SHE                                  base.py:202\n           Deleting batch no. 1 consisting of 61 files               base.py:211\n[11:28:32] An error occurred (ThrottlingException) when calling   handlers.py:34\n           the CreateCommit operation (reached max retries: 4):                 \n           Rate exceeded                                                        \n           Finished attempting to scrape: SHE                        base.py:319\n","errors":"An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded","start":"2022-04-04 11:28:20.509898","end":"2022-04-04 11:28:32.871624","duration":12}},{"council_id":"SND","missing":false,"latest_run":{"status_code":1,"log_text":"[10:20:15] Fetching Scraper for: SND                              handlers.py:23\n           Begin attempting to scrape: SND                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:20:16] Getting all files in Councillors/json...                  base.py:209\n           ...found 74 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 74 files in Councillors/raw                      base.py:225\n           ...found 149 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:20:17] Deleting batch no. 2 consisting of 49 files               base.py:236\n[10:20:18] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers.aspx                                                             \n[10:20:19] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1911/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:21] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1974/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:24] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1816/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:26] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1961/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:27] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1586/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:30] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1228/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:32] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1902/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:34] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1742/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:36] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1861/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:38] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1958/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:39] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1854/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:41] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1914/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:44] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1944/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:46] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1906/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:48] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1981/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:50] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1247/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:52] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1905/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:54] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1588/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:56] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1359/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:20:59] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1823/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:01] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1936/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:03] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1959/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:06] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1415/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:08] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1916/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:10] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1744/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:11] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1860/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:13] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1818/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:15] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1814/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:17] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1901/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:18] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1819/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:20] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1910/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:22] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1399/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:26] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1940/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:28] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1956/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:30] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1980/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:32] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1852/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:34] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1900/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:35] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1766/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:52] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1917/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:21:59] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1642/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:22:16] Scraping from                                              base.py:49\n           https://committees.sunderland.gov.uk/committees/cmis5/Memb           \n           ers/tabid/62/ctl/ViewCMIS_Person/mid/600/id/1390/ScreenMod           \n           e/Ward/Default.aspx                                                  \n[10:22:47] The read operation timed out                           handlers.py:36\n           Committing batch 1 consisting of 80 files                 base.py:297\n[10:22:48] Finished attempting to scrape: SND                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 101, in handle_request\n    return self._connection.handle_request(request)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 143, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/http11.py\", line 113, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 186, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n  File \"/opt/python/httpcore/_backends/sync.py\", line 124, in read\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 310, in get_single_councillor\n    req = self.get(url)\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n","start":"2024-04-29 10:20:15.010083","end":"2024-04-29 10:22:48.783526","duration":153}},{"council_id":"THE","missing":false,"latest_run":{"status_code":1,"log_text":"[10:57:01] Fetching Scraper for: THE                              handlers.py:23\n           Begin attempting to scrape: THE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:57:02] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:57:03] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.threerivers.gov.uk/listing/councillors                   \n[10:57:04] 'NoneType' object has no attribute 'findNext'          handlers.py:36\n           Finished attempting to scrape: THE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"scrapers/THE-three-rivers/councillors.py\", line 15, in get_list_container\n    return soup.find(\"h3\", text=\"District Councillor\").findNext(\"ul\")\nAttributeError: 'NoneType' object has no attribute 'findNext'\n","start":"2024-04-29 10:57:01.118160","end":"2024-04-29 10:57:04.986124","duration":3}},{"council_id":"TRF","missing":false,"latest_run":{"status_code":1,"log_text":"[09:03:10] Fetching Scraper for: TRF                              handlers.py:23\n           Begin attempting to scrape: TRF                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:03:11] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 63 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 63 files in Councillors/raw                      base.py:225\n           ...found 127 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[09:03:12] Deleting batch no. 2 consisting of 27 files               base.py:236\n[09:03:13] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://democratic.trafford.gov.uk/mgWebService.asmx/GetCo           \n           uncillorsByWard                                                      \n[09:03:43] The read operation timed out                           handlers.py:36\n           Finished attempting to scrape: TRF                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 101, in handle_request\n    return self._connection.handle_request(request)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 143, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/http11.py\", line 113, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 186, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n  File \"/opt/python/httpcore/_backends/sync.py\", line 124, in read\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n","start":"2024-04-29 09:03:10.336167","end":"2024-04-29 09:03:43.660685","duration":33}}]
