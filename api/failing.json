[{"council_id":"BOT","missing":false,"latest_run":{"status_code":1,"log_text":"[08:50:44] Fetching Scraper for: BOT                              handlers.py:23\n           Begin attempting to scrape: BOT                        handlers.py:27\n[08:50:45] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[08:50:46] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://moderngov.boston.gov.uk/mgWebService.asmx/GetCounci           \n           llorsByWard                                                          \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n           Finished attempting to scrape: BOT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-27 08:50:44.959309","end":"2024-04-27 08:50:47.010377","duration":2}},{"council_id":"CAT","missing":false,"latest_run":{"status_code":1,"log_text":"[08:49:37] Fetching Scraper for: CAT                              handlers.py:23\n           Begin attempting to scrape: CAT                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[08:49:38] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[08:49:39] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://democracy.canterbury.gov.uk/mgWebService.asmx/GetCo           \n           uncillorsByWard                                                      \n[08:50:09] timed out                                              handlers.py:36\n           Finished attempting to scrape: CAT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectTimeout: timed out\n","start":"2024-04-27 08:49:37.319425","end":"2024-04-27 08:50:09.575121","duration":32}},{"council_id":"DRS","missing":false,"latest_run":{"status_code":1,"log_text":"[09:54:06] Fetching Scraper for: DRS                              handlers.py:23\n           Begin attempting to scrape: DRS                        handlers.py:27\n[09:54:07] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:54:08] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           \n           ice.asmx/GetCouncillorsByWard                                        \n[09:54:38] timed out                                              handlers.py:36\n           Finished attempting to scrape: DRS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectTimeout: timed out\n","start":"2024-04-27 09:54:06.568561","end":"2024-04-27 09:54:38.991445","duration":32}},{"council_id":"EAY","missing":false,"latest_run":{"status_code":1,"log_text":"[08:49:17] Fetching Scraper for: EAY                              handlers.py:23\n           Begin attempting to scrape: EAY                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[08:49:18] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[08:49:19] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.east-ayrshire.gov.uk/CouncilAndGovernment/Abou           \n           t-the-Council/Councillors-and-Provost/YourCouncillor.aspx            \n[08:49:20] Scraping from                                              base.py:49\n           https://www.east-ayrshire.gov.uk/CouncilAndGovernment/Abou           \n           t-the-Council/Councillors-and-Provost/YourCouncillor.aspx?           \n           9                                                                    \n[08:49:21] 'NoneType' object has no attribute 'get_text'          handlers.py:36\n           Finished attempting to scrape: EAY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/EAY-east-ayrshire/councillors.py\", line 23, in get_single_councillor\n    .get_text(strip=True, separator=\"\\n\")\nAttributeError: 'NoneType' object has no attribute 'get_text'\n","start":"2024-04-27 08:49:17.381988","end":"2024-04-27 08:49:21.210340","duration":3}},{"council_id":"ELS","missing":false,"latest_run":{"status_code":1,"log_text":"[09:29:18] Fetching Scraper for: ELS                              handlers.py:23\n           Begin attempting to scrape: ELS                        handlers.py:27\n[09:29:19] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:29:20] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://cne-siar.gov.uk/home/your-council/council-members/           \n[09:29:25] Scraping from https://cne-siar.gov.uk/kenneth-j-maclean/   base.py:49\n[09:29:27] 'NoneType' object has no attribute 'get_text'          handlers.py:36\n[09:29:28] Finished attempting to scrape: ELS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/ELS-na-h-eileanan-an-iar/councillors.py\", line 25, in get_single_councillor\n    .get_text(strip=True)\nAttributeError: 'NoneType' object has no attribute 'get_text'\n","start":"2024-04-27 09:29:18.623410","end":"2024-04-27 09:29:28.022888","duration":9}},{"council_id":"ESS","missing":false,"latest_run":{"status_code":1,"log_text":"[08:37:17] Fetching Scraper for: ESS                              handlers.py:23\n           Begin attempting to scrape: ESS                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[08:37:18] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/EssexCmis5/Councillors.aspx                 \n[08:37:21] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/655/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:24] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/327/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:26] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/100/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:29] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/639/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:32] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/882/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:37] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/880/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:40] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/879/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:46] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/648/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:51] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/80/ScreenMode/Ward/Default.a           \n           spx                                                                  \n[08:37:54] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/649/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:56] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/866/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:37:59] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/458/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:03] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/864/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:08] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/887/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:12] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/334/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:14] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/650/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:18] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/364/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:21] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/863/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:24] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/309/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:27] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/91/ScreenMode/Ward/Default.a           \n           spx                                                                  \n[08:38:29] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/877/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:32] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/777/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:34] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/865/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:37] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/359/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:39] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/870/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:41] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/340/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:44] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/94/ScreenMode/Ward/Default.a           \n           spx                                                                  \n[08:38:52] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/883/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:54] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/656/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:38:58] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/872/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:39:01] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/117/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:39:04] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/889/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:39:06] Scraping from                                              base.py:49\n           http://cmis.essex.gov.uk/essexcmis5/Councillors/tabid/62/c           \n           tl/ViewCMIS_Person/mid/480/id/610/ScreenMode/Ward/Default.           \n           aspx                                                                 \n[08:39:09] 'title'                                                handlers.py:36\n           Committing batch 1 consisting of 66 files                 base.py:297\n[08:39:11] Finished attempting to scrape: ESS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 300, in get_single_councillor\n    party = self.get_party_name(list_page_html)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 281, in get_party_name\n    list_page_html.find_all(\"img\")[-1][\"title\"]\n  File \"/opt/python/bs4/element.py\", line 1930, in __getitem__\n    return self.attrs[key]\nKeyError: 'title'\n","start":"2024-04-27 08:37:17.297730","end":"2024-04-27 08:39:11.186055","duration":113}},{"council_id":"GRE","missing":false,"latest_run":{"status_code":1,"log_text":"[09:06:11] Fetching Scraper for: GRE                              handlers.py:23\n           Begin attempting to scrape: GRE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:06:12] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:06:13] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://committees.royalgreenwich.gov.uk/Councillors/tabid           \n           /63/ScreenMode/Alphabetical/Default.aspx                             \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n           Finished attempting to scrape: GRE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 272, in get_councillors\n    req = self.get(\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-27 09:06:11.448876","end":"2024-04-27 09:06:13.467626","duration":2}},{"council_id":"GRT","missing":false,"latest_run":{"status_code":1,"log_text":"[09:01:31] Fetching Scraper for: GRT                              handlers.py:23\n           Begin attempting to scrape: GRT                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:01:32] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:01:33] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www2.guildford.gov.uk/councilmeetings/mgWebService           \n           .asmx/GetCouncillorsByWard                                           \n           [Errno -2] Name or service not known                   handlers.py:36\n           Finished attempting to scrape: GRT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n","start":"2024-04-27 09:01:31.145056","end":"2024-04-27 09:01:33.293045","duration":2}},{"council_id":"HIG","missing":false,"latest_run":{"status_code":1,"log_text":"[09:01:49] Fetching Scraper for: HIG                              handlers.py:23\n           Begin attempting to scrape: HIG                        handlers.py:27\n[09:01:50] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 100 files in Councillors/json                    base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n[09:01:51] ...found 100 files in Councillors/raw                     base.py:225\n           ...found 201 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n           Deleting batch no. 2 consisting of 100 files              base.py:236\n[09:01:52] Deleting batch no. 3 consisting of 1 files                base.py:236\n[09:01:53] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://democracy.highpeak.gov.uk/mgWebService.asmx/GetCou           \n           ncillorsByWard                                                       \n[09:02:23] The read operation timed out                           handlers.py:36\n           Finished attempting to scrape: HIG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 101, in handle_request\n    return self._connection.handle_request(request)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 143, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/http11.py\", line 113, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 186, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n  File \"/opt/python/httpcore/_backends/sync.py\", line 124, in read\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n","start":"2024-04-27 09:01:49.750483","end":"2024-04-27 09:02:23.713123","duration":33}},{"council_id":"HLD","missing":false,"latest_run":{"status_code":1,"log_text":"[10:29:21] Fetching Scraper for: HLD                              handlers.py:23\n           Begin attempting to scrape: HLD                        handlers.py:27\n[10:29:22] Deleting existing data...                                 base.py:257\n[10:29:24] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:29:25] ...data deleted.                                          base.py:264\n           Scraping from https://www.highland.gov.uk/councillors/name base.py:49\n[10:29:26] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/102/sarah_atkin              \n[10:29:27] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/110/michael_baird            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/94/andrew_baldrey            \n[10:29:28] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/100/chris_ballance           \n[10:29:29] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/120/chris_birt               \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/41/bill_boyd                 \n[10:29:30] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/8/raymond_bremner            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/30/ian_brown                 \n[10:29:31] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/79/john_bruce                \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/117/michael_camero           \n           n                                                                    \n[10:29:32] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/17/isabelle_biz_ca           \n           mpbell                                                               \n[10:29:33] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/82/glynis_campbell           \n           _sinclair                                                            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/35/alasdair_christ           \n           ie                                                                   \n[10:29:34] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/40/muriel_cockburn           \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/124/tamala_collier           \n[10:29:35] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/101/helen_crawford           \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/83/sarah_fanet               \n[10:29:36] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/71/john_finlayson            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/29/david_fraser              \n[10:29:37] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/47/laurie_fraser             \n[10:29:38] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/10/richard_gale              \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/51/ken_gowans                \n[10:29:39] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/95/john_grafton              \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/52/alex_graham               \n[10:29:40] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/130/michael_green            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/128/david_gregg              \n[10:29:41] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/114/ron_gunn                 \n[10:29:42] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/123/jackie_hendry            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/111/marianne_hutch           \n           ison                                                                 \n[10:29:43] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/68/andrew_jarvie             \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/131/barbara_jarvie           \n[10:29:44] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/103/lyndsey_johnst           \n           on                                                                   \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/109/russell_jones            \n[10:29:45] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/99/sean_kennedy              \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/86/emma_knox                 \n[10:29:46] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/121/liz_kraft                \n[10:29:47] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/61/bill_lobban               \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/122/patrick_logue            \n[10:29:48] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/78/derek_louden              \n[10:29:49] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/105/morven-may_mac           \n           callum                                                               \n[10:29:50] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/112/angus_macdonal           \n           d                                                                    \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/12/willie_mackay             \n[10:29:51] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/64/graham_mackenzi           \n           e                                                                    \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/39/isabelle_macken           \n           zie                                                                  \n[10:29:52] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/11/struan_mackie             \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/125/andrew_mackint           \n           osh                                                                  \n[10:29:53] Committing batch 1 consisting of 92 files                 base.py:297\n[10:29:54] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/98/ryan_mackintosh           \n[10:29:55] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/66/angela_maclean            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/119/kate_maclean             \n[10:29:56] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/113/thomas_maclenn           \n           an                                                                   \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/37/duncan_macphers           \n           on                                                                   \n[10:29:57] Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/69/bet_mcallister            \n           Scraping from                                              base.py:49\n           https://www.highland.gov.uk/councillors/81/duncan_mcdonald           \n[10:29:58] 'NoneType' object has no attribute 'get_text'          handlers.py:36\n           Committing batch 2 consisting of 12 files                 base.py:297\n[10:29:59] Finished attempting to scrape: HLD                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/HLD-highland/councillors.py\", line 49, in get_single_councillor\n    councillor.email = soup.select_one(\"li a[href^=mailto]\").get_text(\nAttributeError: 'NoneType' object has no attribute 'get_text'\n","start":"2024-04-27 10:29:21.773342","end":"2024-04-27 10:29:59.503491","duration":37}},{"council_id":"LEC","missing":false,"latest_run":{"status_code":1,"log_text":"[08:57:49] Fetching Scraper for: LEC                              handlers.py:23\n           Begin attempting to scrape: LEC                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[08:57:50] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           \n           lorsByWard                                                           \n           [Errno 111] Connection refused                         handlers.py:36\n           Finished attempting to scrape: LEC                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno 111] Connection refused\n","start":"2024-04-27 08:57:49.144363","end":"2024-04-27 08:57:50.999235","duration":1}},{"council_id":"MOL","missing":false,"latest_run":{"status_code":1,"log_text":"[09:58:30] Fetching Scraper for: MOL                              handlers.py:23\n[09:58:31] Begin attempting to scrape: MOL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:58:32] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.molevalley.gov.uk/home/council/councillors/who           \n           -are-your-councillors                                                \n[09:58:34] Client error '404 Not Found' for url                   handlers.py:36\n           'https://www.molevalley.gov.uk/home/council/councillor               \n           s/who-are-your-councillors'                                          \n           For more information check:                                          \n           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               \n           us/404                                                               \n           Finished attempting to scrape: MOL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 152, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(url, extra_headers=self.extra_headers).text\n  File \"/var/task/lgsf/scrapers/base.py\", line 56, in get\n    response.raise_for_status()\n  File \"/opt/python/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.molevalley.gov.uk/home/council/councillors/who-are-your-councillors'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n","start":"2024-04-27 09:58:30.972235","end":"2024-04-27 09:58:34.852109","duration":3}},{"council_id":"NUN","missing":false,"latest_run":{"status_code":1,"log_text":"[08:54:30] Fetching Scraper for: NUN                              handlers.py:23\n           Begin attempting to scrape: NUN                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[08:54:31] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[08:54:32] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.nuneatonandbedworth.gov.uk/councillors/name              \n           Client error '404 Not Found' for url                   handlers.py:36\n           'https://www.nuneatonandbedworth.gov.uk/councillors/na               \n           me'                                                                  \n           For more information check:                                          \n           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               \n           us/404                                                               \n           Finished attempting to scrape: NUN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 152, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(url, extra_headers=self.extra_headers).text\n  File \"/var/task/lgsf/scrapers/base.py\", line 56, in get\n    response.raise_for_status()\n  File \"/opt/python/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.nuneatonandbedworth.gov.uk/councillors/name'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n","start":"2024-04-27 08:54:30.380592","end":"2024-04-27 08:54:32.631479","duration":2}},{"council_id":"ROS","missing":false,"latest_run":{"status_code":1,"log_text":"[10:37:17] Fetching Scraper for: ROS                              handlers.py:23\n           Begin attempting to scrape: ROS                        handlers.py:27\n[10:37:18] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:37:19] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from https://www.rossendale.gov.uk/councillors    base.py:49\n[10:37:21] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10079/adrian-lyt           \n           hgoe                                                                 \n[10:37:22] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10084/alan-neal            \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10093/alan-woods           \n[10:37:23] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10062/alyson-bar           \n           nes                                                                  \n[10:37:24] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10095/andrew-wal           \n           msley                                                                \n[10:37:25] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10080/andy-macna           \n           e                                                                    \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10102/ann-hodgki           \n           ss                                                                   \n[10:37:26] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10077/ann-kenyon           \n[10:37:27] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10065/anne-cartn           \n           er-cheetham                                                          \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10097/annie-mcma           \n           hon                                                                  \n[10:37:28] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10061/barbara-as           \n           hworth                                                               \n[10:37:29] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10101/caroline-s           \n           nowden                                                               \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10103/christine-           \n           gill                                                                 \n[10:37:30] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10107/danielle-a           \n           shworth                                                              \n[10:37:31] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10070/david-foxc           \n           roft                                                                 \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10096/dayne-powe           \n           ll                                                                   \n[10:37:32] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10071/gemma-rook           \n           e                                                                    \n[10:37:33] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10083/granville-           \n           morris                                                               \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10085/jacqueline           \n           -oakes                                                               \n[10:37:34] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10067/james-eato           \n           n                                                                    \n[10:37:35] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10060/janet-whit           \n           ehead                                                                \n[10:37:36] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10075/janice-joh           \n           nson                                                                 \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10064/jenny-rigb           \n           y                                                                    \n[10:37:37] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10105/judith-dri           \n           ver                                                                  \n[10:37:38] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10088/julie-adsh           \n           ead                                                                  \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10087/laura-beth           \n           -thompson                                                            \n[10:37:39] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10100/liz-mcinne           \n           s                                                                    \n[10:37:40] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10086/marilyn-pr           \n           octer                                                                \n[10:37:42] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10099/mary-cooga           \n           n                                                                    \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10106/matt-norto           \n           n                                                                    \n[10:37:43] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10098/michelle-s           \n           mith                                                                 \n[10:37:44] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10104/neil-looke           \n           r                                                                    \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10081/patrick-ma           \n           rriott                                                               \n[10:37:45] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10072/samara-bar           \n           nes                                                                  \n[10:37:46] Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10063/scott-smit           \n           h                                                                    \n           Scraping from                                              base.py:49\n           https://www.rossendale.gov.uk/councillors/10074/vacant-vac           \n           ant                                                                  \n[10:37:47] 'NoneType' object is not subscriptable                 handlers.py:36\n           Committing batch 1 consisting of 70 files                 base.py:297\n[10:37:48] Finished attempting to scrape: ROS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/ROS-rossendale/councillors.py\", line 48, in get_single_councillor\n    councillor.email = soup.select_one(\".page-meta a[href^=mailto]\")[\nTypeError: 'NoneType' object is not subscriptable\n","start":"2024-04-27 10:37:17.872854","end":"2024-04-27 10:37:48.723227","duration":30}},{"council_id":"SHE","missing":false,"latest_run":{"status_code":null,"log_text":"[11:28:20] Fetching Scraper for: SHE                              handlers.py:22\n           Begin attempting to scrape: SHE                        handlers.py:25\n           Deleting existing data...                                 base.py:234\n           Getting all files in SHE...                               base.py:186\n[11:28:21] Getting all files in SHE/json...                          base.py:186\n           ...found 30 files in SHE/json                             base.py:202\n           Getting all files in SHE/raw...                           base.py:186\n           ...found 30 files in SHE/raw                              base.py:202\n           ...found 61 files in SHE                                  base.py:202\n           Deleting batch no. 1 consisting of 61 files               base.py:211\n[11:28:32] An error occurred (ThrottlingException) when calling   handlers.py:34\n           the CreateCommit operation (reached max retries: 4):                 \n           Rate exceeded                                                        \n           Finished attempting to scrape: SHE                        base.py:319\n","errors":"An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded","start":"2022-04-04 11:28:20.509898","end":"2022-04-04 11:28:32.871624","duration":12}},{"council_id":"SHO","missing":false,"latest_run":{"status_code":1,"log_text":"[08:29:57] Fetching Scraper for: SHO                              handlers.py:23\n           Begin attempting to scrape: SHO                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[08:29:58] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://democracy.sholland.gov.uk/mgWebService.asmx/GetCou           \n           ncillorsByWard                                                       \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n[08:29:59] Finished attempting to scrape: SHO                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-27 08:29:57.008392","end":"2024-04-27 08:29:59.225562","duration":2}},{"council_id":"STG","missing":false,"latest_run":{"status_code":1,"log_text":"[10:27:47] Fetching Scraper for: STG                              handlers.py:23\n           Begin attempting to scrape: STG                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:27:48] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:27:49] ...data deleted.                                          base.py:264\n           Scraping from https://www.stirling.gov.uk/councillors      base.py:49\n[10:27:50] list index out of range                                handlers.py:36\n           Finished attempting to scrape: STG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 158, in get_list_container\n    return selected[0]\nIndexError: list index out of range\n","start":"2024-04-27 10:27:47.066428","end":"2024-04-27 10:27:50.713851","duration":3}},{"council_id":"THE","missing":false,"latest_run":{"status_code":1,"log_text":"[09:16:10] Fetching Scraper for: THE                              handlers.py:23\n           Begin attempting to scrape: THE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:16:11] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:16:12] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.threerivers.gov.uk/listing/councillors                   \n[09:16:14] 'NoneType' object has no attribute 'findNext'          handlers.py:36\n[09:16:15] Finished attempting to scrape: THE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"scrapers/THE-three-rivers/councillors.py\", line 15, in get_list_container\n    return soup.find(\"h3\", text=\"District Councillor\").findNext(\"ul\")\nAttributeError: 'NoneType' object has no attribute 'findNext'\n","start":"2024-04-27 09:16:10.453460","end":"2024-04-27 09:16:15.118084","duration":4}},{"council_id":"WAE","missing":false,"latest_run":{"status_code":1,"log_text":"[09:13:41] Fetching Scraper for: WAE                              handlers.py:23\n           Begin attempting to scrape: WAE                        handlers.py:27\n[09:13:42] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:13:43] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           \n           llorsByWard                                                          \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n           Finished attempting to scrape: WAE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 197, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 216, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-27 09:13:41.843462","end":"2024-04-27 09:13:43.980352","duration":2}}]
