[{"council_id":"ABC","missing":false,"latest_run":{"status_code":1,"log_text":"[10:00:43] Fetching Scraper for: ABC                              handlers.py:23\n           Begin attempting to scrape: ABC                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:00:44] Getting all files in Councillors/json...                  base.py:209\n           ...found 16 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 16 files in Councillors/raw                      base.py:225\n           ...found 33 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 33 files               base.py:236\n[10:00:45] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ABC                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:00:43.064215","end":"2024-04-26 10:00:45.512419","duration":2}},{"council_id":"AGB","missing":false,"latest_run":{"status_code":1,"log_text":"[09:45:33] Fetching Scraper for: AGB                              handlers.py:23\n           Begin attempting to scrape: AGB                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:45:34] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 36 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 36 files in Councillors/raw                      base.py:225\n           ...found 73 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 73 files               base.py:236\n[09:45:35] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: AGB                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 182, in get_councillors\n    soup = self.get_page(url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 09:45:33.292084","end":"2024-04-26 09:45:35.769564","duration":2}},{"council_id":"AND","missing":false,"latest_run":{"status_code":1,"log_text":"[10:22:07] Fetching Scraper for: AND                              handlers.py:23\n           Begin attempting to scrape: AND                        handlers.py:27\n[10:22:08] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:22:09] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: AND                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:22:07.872454","end":"2024-04-26 10:22:09.833690","duration":1}},{"council_id":"ANN","missing":false,"latest_run":{"status_code":1,"log_text":"[11:07:10] Fetching Scraper for: ANN                              handlers.py:23\n           Begin attempting to scrape: ANN                        handlers.py:27\n[11:07:11] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:07:12] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ANN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:07:10.592497","end":"2024-04-26 11:07:12.643291","duration":2}},{"council_id":"ANS","missing":false,"latest_run":{"status_code":1,"log_text":"[11:05:01] Fetching Scraper for: ANS                              handlers.py:23\n           Begin attempting to scrape: ANS                        handlers.py:27\n[11:05:02] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n[11:05:03] ...found 27 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 27 files in Councillors/raw                      base.py:225\n           ...found 55 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 55 files               base.py:236\n[11:05:04] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ANS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:05:01.714747","end":"2024-04-26 11:05:04.275583","duration":2}},{"council_id":"BOL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:34:31] Fetching Scraper for: BOL                              handlers.py:23\n           Begin attempting to scrape: BOL                        handlers.py:27\n[10:34:32] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n[10:34:33] ...found 59 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 59 files in Councillors/raw                      base.py:225\n           ...found 119 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:34:34] Deleting batch no. 2 consisting of 19 files               base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:34:35] Finished attempting to scrape: BOL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:34:31.768948","end":"2024-04-26 10:34:35.027590","duration":3}},{"council_id":"BOT","missing":false,"latest_run":{"status_code":1,"log_text":"[10:19:17] Fetching Scraper for: BOT                              handlers.py:23\n           Begin attempting to scrape: BOT                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:19:18] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:19:19] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://moderngov.boston.gov.uk/mgWebService.asmx/GetCounci           \n           llorsByWard                                                          \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n           Finished attempting to scrape: BOT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-26 10:19:17.476725","end":"2024-04-26 10:19:19.738123","duration":2}},{"council_id":"BRA","missing":false,"latest_run":{"status_code":1,"log_text":"[09:40:34] Fetching Scraper for: BRA                              handlers.py:23\n           Begin attempting to scrape: BRA                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:40:35] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 49 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 49 files in Councillors/raw                      base.py:225\n           ...found 99 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 99 files               base.py:236\n[09:40:36] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: BRA                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 09:40:34.260530","end":"2024-04-26 09:40:36.799612","duration":2}},{"council_id":"CAM","missing":false,"latest_run":{"status_code":1,"log_text":"[11:13:13] Fetching Scraper for: CAM                              handlers.py:23\n           Begin attempting to scrape: CAM                        handlers.py:27\n[11:13:14] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:13:15] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: CAM                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:13:13.686868","end":"2024-04-26 11:13:15.809696","duration":2}},{"council_id":"CAN","missing":false,"latest_run":{"status_code":1,"log_text":"[10:16:14] Fetching Scraper for: CAN                              handlers.py:23\n           Begin attempting to scrape: CAN                        handlers.py:27\n[10:16:15] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:16:16] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: CAN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:16:14.847314","end":"2024-04-26 10:16:16.812233","duration":1}},{"council_id":"CAS","missing":false,"latest_run":{"status_code":1,"log_text":"[10:26:28] Fetching Scraper for: CAS                              handlers.py:23\n           Begin attempting to scrape: CAS                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:26:29] Getting all files in Councillors/json...                  base.py:209\n           ...found 40 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 40 files in Councillors/raw                      base.py:225\n           ...found 81 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 81 files               base.py:236\n[10:26:30] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: CAS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:26:28.088876","end":"2024-04-26 10:26:30.467025","duration":2}},{"council_id":"CAT","missing":false,"latest_run":{"status_code":1,"log_text":"[09:50:36] Fetching Scraper for: CAT                              handlers.py:23\n           Begin attempting to scrape: CAT                        handlers.py:27\n[09:50:37] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[09:50:38] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://democracy.canterbury.gov.uk/mgWebService.asmx/GetCo           \n           uncillorsByWard                                                      \n[09:50:43] timed out                                              handlers.py:36\n           Finished attempting to scrape: CAT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectTimeout: timed out\n","start":"2024-04-26 09:50:36.801586","end":"2024-04-26 09:50:43.847713","duration":7}},{"council_id":"CLK","missing":false,"latest_run":{"status_code":1,"log_text":"[10:09:35] Fetching Scraper for: CLK                              handlers.py:23\n           Begin attempting to scrape: CLK                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:09:36] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 18 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 18 files in Councillors/raw                      base.py:225\n           ...found 37 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 37 files               base.py:236\n[10:09:37] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: CLK                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:09:35.101362","end":"2024-04-26 10:09:37.604090","duration":2}},{"council_id":"COL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:18:43] Fetching Scraper for: COL                              handlers.py:23\n           Begin attempting to scrape: COL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:18:44] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 50 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 50 files in Councillors/raw                      base.py:225\n           ...found 101 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:18:45] Deleting batch no. 2 consisting of 1 files                base.py:236\n[10:18:46] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: COL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:18:43.314540","end":"2024-04-26 10:18:46.423578","duration":3}},{"council_id":"DER","missing":false,"latest_run":{"status_code":1,"log_text":"[10:47:18] Fetching Scraper for: DER                              handlers.py:23\n           Begin attempting to scrape: DER                        handlers.py:27\n[10:47:19] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:47:20] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:47:21] Finished attempting to scrape: DER                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:47:18.945606","end":"2024-04-26 10:47:21.096675","duration":2}},{"council_id":"DRS","missing":false,"latest_run":{"status_code":1,"log_text":"[11:11:46] Fetching Scraper for: DRS                              handlers.py:23\n           Begin attempting to scrape: DRS                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[11:11:47] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           \n           ice.asmx/GetCouncillorsByWard                                        \n[11:11:52] timed out                                              handlers.py:36\n           Finished attempting to scrape: DRS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectTimeout: timed out\n","start":"2024-04-26 11:11:46.072556","end":"2024-04-26 11:11:53.000110","duration":6}},{"council_id":"DUD","missing":false,"latest_run":{"status_code":1,"log_text":"[09:51:15] Fetching Scraper for: DUD                              handlers.py:23\n           Begin attempting to scrape: DUD                        handlers.py:27\n[09:51:16] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 71 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n[09:51:17] ...found 71 files in Councillors/raw                      base.py:225\n           ...found 143 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n           Deleting batch no. 2 consisting of 43 files               base.py:236\n[09:51:18] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: DUD                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 09:51:15.592894","end":"2024-04-26 09:51:18.868373","duration":3}},{"council_id":"EAY","missing":false,"latest_run":{"status_code":1,"log_text":"[10:24:14] Fetching Scraper for: EAY                              handlers.py:23\n           Begin attempting to scrape: EAY                        handlers.py:27\n[10:24:15] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:24:16] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: EAY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:24:14.649171","end":"2024-04-26 10:24:16.607897","duration":1}},{"council_id":"EDU","missing":false,"latest_run":{"status_code":1,"log_text":"[11:13:51] Fetching Scraper for: EDU                              handlers.py:23\n           Begin attempting to scrape: EDU                        handlers.py:27\n[11:13:52] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[11:13:53] Getting all files in Councillors/json...                  base.py:209\n           ...found 22 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 22 files in Councillors/raw                      base.py:225\n           ...found 45 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 45 files               base.py:236\n[11:13:54] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: EDU                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:13:51.783253","end":"2024-04-26 11:13:54.463472","duration":2}},{"council_id":"ELS","missing":false,"latest_run":{"status_code":1,"log_text":"[08:19:07] Fetching Scraper for: ELS                              handlers.py:23\n           Begin attempting to scrape: ELS                        handlers.py:27\n           Deleting existing data...                                 base.py:251\n[08:19:08] Getting all files in Councillors...                       base.py:203\n           ...found 1 files in Councillors                           base.py:219\n           Deleting batch no. 1 consisting of 1 files                base.py:230\n[08:19:09] ...data deleted.                                          base.py:258\n           Scraping from                                              base.py:41\n           https://cne-siar.gov.uk/home/your-council/council-members/           \n[08:19:12] Scraping from https://cne-siar.gov.uk/kenneth-j-maclean/   base.py:41\n[08:19:14] 'NoneType' object has no attribute 'get_text'          handlers.py:36\n           Finished attempting to scrape: ELS                        base.py:339\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 58, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/ELS-na-h-eileanan-an-iar/councillors.py\", line 25, in get_single_councillor\n    .get_text(strip=True)\nAttributeError: 'NoneType' object has no attribute 'get_text'\n","start":"2024-04-26 08:19:07.218348","end":"2024-04-26 08:19:14.804740","duration":7}},{"council_id":"ERW","missing":false,"latest_run":{"status_code":1,"log_text":"[10:42:11] Fetching Scraper for: ERW                              handlers.py:23\n           Begin attempting to scrape: ERW                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:42:12] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:42:13] Finished attempting to scrape: ERW                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:42:11.119582","end":"2024-04-26 10:42:13.150741","duration":2}},{"council_id":"ESS","missing":false,"latest_run":{"status_code":1,"log_text":"[10:01:41] Fetching Scraper for: ESS                              handlers.py:23\n           Begin attempting to scrape: ESS                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:01:42] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:01:43] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ESS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:01:41.383722","end":"2024-04-26 10:01:43.432976","duration":2}},{"council_id":"FAL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:56:24] Fetching Scraper for: FAL                              handlers.py:23\n           Begin attempting to scrape: FAL                        handlers.py:27\n[10:56:26] Deleting existing data...                                 base.py:257\n[10:56:27] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:56:28] Finished attempting to scrape: FAL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:56:24.613746","end":"2024-04-26 10:56:28.175656","duration":3}},{"council_id":"FIF","missing":false,"latest_run":{"status_code":1,"log_text":"[10:41:48] Fetching Scraper for: FIF                              handlers.py:23\n           Begin attempting to scrape: FIF                        handlers.py:27\n[10:41:49] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:41:50] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: FIF                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"scrapers/FIF-fife/councillors.py\", line 17, in get_councillors\n    soup = self.get_page(url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:41:48.637180","end":"2024-04-26 10:41:50.833809","duration":2}},{"council_id":"FYL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:56:48] Fetching Scraper for: FYL                              handlers.py:23\n           Begin attempting to scrape: FYL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:56:49] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 37 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 37 files in Councillors/raw                      base.py:225\n           ...found 75 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 75 files               base.py:236\n[10:56:50] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: FYL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:56:48.509517","end":"2024-04-26 10:56:50.990382","duration":2}},{"council_id":"GLG","missing":false,"latest_run":{"status_code":1,"log_text":"[10:40:31] Fetching Scraper for: GLG                              handlers.py:23\n           Begin attempting to scrape: GLG                        handlers.py:27\n[10:40:32] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 85 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 85 files in Councillors/raw                      base.py:225\n           ...found 171 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:40:33] Deleting batch no. 2 consisting of 71 files               base.py:236\n[10:40:34] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: GLG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:40:31.567168","end":"2024-04-26 10:40:34.519244","duration":2}},{"council_id":"GRE","missing":false,"latest_run":{"status_code":1,"log_text":"[09:10:53] Fetching Scraper for: GRE                              handlers.py:23\n           Begin attempting to scrape: GRE                        handlers.py:27\n           Deleting existing data...                                 base.py:251\n[09:10:54] Getting all files in Councillors...                       base.py:203\n           ...found 1 files in Councillors                           base.py:219\n           Deleting batch no. 1 consisting of 1 files                base.py:230\n[09:10:55] ...data deleted.                                          base.py:258\n           Scraping from                                              base.py:41\n           https://committees.royalgreenwich.gov.uk/Councillors/tabid           \n           /63/ScreenMode/Alphabetical/Default.aspx                             \n           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36\n           v.uk', port=443): Max retries exceeded with url:                     \n           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               \n           aspx (Caused by SSLError(SSLCertVerificationError(1,                 \n           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 \n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)')))                                                    \n           Finished attempting to scrape: GRE                        base.py:339\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/urllib3/connectionpool.py\", line 468, in _make_request\n    self._validate_conn(conn)\n  File \"/opt/python/urllib3/connectionpool.py\", line 1097, in _validate_conn\n    conn.connect()\n  File \"/opt/python/urllib3/connection.py\", line 642, in connect\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n  File \"/opt/python/urllib3/connection.py\", line 783, in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n  File \"/opt/python/urllib3/util/ssl_.py\", line 471, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n  File \"/opt/python/urllib3/util/ssl_.py\", line 515, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"/var/lang/lib/python3.10/ssl.py\", line 513, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"/var/lang/lib/python3.10/ssl.py\", line 1104, in _create\n    self.do_handshake()\n  File \"/var/lang/lib/python3.10/ssl.py\", line 1375, in do_handshake\n    self._sslobj.do_handshake()\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/python/urllib3/connectionpool.py\", line 791, in urlopen\n    response = self._make_request(\n  File \"/opt/python/urllib3/connectionpool.py\", line 492, in _make_request\n    raise new_e\nurllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/python/requests/adapters.py\", line 486, in send\n    resp = conn.urlopen(\n  File \"/opt/python/urllib3/connectionpool.py\", line 845, in urlopen\n    retries = retries.increment(\n  File \"/opt/python/urllib3/util/retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 56, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 277, in get_councillors\n    req = self.get(\n  File \"/var/task/lgsf/scrapers/base.py\", line 47, in get\n    response = self.requests_session.get(\n  File \"/opt/python/requests/sessions.py\", line 602, in get\n    return self.request(\"GET\", url, **kwargs)\n  File \"/opt/python/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/opt/python/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/opt/python/requests/adapters.py\", line 517, in send\n    raise SSLError(e, request=request)\nrequests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n","start":"2024-04-26 09:10:53.542865","end":"2024-04-26 09:10:55.548371","duration":2}},{"council_id":"GRT","missing":false,"latest_run":{"status_code":1,"log_text":"[10:55:00] Fetching Scraper for: GRT                              handlers.py:23\n           Begin attempting to scrape: GRT                        handlers.py:27\n[10:55:01] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:55:02] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www2.guildford.gov.uk/councilmeetings/mgWebService           \n           .asmx/GetCouncillorsByWard                                           \n           [Errno -2] Name or service not known                   handlers.py:36\n           Finished attempting to scrape: GRT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n","start":"2024-04-26 10:55:00.632269","end":"2024-04-26 10:55:02.830008","duration":2}},{"council_id":"GRY","missing":false,"latest_run":{"status_code":1,"log_text":"[09:46:16] Fetching Scraper for: GRY                              handlers.py:23\n           Begin attempting to scrape: GRY                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:46:17] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 39 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 39 files in Councillors/raw                      base.py:225\n           ...found 79 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 79 files               base.py:236\n[09:46:18] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: GRY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 09:46:16.359761","end":"2024-04-26 09:46:18.888875","duration":2}},{"council_id":"HAO","missing":false,"latest_run":{"status_code":1,"log_text":"[10:22:52] Fetching Scraper for: HAO                              handlers.py:23\n           Begin attempting to scrape: HAO                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:22:53] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: HAO                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:22:52.046588","end":"2024-04-26 10:22:53.986713","duration":1}},{"council_id":"HLD","missing":false,"latest_run":{"status_code":1,"log_text":"[10:42:05] Fetching Scraper for: HLD                              handlers.py:23\n           Begin attempting to scrape: HLD                        handlers.py:27\n[10:42:06] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:42:07] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: HLD                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:42:05.539201","end":"2024-04-26 10:42:07.577737","duration":2}},{"council_id":"HPL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:20:23] Fetching Scraper for: HPL                              handlers.py:23\n           Begin attempting to scrape: HPL                        handlers.py:27\n[10:20:24] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:20:25] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: HPL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:20:23.840932","end":"2024-04-26 10:20:25.859299","duration":2}},{"council_id":"HRY","missing":false,"latest_run":{"status_code":1,"log_text":"[09:45:39] Fetching Scraper for: HRY                              handlers.py:23\n           Begin attempting to scrape: HRY                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[09:45:40] Getting all files in Councillors/json...                  base.py:209\n           ...found 57 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 57 files in Councillors/raw                      base.py:225\n           ...found 115 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[09:45:41] Deleting batch no. 2 consisting of 15 files               base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://www.minutes.haringey.gov.uk/mgWebService.asmx/GetCo           \n           uncillorsByWard                                                      \n[09:45:46] The read operation timed out                           handlers.py:36\n[09:45:47] Finished attempting to scrape: HRY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 101, in handle_request\n    return self._connection.handle_request(request)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 143, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/http11.py\", line 113, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 186, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n  File \"/opt/python/httpcore/_backends/sync.py\", line 124, in read\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n","start":"2024-04-26 09:45:39.024055","end":"2024-04-26 09:45:47.058299","duration":8}},{"council_id":"KHL","missing":false,"latest_run":{"status_code":1,"log_text":"[11:12:10] Fetching Scraper for: KHL                              handlers.py:23\n           Begin attempting to scrape: KHL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[11:12:11] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 57 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 57 files in Councillors/raw                      base.py:225\n           ...found 115 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[11:12:12] Deleting batch no. 2 consisting of 15 files               base.py:236\n[11:12:13] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: KHL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:12:10.424528","end":"2024-04-26 11:12:13.620141","duration":3}},{"council_id":"LEC","missing":false,"latest_run":{"status_code":1,"log_text":"[11:02:53] Fetching Scraper for: LEC                              handlers.py:23\n           Begin attempting to scrape: LEC                        handlers.py:27\n[11:02:54] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:02:55] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           \n           lorsByWard                                                           \n           [Errno 111] Connection refused                         handlers.py:36\n[11:02:56] Finished attempting to scrape: LEC                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno 111] Connection refused\n","start":"2024-04-26 11:02:53.805305","end":"2024-04-26 11:02:56.152528","duration":2}},{"council_id":"LUT","missing":false,"latest_run":{"status_code":1,"log_text":"[11:05:10] Fetching Scraper for: LUT                              handlers.py:23\n           Begin attempting to scrape: LUT                        handlers.py:27\n[11:05:11] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n[11:05:12] ...found 48 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 48 files in Councillors/raw                      base.py:225\n           ...found 97 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 97 files               base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[11:05:13] Finished attempting to scrape: LUT                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:05:10.740147","end":"2024-04-26 11:05:13.101185","duration":2}},{"council_id":"MLN","missing":false,"latest_run":{"status_code":1,"log_text":"[11:05:39] Fetching Scraper for: MLN                              handlers.py:23\n           Begin attempting to scrape: MLN                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[11:05:40] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:05:41] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: MLN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:05:39.550754","end":"2024-04-26 11:05:41.534667","duration":1}},{"council_id":"MOL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:45:53] Fetching Scraper for: MOL                              handlers.py:23\n           Begin attempting to scrape: MOL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:45:54] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:45:55] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: MOL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:45:53.412375","end":"2024-04-26 10:45:55.304251","duration":1}},{"council_id":"MRY","missing":false,"latest_run":{"status_code":1,"log_text":"[10:44:32] Fetching Scraper for: MRY                              handlers.py:23\n           Begin attempting to scrape: MRY                        handlers.py:27\n[10:44:33] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:44:35] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:44:36] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: MRY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:44:32.830612","end":"2024-04-26 10:44:36.461427","duration":3}},{"council_id":"MUL","missing":false,"latest_run":{"status_code":1,"log_text":"[11:10:50] Fetching Scraper for: MUL                              handlers.py:23\n           Begin attempting to scrape: MUL                        handlers.py:27\n[11:10:51] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:10:52] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: MUL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:10:50.550557","end":"2024-04-26 11:10:52.617569","duration":2}},{"council_id":"NAY","missing":false,"latest_run":{"status_code":1,"log_text":"[10:50:26] Fetching Scraper for: NAY                              handlers.py:23\n           Begin attempting to scrape: NAY                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:50:27] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 32 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 32 files in Councillors/raw                      base.py:225\n           ...found 65 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 65 files               base.py:236\n[10:50:28] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: NAY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:50:26.369878","end":"2024-04-26 10:50:28.725437","duration":2}},{"council_id":"NEL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:40:51] Fetching Scraper for: NEL                              handlers.py:23\n           Begin attempting to scrape: NEL                        handlers.py:27\n[10:40:52] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:40:53] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:40:54] Finished attempting to scrape: NEL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:40:51.946170","end":"2024-04-26 10:40:54.016475","duration":2}},{"council_id":"NFK","missing":false,"latest_run":{"status_code":1,"log_text":"[10:53:31] Fetching Scraper for: NFK                              handlers.py:23\n           Begin attempting to scrape: NFK                        handlers.py:27\n[10:53:32] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n[10:53:33] ...found 84 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 84 files in Councillors/raw                      base.py:225\n           ...found 169 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:53:34] Deleting batch no. 2 consisting of 69 files               base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: NFK                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:53:31.868840","end":"2024-04-26 10:53:34.936683","duration":3}},{"council_id":"NLK","missing":false,"latest_run":{"status_code":1,"log_text":"[10:58:24] Fetching Scraper for: NLK                              handlers.py:23\n           Begin attempting to scrape: NLK                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:58:25] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 77 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 77 files in Councillors/raw                      base.py:225\n           ...found 155 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:58:26] Deleting batch no. 2 consisting of 55 files               base.py:236\n[10:58:27] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: NLK                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:58:24.193628","end":"2024-04-26 10:58:27.348355","duration":3}},{"council_id":"NOW","missing":false,"latest_run":{"status_code":1,"log_text":"[10:46:18] Fetching Scraper for: NOW                              handlers.py:23\n           Begin attempting to scrape: NOW                        handlers.py:27\n[10:46:19] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:46:20] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: NOW                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:46:18.873107","end":"2024-04-26 10:46:20.764131","duration":1}},{"council_id":"NUN","missing":false,"latest_run":{"status_code":1,"log_text":"[09:11:00] Fetching Scraper for: NUN                              handlers.py:23\n           Begin attempting to scrape: NUN                        handlers.py:27\n           Deleting existing data...                                 base.py:251\n           Getting all files in Councillors...                       base.py:203\n[09:11:01] ...found 1 files in Councillors                           base.py:219\n           Deleting batch no. 1 consisting of 1 files                base.py:230\n           ...data deleted.                                          base.py:258\n           Scraping from                                              base.py:41\n           https://www.nuneatonandbedworth.gov.uk/councillors/name              \n[09:11:02] 404 Client Error: Not Found for url:                   handlers.py:36\n           https://www.nuneatonandbedworth.gov.uk/councillors/nam               \n           e                                                                    \n           Finished attempting to scrape: NUN                        base.py:339\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 56, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 164, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 155, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 142, in get_page\n    page = self.get(\n  File \"/var/task/lgsf/scrapers/base.py\", line 50, in get\n    response.raise_for_status()\n  File \"/opt/python/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.nuneatonandbedworth.gov.uk/councillors/name\n","start":"2024-04-26 09:11:00.108856","end":"2024-04-26 09:11:02.445174","duration":2}},{"council_id":"ORK","missing":false,"latest_run":{"status_code":1,"log_text":"[10:53:23] Fetching Scraper for: ORK                              handlers.py:23\n           Begin attempting to scrape: ORK                        handlers.py:27\n[10:53:24] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n[10:53:25] Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:53:26] Finished attempting to scrape: ORK                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:53:23.838998","end":"2024-04-26 10:53:26.006902","duration":2}},{"council_id":"PEN","missing":false,"latest_run":{"status_code":1,"log_text":"[10:47:38] Fetching Scraper for: PEN                              handlers.py:23\n           Begin attempting to scrape: PEN                        handlers.py:27\n[10:47:39] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:47:40] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:47:41] Finished attempting to scrape: PEN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:47:38.819416","end":"2024-04-26 10:47:41.142280","duration":2}},{"council_id":"PKN","missing":false,"latest_run":{"status_code":1,"log_text":"[10:05:24] Fetching Scraper for: PKN                              handlers.py:23\n           Begin attempting to scrape: PKN                        handlers.py:27\n[10:05:26] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:05:27] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: PKN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:05:24.609598","end":"2024-04-26 10:05:27.995333","duration":3}},{"council_id":"PLY","missing":false,"latest_run":{"status_code":1,"log_text":"[09:44:13] Fetching Scraper for: PLY                              handlers.py:23\n           Begin attempting to scrape: PLY                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:44:14] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 57 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 57 files in Councillors/raw                      base.py:225\n           ...found 115 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[09:44:15] Deleting batch no. 2 consisting of 15 files               base.py:236\n[09:44:16] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://democracy.plymouth.gov.uk/mgWebService.asmx/GetCou           \n           ncillorsByWard                                                       \n[09:44:21] The read operation timed out                           handlers.py:36\n           Finished attempting to scrape: PLY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 101, in handle_request\n    return self._connection.handle_request(request)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 143, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/http11.py\", line 113, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 186, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n  File \"/opt/python/httpcore/_sync/http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n  File \"/opt/python/httpcore/_backends/sync.py\", line 124, in read\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n","start":"2024-04-26 09:44:13.353283","end":"2024-04-26 09:44:21.547885","duration":8}},{"council_id":"RFW","missing":false,"latest_run":{"status_code":1,"log_text":"[10:07:52] Fetching Scraper for: RFW                              handlers.py:23\n           Begin attempting to scrape: RFW                        handlers.py:27\n[10:07:53] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n[10:07:54] ...found 43 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 43 files in Councillors/raw                      base.py:225\n           ...found 87 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 87 files               base.py:236\n[10:07:55] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: RFW                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:07:52.803334","end":"2024-04-26 10:07:55.356840","duration":2}},{"council_id":"ROC","missing":false,"latest_run":{"status_code":1,"log_text":"[11:14:35] Fetching Scraper for: ROC                              handlers.py:23\n           Begin attempting to scrape: ROC                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[11:14:36] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:14:37] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ROC                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:14:35.213277","end":"2024-04-26 11:14:37.301301","duration":2}},{"council_id":"ROS","missing":false,"latest_run":{"status_code":1,"log_text":"[11:09:31] Fetching Scraper for: ROS                              handlers.py:23\n           Begin attempting to scrape: ROS                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[11:09:32] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:09:33] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ROS                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:09:31.286642","end":"2024-04-26 11:09:33.277202","duration":1}},{"council_id":"RUG","missing":false,"latest_run":{"status_code":1,"log_text":"[10:21:41] Fetching Scraper for: RUG                              handlers.py:23\n           Begin attempting to scrape: RUG                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:21:42] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:21:43] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: RUG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:21:41.263772","end":"2024-04-26 10:21:43.359371","duration":2}},{"council_id":"SAY","missing":false,"latest_run":{"status_code":1,"log_text":"[10:50:34] Fetching Scraper for: SAY                              handlers.py:23\n           Begin attempting to scrape: SAY                        handlers.py:27\n[10:50:35] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:50:36] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: SAY                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:50:34.670431","end":"2024-04-26 10:50:36.705164","duration":2}},{"council_id":"SDE","missing":false,"latest_run":{"status_code":1,"log_text":"[10:50:40] Fetching Scraper for: SDE                              handlers.py:23\n           Begin attempting to scrape: SDE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:50:41] Getting all files in Councillors/json...                  base.py:209\n           ...found 35 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 35 files in Councillors/raw                      base.py:225\n           ...found 71 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 71 files               base.py:236\n[10:50:42] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: SDE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:50:40.045270","end":"2024-04-26 10:50:42.344414","duration":2}},{"council_id":"SFK","missing":false,"latest_run":{"status_code":1,"log_text":"[10:03:55] Fetching Scraper for: SFK                              handlers.py:23\n           Begin attempting to scrape: SFK                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:03:56] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:03:57] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: SFK                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:03:55.381850","end":"2024-04-26 10:03:57.454551","duration":2}},{"council_id":"SHE","missing":false,"latest_run":{"status_code":null,"log_text":"[11:28:20] Fetching Scraper for: SHE                              handlers.py:22\n           Begin attempting to scrape: SHE                        handlers.py:25\n           Deleting existing data...                                 base.py:234\n           Getting all files in SHE...                               base.py:186\n[11:28:21] Getting all files in SHE/json...                          base.py:186\n           ...found 30 files in SHE/json                             base.py:202\n           Getting all files in SHE/raw...                           base.py:186\n           ...found 30 files in SHE/raw                              base.py:202\n           ...found 61 files in SHE                                  base.py:202\n           Deleting batch no. 1 consisting of 61 files               base.py:211\n[11:28:32] An error occurred (ThrottlingException) when calling   handlers.py:34\n           the CreateCommit operation (reached max retries: 4):                 \n           Rate exceeded                                                        \n           Finished attempting to scrape: SHE                        base.py:319\n","errors":"An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded","start":"2022-04-04 11:28:20.509898","end":"2022-04-04 11:28:32.871624","duration":12}},{"council_id":"SHO","missing":false,"latest_run":{"status_code":1,"log_text":"[10:51:45] Fetching Scraper for: SHO                              handlers.py:23\n[10:51:46] Begin attempting to scrape: SHO                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:51:47] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://democracy.sholland.gov.uk/mgWebService.asmx/GetCou           \n           ncillorsByWard                                                       \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n[10:51:48] Finished attempting to scrape: SHO                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-26 10:51:45.988255","end":"2024-04-26 10:51:48.123991","duration":2}},{"council_id":"SLK","missing":false,"latest_run":{"status_code":1,"log_text":"[10:45:08] Fetching Scraper for: SLK                              handlers.py:23\n           Begin attempting to scrape: SLK                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:45:09] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 64 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 64 files in Councillors/raw                      base.py:225\n           ...found 129 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:45:10] Deleting batch no. 2 consisting of 29 files               base.py:236\n[10:45:11] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: SLK                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:45:08.347671","end":"2024-04-26 10:45:11.474868","duration":3}},{"council_id":"SND","missing":false,"latest_run":{"status_code":1,"log_text":"[10:26:13] Fetching Scraper for: SND                              handlers.py:23\n           Begin attempting to scrape: SND                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:26:14] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n[10:26:15] ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: SND                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:26:13.047609","end":"2024-04-26 10:26:15.268543","duration":2}},{"council_id":"SOL","missing":false,"latest_run":{"status_code":1,"log_text":"[08:58:24] Fetching Scraper for: SOL                              handlers.py:23\n           Begin attempting to scrape: SOL                        handlers.py:27\n[08:58:25] Deleting existing data...                                 base.py:251\n           Getting all files in Councillors...                       base.py:203\n           ...found 1 files in Councillors                           base.py:219\n           Deleting batch no. 1 consisting of 1 files                base.py:230\n[08:58:26] ...data deleted.                                          base.py:258\n           Scraping from                                              base.py:41\n           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           \n           asmx/GetCouncillorsByWard                                            \n           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36\n           port=443): Max retries exceeded with url:                            \n           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   \n           (Caused by                                                           \n           NewConnectionError('<urllib3.connection.HTTPSConnectio               \n           n object at 0x7f95498943a0>: Failed to establish a new               \n           connection: [Errno 111] Connection refused'))                        \n           Finished attempting to scrape: SOL                        base.py:339\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/urllib3/connection.py\", line 203, in _new_conn\n    sock = connection.create_connection(\n  File \"/opt/python/urllib3/util/connection.py\", line 85, in create_connection\n    raise err\n  File \"/opt/python/urllib3/util/connection.py\", line 73, in create_connection\n    sock.connect(sa)\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/python/urllib3/connectionpool.py\", line 791, in urlopen\n    response = self._make_request(\n  File \"/opt/python/urllib3/connectionpool.py\", line 492, in _make_request\n    raise new_e\n  File \"/opt/python/urllib3/connectionpool.py\", line 468, in _make_request\n    self._validate_conn(conn)\n  File \"/opt/python/urllib3/connectionpool.py\", line 1097, in _validate_conn\n    conn.connect()\n  File \"/opt/python/urllib3/connection.py\", line 611, in connect\n    self.sock = sock = self._new_conn()\n  File \"/opt/python/urllib3/connection.py\", line 218, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f95498943a0>: Failed to establish a new connection: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/python/requests/adapters.py\", line 486, in send\n    resp = conn.urlopen(\n  File \"/opt/python/urllib3/connectionpool.py\", line 845, in urlopen\n    retries = retries.increment(\n  File \"/opt/python/urllib3/util/retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f95498943a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 200, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 219, in get_councillors\n    req = self.get(\n  File \"/var/task/lgsf/scrapers/base.py\", line 47, in get\n    response = self.requests_session.get(\n  File \"/opt/python/requests/sessions.py\", line 602, in get\n    return self.request(\"GET\", url, **kwargs)\n  File \"/opt/python/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/opt/python/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/opt/python/requests/adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f95498943a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n","start":"2024-04-26 08:58:24.791210","end":"2024-04-26 08:58:26.807008","duration":2}},{"council_id":"SST","missing":false,"latest_run":{"status_code":1,"log_text":"[11:09:01] Fetching Scraper for: SST                              handlers.py:23\n           Begin attempting to scrape: SST                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[11:09:02] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[11:09:03] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: SST                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 11:09:01.278605","end":"2024-04-26 11:09:03.590852","duration":2}},{"council_id":"STG","missing":false,"latest_run":{"status_code":1,"log_text":"[10:53:11] Fetching Scraper for: STG                              handlers.py:23\n           Begin attempting to scrape: STG                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:53:12] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:53:13] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: STG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:53:11.136453","end":"2024-04-26 10:53:13.287724","duration":2}},{"council_id":"THE","missing":false,"latest_run":{"status_code":1,"log_text":"[10:21:11] Fetching Scraper for: THE                              handlers.py:23\n           Begin attempting to scrape: THE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:21:12] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:21:13] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: THE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"scrapers/THE-three-rivers/councillors.py\", line 14, in get_list_container\n    soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:21:11.480800","end":"2024-04-26 10:21:13.504490","duration":2}},{"council_id":"VGL","missing":false,"latest_run":{"status_code":1,"log_text":"[09:50:30] Fetching Scraper for: VGL                              handlers.py:23\n           Begin attempting to scrape: VGL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[09:50:31] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 54 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 54 files in Councillors/raw                      base.py:225\n           ...found 109 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[09:50:32] Deleting batch no. 2 consisting of 9 files                base.py:236\n[09:50:33] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: VGL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 09:50:30.294826","end":"2024-04-26 09:50:33.608910","duration":3}},{"council_id":"WAE","missing":false,"latest_run":{"status_code":1,"log_text":"[10:55:08] Fetching Scraper for: WAE                              handlers.py:23\n           Begin attempting to scrape: WAE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:55:09] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:55:10] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           \n           llorsByWard                                                          \n           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36\n           failed: unable to get local issuer certificate                       \n           (_ssl.c:1007)                                                        \n           Finished attempting to scrape: WAE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 154, in _connect\n    stream = stream.start_tls(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 152, in start_tls\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 199, in run\n    wards = self.get_councillors()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 218, in get_councillors\n    req = self.get(self.format_councillor_api_url())\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)\n","start":"2024-04-26 10:55:08.232719","end":"2024-04-26 10:55:10.351898","duration":2}},{"council_id":"WAW","missing":false,"latest_run":{"status_code":1,"log_text":"[10:40:04] Fetching Scraper for: WAW                              handlers.py:23\n           Begin attempting to scrape: WAW                        handlers.py:27\n[10:40:05] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:40:06] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: WAW                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:40:04.826662","end":"2024-04-26 10:40:06.917657","duration":2}},{"council_id":"WDU","missing":false,"latest_run":{"status_code":1,"log_text":"[10:58:54] Fetching Scraper for: WDU                              handlers.py:23\n           Begin attempting to scrape: WDU                        handlers.py:27\n[10:58:55] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:58:57] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:58:58] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: WDU                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:58:54.660786","end":"2024-04-26 10:58:58.311762","duration":3}},{"council_id":"WLL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:28:52] Fetching Scraper for: WLL                              handlers.py:23\n           Begin attempting to scrape: WLL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:28:53] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:28:54] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: WLL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 274, in get_councillors\n    req = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:28:52.427560","end":"2024-04-26 10:28:54.501088","duration":2}},{"council_id":"WLN","missing":false,"latest_run":{"status_code":1,"log_text":"[10:57:45] Fetching Scraper for: WLN                              handlers.py:23\n           Begin attempting to scrape: WLN                        handlers.py:27\n[10:57:46] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:57:47] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n[10:57:48] Finished attempting to scrape: WLN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"scrapers/WLN-west-lothian/councillors.py\", line 12, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:57:45.849414","end":"2024-04-26 10:57:48.011045","duration":2}},{"council_id":"WYE","missing":false,"latest_run":{"status_code":1,"log_text":"[10:25:52] Fetching Scraper for: WYE                              handlers.py:23\n           Begin attempting to scrape: WYE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:25:53] Getting all files in Councillors...                       base.py:209\n           ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:25:54] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: WYE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 163, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:25:52.394174","end":"2024-04-26 10:25:54.489063","duration":2}},{"council_id":"ZET","missing":false,"latest_run":{"status_code":1,"log_text":"[10:18:00] Fetching Scraper for: ZET                              handlers.py:23\n[10:18:01] Begin attempting to scrape: ZET                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:18:02] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n[10:18:03] ...data deleted.                                          base.py:264\n           ScraperBase.get() got an unexpected keyword argument   handlers.py:36\n           'verify'                                                             \n           Finished attempting to scrape: ZET                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"scrapers/ZET-shetland-islands/councillors.py\", line 14, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 154, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(\nTypeError: ScraperBase.get() got an unexpected keyword argument 'verify'\n","start":"2024-04-26 10:18:00.970088","end":"2024-04-26 10:18:03.282128","duration":2}}]
