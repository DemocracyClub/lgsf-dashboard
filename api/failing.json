[{"council_id":"BOL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:40:49] Fetching Scraper for: BOL                              handlers.py:23\n           Begin attempting to scrape: BOL                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:40:50] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.democracy.bolton.gov.uk/cmis5/People.aspx                \n           [Errno -2] Name or service not known                   handlers.py:36\n[10:40:51] Finished attempting to scrape: BOL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/opt/python/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/opt/python/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/opt/python/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n  File \"/opt/python/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/opt/python/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n  File \"/opt/python/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n  File \"/opt/python/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 272, in get_councillors\n    req = self.get(\n  File \"/var/task/lgsf/scrapers/base.py\", line 55, in get\n    response = self.http_client.get(url, headers=headers, timeout=30)\n  File \"/opt/python/httpx/_client.py\", line 1054, in get\n    return self.request(\n  File \"/opt/python/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n  File \"/opt/python/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n  File \"/opt/python/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n  File \"/opt/python/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n  File \"/opt/python/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n  File \"/opt/python/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/var/lang/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/python/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n","start":"2024-05-08 10:40:49.031918","end":"2024-05-08 10:40:51.163495","duration":2}},{"council_id":"CAN","missing":false,"latest_run":{"status_code":1,"log_text":"[09:28:50] Fetching Scraper for: CAN                              handlers.py:23\n           Begin attempting to scrape: CAN                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[09:28:51] Getting all files in Councillors/json...                  base.py:209\n           ...found 3 files in Councillors/json                      base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 3 files in Councillors/raw                       base.py:225\n           ...found 7 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 7 files                base.py:236\n[09:28:52] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.cannockchasedc.gov.uk/council/about-council/yo           \n           ur-councillors                                                       \n[09:28:54] Scraping from                                              base.py:49\n           https://www.cannockchasedc.gov.uk/council/about-us/council           \n           lors/carl-boulton                                                    \n[09:28:56] Scraping from                                              base.py:49\n           https://www.cannockchasedc.gov.uk/council/about-us/council           \n           lors/paul-fisher                                                     \n[09:28:58] Scraping from                                              base.py:49\n           https://www.cannockchasedc.gov.uk/council/about-us/council           \n           lors/david-williams                                                  \n[09:28:59] 'NoneType' object is not subscriptable                 handlers.py:36\n           Committing batch 1 consisting of 6 files                  base.py:297\n[09:29:00] Finished attempting to scrape: CAN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/CAN-cannock-chase/councillors.py\", line 22, in get_single_councillor\n    url = urljoin(self.base_url, link[\"href\"].strip())\nTypeError: 'NoneType' object is not subscriptable\n","start":"2024-05-08 09:28:50.025550","end":"2024-05-08 09:29:01.008690","duration":10}},{"council_id":"GLG","missing":false,"latest_run":{"status_code":1,"log_text":"[10:45:48] Fetching Scraper for: GLG                              handlers.py:23\n           Begin attempting to scrape: GLG                        handlers.py:27\n[10:45:49] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n[10:45:50] ...found 85 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 85 files in Councillors/raw                      base.py:225\n           ...found 171 files in Councillors                         base.py:225\n           Deleting batch no. 1 consisting of 100 files              base.py:236\n[10:45:51] Deleting batch no. 2 consisting of 71 files               base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.glasgow.gov.uk/councillorsandcommittees/allMem           \n           bers.asp?sort=0&page=0&rec=100                                       \n[10:45:52] Client error '404 Not Found' for url                   handlers.py:36\n           'https://www.glasgow.gov.uk/councillorsandcommittees/a               \n           llMembers.asp?sort=0&page=0&rec=100'                                 \n           For more information check:                                          \n           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               \n           us/404                                                               \n           Finished attempting to scrape: GLG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 152, in get_list_container\n    self.base_url_soup = self.get_page(self.base_url)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 141, in get_page\n    page = self.get(url, extra_headers=self.extra_headers).text\n  File \"/var/task/lgsf/scrapers/base.py\", line 56, in get\n    response.raise_for_status()\n  File \"/opt/python/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.glasgow.gov.uk/councillorsandcommittees/allMembers.asp?sort=0&page=0&rec=100'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n","start":"2024-05-08 10:45:48.895496","end":"2024-05-08 10:45:52.326037","duration":3}},{"council_id":"GRE","missing":false,"latest_run":{"status_code":1,"log_text":"[09:34:54] Fetching Scraper for: GRE                              handlers.py:23\n           Begin attempting to scrape: GRE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[09:34:55] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://committees.royalgreenwich.gov.uk/Councillors/tabid           \n           /63/ScreenMode/Alphabetical/Default.aspx                             \n[09:35:02] Client error '404 Not Found' for url                   handlers.py:36\n           'https://committees.royalgreenwich.gov.uk/mgError.aspx               \n           '                                                                    \n           For more information check:                                          \n           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               \n           us/404                                                               \n[09:35:03] Finished attempting to scrape: GRE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 272, in get_councillors\n    req = self.get(\n  File \"/var/task/lgsf/scrapers/base.py\", line 56, in get\n    response.raise_for_status()\n  File \"/opt/python/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '404 Not Found' for url 'https://committees.royalgreenwich.gov.uk/mgError.aspx'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n","start":"2024-05-08 09:34:54.110299","end":"2024-05-08 09:35:04.692192","duration":10}},{"council_id":"MOL","missing":false,"latest_run":{"status_code":1,"log_text":"[10:47:33] Fetching Scraper for: MOL                              handlers.py:23\n           Begin attempting to scrape: MOL                        handlers.py:27\n[10:47:34] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[10:47:35] Getting all files in Councillors/json...                  base.py:209\n           ...found 37 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 37 files in Councillors/raw                      base.py:225\n           ...found 75 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 75 files               base.py:236\n[10:47:36] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.molevalley.gov.uk/councillors-decision-making/           \n           who-are-your-councillors/                                            \n[10:47:37] Scraping from                                              base.py:49\n           https://www.molevalley.gov.uk/councillors-decision-making/           \n           who-are-your-councillors/cllr-chris-hunt/                            \n[10:47:42] Scraping from                                              base.py:49\n           https://www.molevalley.gov.uk/councillors-decision-making/           \n           who-are-your-councillors/cllr-patricia-wiltshire/                    \n[10:47:44] Scraping from                                              base.py:49\n           https://www.molevalley.gov.uk/councillors-decision-making/           \n           who-are-your-councillors/cllr-andy-smith/                            \n[10:47:47] 'NoneType' object has no attribute 'get_text'          handlers.py:36\n           Committing batch 1 consisting of 4 files                  base.py:297\n[10:47:48] Finished attempting to scrape: MOL                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/MOL-mole-valley/councillors.py\", line 44, in get_single_councillor\n    ).get_text(strip=True)\nAttributeError: 'NoneType' object has no attribute 'get_text'\n","start":"2024-05-08 10:47:33.834041","end":"2024-05-08 10:47:48.547329","duration":14}},{"council_id":"NUN","missing":false,"latest_run":{"status_code":1,"log_text":"[10:29:42] Fetching Scraper for: NUN                              handlers.py:23\n           Begin attempting to scrape: NUN                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n[10:29:43] Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 16 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 16 files in Councillors/raw                      base.py:225\n           ...found 33 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 33 files               base.py:236\n[10:29:44] ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.nuneatonandbedworth.gov.uk/councillors                   \n[10:29:46] Scraping from                                              base.py:49\n           https://www.nuneatonandbedworth.gov.uk/councillors/50/amar           \n           jit-khangura                                                         \n           'NoneType' object is not subscriptable                 handlers.py:36\n           Finished attempting to scrape: NUN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/NUN-nuneaton-and-bedworth/councillors.py\", line 48, in get_single_councillor\n    councillor.email = soup.select_one(\nTypeError: 'NoneType' object is not subscriptable\n","start":"2024-05-08 10:29:42.402412","end":"2024-05-08 10:29:46.757067","duration":4}},{"council_id":"PEN","missing":false,"latest_run":{"status_code":1,"log_text":"[09:29:27] Fetching Scraper for: PEN                              handlers.py:23\n           Begin attempting to scrape: PEN                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[09:29:28] Getting all files in Councillors/json...                  base.py:209\n           ...found 32 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n           ...found 32 files in Councillors/raw                      base.py:225\n           ...found 65 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 65 files               base.py:236\n[09:29:29] ...data deleted.                                          base.py:264\n           Scraping from https://www.pendle.gov.uk/councillors/name   base.py:49\n[09:29:31] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/76/mohammed_adnan              \n           Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/83/faraz_ahmad                 \n[09:29:32] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/2/nadeem_ahmed                 \n[09:29:33] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/91/sajjad_ahmed                \n           Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/67/zafar_ali                   \n[09:29:34] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/88/mohammad_ammer              \n[09:29:35] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/84/ruby_anwar                  \n[09:29:36] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/8/naeem_hussain_ashr           \n           af                                                                   \n           Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/94/mohammad_aslam              \n[09:29:38] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/12/neil_butterworth            \n[09:29:39] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/85/chris_church                \n[09:29:40] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/75/david_cockburn-pr           \n           ice                                                                  \n[09:29:41] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/64/sarah_cockburn-pr           \n           ice                                                                  \n           Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/92/david_gallear               \n[09:29:42] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/71/mohammad_hanif              \n[09:29:43] Scraping from                                              base.py:49\n           https://www.pendle.gov.uk/councillors/99/david_hartley               \n           'NoneType' object is not subscriptable                 handlers.py:36\n[09:29:44] Committing batch 1 consisting of 30 files                 base.py:297\n[09:29:45] Finished attempting to scrape: PEN                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/PEN-pendle/councillors.py\", line 48, in get_single_councillor\n    councillor.email = soup.select_one(\"li a[href^=mailto]\")[\nTypeError: 'NoneType' object is not subscriptable\n","start":"2024-05-08 09:29:27.010331","end":"2024-05-08 09:29:45.229506","duration":18}},{"council_id":"RUG","missing":false,"latest_run":{"status_code":1,"log_text":"[08:55:10] Fetching Scraper for: RUG                              handlers.py:23\n           Begin attempting to scrape: RUG                        handlers.py:27\n[08:55:11] Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n           Getting all files in Councillors/json...                  base.py:209\n           ...found 42 files in Councillors/json                     base.py:225\n           Getting all files in Councillors/raw...                   base.py:209\n[08:55:12] ...found 42 files in Councillors/raw                      base.py:225\n           ...found 85 files in Councillors                          base.py:225\n           Deleting batch no. 1 consisting of 85 files               base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from https://www.rugby.gov.uk/councillors/        base.py:49\n[08:55:15] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18474/6618404/maximized                                              \n[08:55:17] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18756/6618404/maximized                                              \n[08:55:18] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18792/6618404/maximized                                              \n[08:55:19] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18810/6618404/maximized                                              \n[08:55:20] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18828/6618404/maximized                                              \n[08:55:22] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18919/6618404/maximized                                              \n[08:55:25] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18991/6618404/maximized                                              \n[08:55:26] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19117/6618404/maximized                                              \n[08:55:27] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19171/6618404/maximized                                              \n[08:55:28] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19207/6618404/maximized                                              \n[08:55:29] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19261/6618404/maximized                                              \n[08:55:31] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18665/6618404/maximized                                              \n[08:55:32] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18719/6618404/maximized                                              \n[08:55:33] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18774/6618404/maximized                                              \n[08:55:34] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18846/6618404/maximized                                              \n[08:55:36] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19009/6618404/maximized                                              \n[08:55:37] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19082/6618404/maximized                                              \n[08:55:38] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19099/6618404/maximized                                              \n[08:55:39] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19153/6618404/maximized                                              \n[08:55:41] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19189/6618404/maximized                                              \n[08:55:42] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           19225/6618404/maximized                                              \n[08:55:43] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18865/6618404/maximized                                              \n[08:55:44] Scraping from                                              base.py:49\n           https://www.rugby.gov.uk/councillors//-/ddl_display/ddl/66           \n           18629/6618404/maximized                                              \n[08:55:46] 'NoneType' object has no attribute 'get_text'          handlers.py:36\n           Committing batch 1 consisting of 44 files                 base.py:297\n[08:55:47] Finished attempting to scrape: RUG                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 57, in run\n    councillor = self.get_single_councillor(councillor_html)\n  File \"scrapers/RUG-rugby/councillors.py\", line 49, in get_single_councillor\n    councillor.email = soup.find(\"span\", text=re.compile(\"@\")).get_text(strip=True)\nAttributeError: 'NoneType' object has no attribute 'get_text'\n","start":"2024-05-08 08:55:10.547098","end":"2024-05-08 08:55:47.420709","duration":36}},{"council_id":"SHE","missing":false,"latest_run":{"status_code":null,"log_text":"[11:28:20] Fetching Scraper for: SHE                              handlers.py:22\n           Begin attempting to scrape: SHE                        handlers.py:25\n           Deleting existing data...                                 base.py:234\n           Getting all files in SHE...                               base.py:186\n[11:28:21] Getting all files in SHE/json...                          base.py:186\n           ...found 30 files in SHE/json                             base.py:202\n           Getting all files in SHE/raw...                           base.py:186\n           ...found 30 files in SHE/raw                              base.py:202\n           ...found 61 files in SHE                                  base.py:202\n           Deleting batch no. 1 consisting of 61 files               base.py:211\n[11:28:32] An error occurred (ThrottlingException) when calling   handlers.py:34\n           the CreateCommit operation (reached max retries: 4):                 \n           Rate exceeded                                                        \n           Finished attempting to scrape: SHE                        base.py:319\n","errors":"An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded","start":"2022-04-04 11:28:20.509898","end":"2022-04-04 11:28:32.871624","duration":12}},{"council_id":"THE","missing":false,"latest_run":{"status_code":1,"log_text":"[09:10:45] Fetching Scraper for: THE                              handlers.py:23\n           Begin attempting to scrape: THE                        handlers.py:27\n           Deleting existing data...                                 base.py:257\n           Getting all files in Councillors...                       base.py:209\n[09:10:46] ...found 1 files in Councillors                           base.py:225\n           Deleting batch no. 1 consisting of 1 files                base.py:236\n           ...data deleted.                                          base.py:264\n           Scraping from                                              base.py:49\n           https://www.threerivers.gov.uk/listing/councillors                   \n[09:10:48] 'NoneType' object has no attribute 'findNext'          handlers.py:36\n           Finished attempting to scrape: THE                        base.py:345\n","errors":"Traceback (most recent call last):\n  File \"/var/task/lgsf/aws_lambda/handlers.py\", line 32, in scraper_worker_handler\n    scraper.run(run_log)\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 55, in run\n    for councillor_html in self.get_councillors():\n  File \"/var/task/lgsf/councillors/scrapers.py\", line 161, in get_councillors\n    container = self.get_list_container()\n  File \"scrapers/THE-three-rivers/councillors.py\", line 15, in get_list_container\n    return soup.find(\"h3\", text=\"District Councillor\").findNext(\"ul\")\nAttributeError: 'NoneType' object has no attribute 'findNext'\n","start":"2024-05-08 09:10:45.008863","end":"2024-05-08 09:10:48.623376","duration":3}}]
