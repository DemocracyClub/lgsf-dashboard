<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-14-11-15">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:15:50.538687</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:15:56.223926</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:15:50] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:15:51] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[11:15:52] ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:15:53] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:15:55] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:15:56] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-13-11-42">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:42:35.903783</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:42:46.584790</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:35] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
[11:42:36] Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:42:46] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-13-00-05">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>22 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 00:05:09.773781</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 00:05:32.657896</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:05:27] Created log commit                                        base.py:376
           4ebe8c4c2b276b96ecb4b30d7c71d426ce6642f3                             
           Attempting to create merge commit...                      base.py:281
[00:05:32] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-11-11-25">2022-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-11 11:25:45.097125</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-11 11:25:57.544811</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:25:45] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[11:25:46] Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:25:47] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:25:57] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-10-11-48">2022-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-10 11:48:02.758704</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-10 11:48:12.584672</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:48:02] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:48:03] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:48:12] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-09-11-36">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 11:36:30.592161</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 11:36:37.062999</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:36:30] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[11:36:31] Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:36:36] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:36:37] No new councillor data found.                             base.py:317
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-08-12-16">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>24 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 12:16:32.769211</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 12:16:57.510617</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:16:51] Created log commit                                        base.py:376
           ac67771dbaf13554c86f7df2e0ec076bfd42e97a                             
           Attempting to create merge commit...                      base.py:281
[12:16:57] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-08-12-00">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>27 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 12:00:35.124470</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 12:01:02.201958</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:00:35] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[12:00:36] ...found 53 files in SEV/raw                              base.py:202
           ...found 106 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:00:46] Deleting batch no. 2 consisting of 6 files                base.py:211
[12:00:48] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[12:00:54] Committing batch 1 consisting of 92 files                 base.py:269
[12:01:00] Committing batch 2 consisting of 14 files                 base.py:269
[12:01:02] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-08-00-12">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 00:12:19.067110</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 00:12:36.609478</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:12:19] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 46 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 46 files in SEV/raw                              base.py:202
           ...found 93 files in SEV                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[00:12:21] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:12:28] Committing batch 1 consisting of 92 files                 base.py:269
[00:12:35] Committing batch 2 consisting of 14 files                 base.py:269
[00:12:36] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-08-00-03">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 00:03:53.854630</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 00:04:10.836831</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:03:53] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
[00:03:54] Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:03:56] Deleting batch no. 2 consisting of 7 files                base.py:211
[00:04:01] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:04:07] Committing batch 1 consisting of 92 files                 base.py:269
[00:04:09] Committing batch 2 consisting of 14 files                 base.py:269
[00:04:10] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-08-00-01">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 00:01:23.567008</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 00:01:44.852333</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:01:23] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[00:01:24] Getting all files in SEV/json...                          base.py:186
           ...found 46 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 46 files in SEV/raw                              base.py:202
           ...found 92 files in SEV                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[00:01:25] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:01:32] Committing batch 1 consisting of 92 files                 base.py:269
[00:01:35] Committing batch 2 consisting of 14 files                 base.py:269
[00:01:41] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 14 files                 base.py:269
[00:01:44] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-05-20-03">2022-03-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-05 20:03:29.931596</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-05 20:03:39.021593</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[20:03:29] Fetching Scraper for: SEV                              handlers.py:21
           Begin attempting to scrape: SEV                        handlers.py:24
[20:03:30] Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
[20:03:31] Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 106 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[20:03:38] An error occurred (ThrottlingException) when calling   handlers.py:33
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[20:03:39] No new councillor data found.                             base.py:317
           Finished attempting to scrape: SEV                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
