<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-04-01-00-00">2022-04-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-01 00:00:24.765339</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-01 00:00:36.274288</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:00:24] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:00:25] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
[00:00:26] ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:00:27] Deleting batch no. 2 consisting of 7 files                base.py:211
[00:00:28] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:00:31] Committing batch 1 consisting of 92 files                 base.py:269
[00:00:33] Committing batch 2 consisting of 14 files                 base.py:269
[00:00:36] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-30-11-14">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 11:14:44.084621</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 11:14:55.774869</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:14:44] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[11:14:45] Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:14:46] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:14:47] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:14:52] Committing batch 1 consisting of 92 files                 base.py:269
[11:14:54] Committing batch 2 consisting of 14 files                 base.py:269
[11:14:55] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-29-11-50">2022-03-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-29 11:50:34.724146</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-29 11:50:47.221821</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:50:34] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:50:35] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:50:36] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:50:39] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:50:43] Committing batch 1 consisting of 92 files                 base.py:269
[11:50:45] Committing batch 2 consisting of 14 files                 base.py:269
[11:50:47] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-28-11-32">2022-03-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-28 11:32:21.407970</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-28 11:32:28.029284</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:32:21] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/raw...                           base.py:186
[11:32:22] ...found 7 files in SEV/raw                               base.py:202
           ...found 8 files in SEV                                   base.py:202
           Deleting batch no. 1 consisting of 8 files                base.py:211
[11:32:27] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:32:28] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-27-11-35">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 11:35:22.724914</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 11:35:37.438994</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:22] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:35:23] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/raw...                           base.py:186
[11:35:24] ...found 7 files in SEV/raw                               base.py:202
           ...found 8 files in SEV                                   base.py:202
           Deleting batch no. 1 consisting of 8 files                base.py:211
[11:35:30] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:35:34] Committing batch 1 consisting of 92 files                 base.py:269
[11:35:35] Committing batch 2 consisting of 14 files                 base.py:269
[11:35:37] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-27-00-00">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 00:00:44.970997</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 00:00:52.768396</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:00:44] Fetching Scraper for: SEV                              handlers.py:22
[00:00:45] Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[00:00:46] Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:00:47] Deleting batch no. 2 consisting of 7 files                base.py:211
[00:00:52] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-25-11-16">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 11:16:23.810535</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 11:16:34.935758</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:23] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:16:24] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:16:25] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:16:27] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:16:30] Committing batch 1 consisting of 92 files                 base.py:269
[11:16:33] Committing batch 2 consisting of 14 files                 base.py:269
[11:16:34] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-25-00-00">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 00:00:33.202329</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 00:00:53.751477</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:00:33] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:00:34] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:00:35] Deleting batch no. 2 consisting of 7 files                base.py:211
[00:00:36] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:00:40] Committing batch 1 consisting of 92 files                 base.py:269
[00:00:51] Committing batch 2 consisting of 14 files                 base.py:269
[00:00:53] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-24-00-02">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>29 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 00:02:14.787271</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 00:02:44.577762</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:02:39] Created log commit                                        base.py:376
           52018b5a4442b7669c4ddb5071f71fed9de1efae                             
           Attempting to create merge commit...                      base.py:281
[00:02:44] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-22-11-16">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 11:16:24.601036</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 11:16:31.550381</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:24] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:16:25] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[11:16:26] ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:16:27] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:16:31] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-21-11-18">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 11:18:04.653234</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 11:18:19.941029</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:18:04] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:18:05] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 46 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[11:18:06] ...found 46 files in SEV/raw                              base.py:202
           ...found 93 files in SEV                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[11:18:07] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:18:12] Committing batch 1 consisting of 92 files                 base.py:269
[11:18:13] Committing batch 2 consisting of 14 files                 base.py:269
[11:18:19] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-21-00-05">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>29 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 00:05:54.632158</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 00:06:24.511952</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:05:54] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:05:55] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[00:05:56] ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:05:57] Deleting batch no. 2 consisting of 7 files                base.py:211
[00:05:58] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:06:03] Committing batch 1 consisting of 92 files                 base.py:269
[00:06:13] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[00:06:24] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-19-12-02">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 12:02:24.211261</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 12:02:33.195166</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:02:24] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 46 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[12:02:25] ...found 46 files in SEV/raw                              base.py:202
           ...found 93 files in SEV                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[12:02:26] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[12:02:30] Committing batch 1 consisting of 92 files                 base.py:269
[12:02:31] Committing batch 2 consisting of 14 files                 base.py:269
[12:02:33] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-18-11-19">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>39 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:19:08.963241</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:19:48.277499</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:19:43] Created log commit                                        base.py:376
           5d818e7c001ca82513973413a874dac5cf082174                             
           Attempting to create merge commit...                      base.py:281
[11:19:47] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[11:19:48] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-17-11-19">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:19:16.995523</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:19:33.102007</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:19:16] Fetching Scraper for: SEV                              handlers.py:22
[11:19:17] Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 46 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 46 files in SEV/raw                              base.py:202
           ...found 93 files in SEV                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[11:19:24] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:19:28] Committing batch 1 consisting of 92 files                 base.py:269
[11:19:29] Committing batch 2 consisting of 14 files                 base.py:269
[11:19:33] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-17-00-01">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 00:01:33.993776</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 00:01:47.159269</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:01:33] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
[00:01:34] Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[00:01:35] Getting all files in SEV/json...                          base.py:186
           ...found 46 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 46 files in SEV/raw                              base.py:202
           ...found 93 files in SEV                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[00:01:39] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[00:01:43] Committing batch 1 consisting of 92 files                 base.py:269
[00:01:45] Committing batch 2 consisting of 14 files                 base.py:269
[00:01:47] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-15-11-18">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>26 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:18:16.427391</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:18:42.824321</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:18:16] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:18:17] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/raw...                           base.py:186
           ...found 7 files in SEV/raw                               base.py:202
           ...found 8 files in SEV                                   base.py:202
           Deleting batch no. 1 consisting of 8 files                base.py:211
[11:18:19] ...data deleted.                                          base.py:241
           Scraping from http://cds.sevenoaks.gov.uk/mgWebService.asm base.py:40
           x/GetCouncillorsByWard                                               
[11:18:26] Committing batch 1 consisting of 92 files                 base.py:269
[11:18:35] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:18:42] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-14-11-15">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:15:50.538687</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:15:56.223926</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:15:50] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:15:51] Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
[11:15:52] ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:15:53] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:15:55] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:15:56] Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-13-11-42">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:42:35.903783</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:42:46.584790</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:35] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
[11:42:36] Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
           Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:42:46] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-13-00-05">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>22 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 00:05:09.773781</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 00:05:32.657896</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:05:27] Created log commit                                        base.py:376
           4ebe8c4c2b276b96ecb4b30d7c71d426ce6642f3                             
           Attempting to create merge commit...                      base.py:281
[00:05:32] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: SEV                        base.py:319
</pre>

  <h2 id="2022-03-11-11-25">2022-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-11 11:25:45.097125</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-11 11:25:57.544811</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:25:45] Fetching Scraper for: SEV                              handlers.py:22
           Begin attempting to scrape: SEV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SEV...                               base.py:186
[11:25:46] Getting all files in SEV/json...                          base.py:186
           ...found 53 files in SEV/json                             base.py:202
           Getting all files in SEV/raw...                           base.py:186
           ...found 53 files in SEV/raw                              base.py:202
           ...found 107 files in SEV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:25:47] Deleting batch no. 2 consisting of 7 files                base.py:211
[11:25:57] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SEV                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
