<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-27-00-08">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 00:08:28.011424</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 00:08:40.285406</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:08:28] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/raw...                           base.py:186
           ...found 51 files in DUR/raw                              base.py:202
           ...found 52 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 52 files               base.py:211
[00:08:29] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:08:34] Committing batch 1 consisting of 92 files                 base.py:269
[00:08:36] Committing batch 2 consisting of 92 files                 base.py:269
[00:08:38] Committing batch 3 consisting of 66 files                 base.py:269
[00:08:40] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-26-00-04">2022-03-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-26 00:04:21.530506</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-26 00:04:37.312467</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:04:21] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:04:22] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 46 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
[00:04:23] ...found 46 files in DUR/raw                              base.py:202
           ...found 93 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[00:04:24] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:04:30] Committing batch 1 consisting of 92 files                 base.py:269
[00:04:32] Committing batch 2 consisting of 92 files                 base.py:269
[00:04:34] Committing batch 3 consisting of 66 files                 base.py:269
[00:04:37] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-24-11-20">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 11:20:39.324615</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 11:20:59.415680</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:20:39] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:20:40] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 46 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 46 files in DUR/raw                              base.py:202
           ...found 93 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[11:20:44] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:20:49] Committing batch 1 consisting of 92 files                 base.py:269
[11:20:57] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:20:59] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-23-11-23">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>23 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 11:23:01.581907</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 11:23:25.292529</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:23:01] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:23:02] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/raw...                           base.py:186
           ...found 52 files in DUR/raw                              base.py:202
           ...found 53 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 53 files               base.py:211
[11:23:10] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:23:15] Committing batch 1 consisting of 92 files                 base.py:269
[11:23:23] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:23:25] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-23-00-02">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 00:02:50.682425</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 00:03:03.890281</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:02:50] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:02:51] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 26 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 152 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:02:58] Deleting batch no. 2 consisting of 52 files               base.py:211
[00:03:03] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-22-00-10">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 00:10:40.653709</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 00:10:49.545141</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:10:40] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
[00:10:41] Getting all files in DUR/json...                          base.py:186
           ...found 125 files in DUR/json                            base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 250 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:10:44] Deleting batch no. 2 consisting of 100 files              base.py:211
[00:10:49] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-20-12-16">2022-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>31 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-20 12:16:31.448677</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-20 12:17:03.249258</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:16:31] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
[12:16:32] ...found 92 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 92 files in DUR/raw                              base.py:202
           ...found 184 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:16:34] Deleting batch no. 2 consisting of 84 files               base.py:211
[12:16:44] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[12:16:48] Committing batch 1 consisting of 92 files                 base.py:269
[12:16:55] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[12:17:03] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-19-11-37">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:37:15.547999</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:37:24.782180</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:37:15] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:37:16] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 92 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 92 files in DUR/raw                              base.py:202
           ...found 185 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:37:18] Deleting batch no. 2 consisting of 85 files               base.py:211
[11:37:24] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-18-11-49">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:49:44.217103</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:50:04.186981</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:49:44] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:49:45] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 125 files in DUR/json                            base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 251 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:49:47] Deleting batch no. 2 consisting of 100 files              base.py:211
[11:49:48] Deleting batch no. 3 consisting of 51 files               base.py:211
[11:49:49] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:49:54] Committing batch 1 consisting of 92 files                 base.py:269
[11:49:57] Committing batch 2 consisting of 92 files                 base.py:269
[11:50:01] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 92 files                 base.py:269
[11:50:04] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-17-11-34">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:34:56.910441</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:35:14.804772</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:34:56] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:34:57] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/raw...                           base.py:186
           ...found 51 files in DUR/raw                              base.py:202
           ...found 51 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 51 files               base.py:211
[11:34:59] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:35:04] Committing batch 1 consisting of 92 files                 base.py:269
[11:35:08] Committing batch 2 consisting of 92 files                 base.py:269
[11:35:12] Committing batch 3 consisting of 66 files                 base.py:269
[11:35:14] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-16-11-35">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:35:11.091306</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:35:25.422981</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:11] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 46 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
[11:35:12] ...found 46 files in DUR/raw                              base.py:202
           ...found 92 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[11:35:13] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:35:18] Committing batch 1 consisting of 92 files                 base.py:269
[11:35:21] Committing batch 2 consisting of 92 files                 base.py:269
[11:35:23] Committing batch 3 consisting of 66 files                 base.py:269
[11:35:25] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-15-11-54">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>37 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:54:41.531213</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:55:19.030363</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:55:11] Created log commit                                        base.py:376
           271f9709bdf740c96d9f580ff566960d0318734f                             
           Attempting to create merge commit...                      base.py:281
[11:55:18] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[11:55:19] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-14-11-53">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:53:04.119896</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:53:18.343520</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:53:04] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 125 files in DUR/json                            base.py:202
           Getting all files in DUR/raw...                           base.py:186
[11:53:05] ...found 125 files in DUR/raw                             base.py:202
           ...found 251 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:53:09] Deleting batch no. 2 consisting of 100 files              base.py:211
[11:53:10] Deleting batch no. 3 consisting of 51 files               base.py:211
[11:53:17] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:53:18] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-13-11-32">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:32:21.302354</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:32:29.482593</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:32:21] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 33 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
[11:32:22] ...found 117 files in DUR/raw                             base.py:202
           ...found 150 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:32:29] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-12-11-29">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>30 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 11:29:57.952210</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 11:30:28.151997</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:29:57] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
[11:29:58] Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
[11:29:59] ...found 25 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 151 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:30:06] Deleting batch no. 2 consisting of 51 files               base.py:211
[11:30:08] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:30:13] Committing batch 1 consisting of 92 files                 base.py:269
[11:30:21] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:30:28] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-11-11-16">2022-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>33 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-11 11:16:56.118799</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-11 11:17:29.495276</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:56] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
[11:16:57] Getting all files in DUR/json...                          base.py:186
           ...found 125 files in DUR/json                            base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 251 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:16:59] Deleting batch no. 2 consisting of 100 files              base.py:211
[11:17:03] Deleting batch no. 3 consisting of 51 files               base.py:211
[11:17:04] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:17:10] Committing batch 1 consisting of 92 files                 base.py:269
[11:17:12] Committing batch 2 consisting of 92 files                 base.py:269
[11:17:14] Committing batch 3 consisting of 66 files                 base.py:269
[11:17:26] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 3 consisting of 66 files                 base.py:269
[11:17:29] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-10-12-00">2022-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-10 12:00:50.053904</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-10 12:01:09.406626</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:00:50] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
[12:00:51] Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/raw...                           base.py:186
[12:00:52] ...found 52 files in DUR/raw                              base.py:202
           ...found 52 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 52 files               base.py:211
[12:00:55] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[12:01:00] Committing batch 1 consisting of 92 files                 base.py:269
[12:01:03] Committing batch 2 consisting of 92 files                 base.py:269
[12:01:07] Committing batch 3 consisting of 66 files                 base.py:269
[12:01:09] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-09-11-31">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 11:31:37.856661</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 11:31:48.268081</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:31:37] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:31:38] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
[11:31:39] ...found 125 files in DUR/json                            base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 251 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:31:40] Deleting batch no. 2 consisting of 100 files              base.py:211
[11:31:47] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:31:48] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-09-00-03">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 00:03:20.789906</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 00:03:34.214858</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:03:20] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:03:21] Getting all files in DUR...                               base.py:186
           Getting all files in DUR/json...                          base.py:186
           ...found 92 files in DUR/json                             base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 92 files in DUR/raw                              base.py:202
           ...found 185 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:03:22] Deleting batch no. 2 consisting of 85 files               base.py:211
[00:03:23] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:03:28] Committing batch 1 consisting of 92 files                 base.py:269
[00:03:30] Committing batch 2 consisting of 92 files                 base.py:269
[00:03:31] Committing batch 3 consisting of 66 files                 base.py:269
[00:03:34] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-07-11-42">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>34 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 11:42:10.952513</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 11:42:44.991243</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:10] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
[11:42:11] Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
           Getting all files in DUR/raw...                           base.py:186
[11:42:12] ...found 51 files in DUR/raw                              base.py:202
           ...found 52 files in DUR                                  base.py:202
           Deleting batch no. 1 consisting of 52 files               base.py:211
[11:42:23] ...data deleted.                                          base.py:241
           Scraping from https://democracy.durham.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:42:30] Committing batch 1 consisting of 92 files                 base.py:269
[11:42:42] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:42:44] Finished attempting to scrape: DUR                        base.py:319
</pre>

  <h2 id="2022-03-06-18-18">2022-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-06 18:18:51.182558</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-06 18:19:01.776068</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:18:51] Fetching Scraper for: DUR                              handlers.py:22
           Begin attempting to scrape: DUR                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in DUR...                               base.py:186
[18:18:52] Getting all files in DUR/json...                          base.py:186
           ...found 125 files in DUR/json                            base.py:202
           Getting all files in DUR/raw...                           base.py:186
           ...found 125 files in DUR/raw                             base.py:202
           ...found 251 files in DUR                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[18:18:54] Deleting batch no. 2 consisting of 100 files              base.py:211
[18:18:55] Deleting batch no. 3 consisting of 51 files               base.py:211
[18:19:01] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: DUR                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
