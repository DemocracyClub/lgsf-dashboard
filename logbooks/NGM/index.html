<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2025-01-13-10-37">2025-01-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-13 10:37:19.268525</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-13 10:37:29.095318</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:37:19] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:37:20] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:37:21] Deleting batch no. 2 consisting of 11 files               base.py:236
[10:37:22] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:37:26] Committing batch 1 consisting of 92 files                 base.py:297
[10:37:27] Committing batch 2 consisting of 18 files                 base.py:297
[10:37:29] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-12-09-33">2025-01-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-12 09:33:17.117128</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-12 09:33:26.379965</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:33:17] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:33:18] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:33:19] Deleting batch no. 2 consisting of 11 files               base.py:236
[09:33:20] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:33:23] Committing batch 1 consisting of 92 files                 base.py:297
[09:33:25] Committing batch 2 consisting of 18 files                 base.py:297
[09:33:26] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-11-08-52">2025-01-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-11 08:52:42.491633</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-11 08:52:50.222880</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:52:42] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:52:43] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
[08:52:44] Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 11 files               base.py:236
[08:52:45] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:52:48] Committing batch 1 consisting of 92 files                 base.py:297
[08:52:49] Committing batch 2 consisting of 18 files                 base.py:297
[08:52:50] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-10-10-04">2025-01-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-10 10:04:59.162417</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-10 10:05:07.109354</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:04:59] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:05:00] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:05:01] Deleting batch no. 2 consisting of 11 files               base.py:236
[10:05:02] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:05:04] Committing batch 1 consisting of 92 files                 base.py:297
[10:05:06] Committing batch 2 consisting of 18 files                 base.py:297
[10:05:07] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-09-08-31">2025-01-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-09 08:31:24.304551</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-09 08:31:31.425578</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:31:24] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:31:25] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:31:26] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:31:29] Committing batch 1 consisting of 92 files                 base.py:297
[08:31:30] Committing batch 2 consisting of 18 files                 base.py:297
[08:31:31] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-08-09-48">2025-01-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>33 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-08 09:48:51.628844</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-08 09:49:25.072787</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:48:51] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[09:48:52] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:48:53] ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 11 files               base.py:236
[09:48:54] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:49:24] The read operation timed out                           handlers.py:36
[09:49:25] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-07-08-36">2025-01-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-07 08:36:07.245316</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-07 08:36:14.251810</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:36:07] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:36:08] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:36:09] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:36:12] Committing batch 1 consisting of 92 files                 base.py:297
[08:36:13] Committing batch 2 consisting of 18 files                 base.py:297
[08:36:14] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-06-08-49">2025-01-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-06 08:49:28.808978</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-06 08:50:01.604326</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:49:28] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[08:49:29] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:49:30] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:50:01] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-05-08-19">2025-01-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-05 08:19:42.694892</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-05 08:19:45.847409</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 972, in _send_handling_redirects
    raise TooManyRedirects(
httpx.TooManyRedirects: Exceeded maximum allowed redirects.
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:19:42] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[08:19:43] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:19:44] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:19:45] Exceeded maximum allowed redirects.                    handlers.py:36
           Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-04-08-32">2025-01-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-04 08:32:01.018114</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-04 08:32:04.139535</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 972, in _send_handling_redirects
    raise TooManyRedirects(
httpx.TooManyRedirects: Exceeded maximum allowed redirects.
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:32:01] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:32:02] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:32:03] Exceeded maximum allowed redirects.                    handlers.py:36
[08:32:04] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-03-08-44">2025-01-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-03 08:44:01.119625</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-03 08:44:04.111982</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 972, in _send_handling_redirects
    raise TooManyRedirects(
httpx.TooManyRedirects: Exceeded maximum allowed redirects.
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:44:01] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:44:02] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:44:03] Exceeded maximum allowed redirects.                    handlers.py:36
[08:44:04] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-02-08-18">2025-01-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-02 08:18:48.336936</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-02 08:18:51.688597</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 972, in _send_handling_redirects
    raise TooManyRedirects(
httpx.TooManyRedirects: Exceeded maximum allowed redirects.
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:18:48] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:18:49] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:18:50] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:18:51] Exceeded maximum allowed redirects.                    handlers.py:36
           Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2025-01-01-09-59">2025-01-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-01-01 09:59:55.763611</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-01-01 10:00:00.119426</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 972, in _send_handling_redirects
    raise TooManyRedirects(
httpx.TooManyRedirects: Exceeded maximum allowed redirects.
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:59:55] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[09:59:56] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[09:59:57] ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:59:58] Deleting batch no. 2 consisting of 11 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:59:59] Exceeded maximum allowed redirects.                    handlers.py:36
[10:00:00] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-31-08-24">2024-12-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-31 08:24:01.816403</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-31 08:24:10.826948</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:01] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[08:24:02] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[08:24:03] ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:24:04] Deleting batch no. 2 consisting of 11 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:24:07] Committing batch 1 consisting of 92 files                 base.py:297
[08:24:09] Committing batch 2 consisting of 18 files                 base.py:297
[08:24:10] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-30-08-18">2024-12-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-30 08:18:07.862146</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-30 08:18:27.300027</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:18:07] Fetching Scraper for: NGM                              handlers.py:23
[08:18:17] Begin attempting to scrape: NGM                        handlers.py:27
[08:18:19] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[08:18:20] ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:18:21] Deleting batch no. 2 consisting of 11 files               base.py:236
[08:18:22] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:18:25] Committing batch 1 consisting of 92 files                 base.py:297
[08:18:26] Committing batch 2 consisting of 18 files                 base.py:297
[08:18:27] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-29-10-06">2024-12-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-29 10:06:33.634294</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-29 10:06:41.519863</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:06:33] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[10:06:34] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[10:06:35] ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 11 files               base.py:236
[10:06:36] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:06:39] Committing batch 1 consisting of 92 files                 base.py:297
[10:06:40] Committing batch 2 consisting of 18 files                 base.py:297
[10:06:41] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-28-09-54">2024-12-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-28 09:54:21.431426</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-28 09:54:30.201811</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:54:21] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:54:22] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:54:23] ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 11 files               base.py:236
[09:54:24] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:54:27] Committing batch 1 consisting of 92 files                 base.py:297
[09:54:29] Committing batch 2 consisting of 18 files                 base.py:297
[09:54:30] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-27-10-15">2024-12-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-27 10:15:04.143057</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-27 10:15:12.451943</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:15:04] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:15:05] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:15:06] Deleting batch no. 2 consisting of 11 files               base.py:236
[10:15:07] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:15:10] Committing batch 1 consisting of 92 files                 base.py:297
[10:15:11] Committing batch 2 consisting of 18 files                 base.py:297
[10:15:12] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-26-10-22">2024-12-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-26 10:22:21.563142</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-26 10:22:31.054623</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:22:21] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:22:22] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[10:22:23] ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 11 files               base.py:236
[10:22:24] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:22:27] Committing batch 1 consisting of 92 files                 base.py:297
[10:22:29] Committing batch 2 consisting of 18 files                 base.py:297
[10:22:31] Finished attempting to scrape: NGM                        base.py:345
</pre>
  

  


  <h2 id="2024-12-25-10-20">2024-12-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-12-25 10:20:03.128094</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-12-25 10:20:10.733466</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:20:03] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:20:04] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 55 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 55 files in Councillors/raw                      base.py:225
           ...found 111 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:20:05] Deleting batch no. 2 consisting of 11 files               base.py:236
[10:20:06] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:20:08] Committing batch 1 consisting of 92 files                 base.py:297
[10:20:09] Committing batch 2 consisting of 18 files                 base.py:297
[10:20:10] Finished attempting to scrape: NGM                        base.py:345
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
