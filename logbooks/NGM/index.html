<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-01-27-09-26">2024-01-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-27 09:26:58.638248</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-27 09:27:06.830125</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:26:58] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:26:59] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:27:00] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:27:01] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:27:04] Committing batch 1 consisting of 92 files                 base.py:291
[09:27:05] Committing batch 2 consisting of 18 files                 base.py:291
[09:27:06] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-26-08-46">2024-01-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-26 08:46:56.074875</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-26 08:47:04.025918</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:46:56] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[08:46:57] Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:46:58] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:47:01] Committing batch 1 consisting of 92 files                 base.py:291
[08:47:02] Committing batch 2 consisting of 18 files                 base.py:291
[08:47:04] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-25-09-32">2024-01-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-25 09:32:25.211107</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-25 09:32:33.290907</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:32:25] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:32:26] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:32:27] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:32:28] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:32:31] Committing batch 1 consisting of 92 files                 base.py:291
[09:32:32] Committing batch 2 consisting of 18 files                 base.py:291
[09:32:33] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-24-09-00">2024-01-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-24 09:00:23.085605</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-24 09:00:31.409436</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:00:23] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:00:24] Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:00:25] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:00:26] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:00:29] Committing batch 1 consisting of 92 files                 base.py:291
[09:00:30] Committing batch 2 consisting of 18 files                 base.py:291
[09:00:31] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-23-09-42">2024-01-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-23 09:42:16.009748</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-23 09:42:22.945358</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:42:16] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
[09:42:17] Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:42:20] Committing batch 1 consisting of 92 files                 base.py:291
[09:42:21] Committing batch 2 consisting of 18 files                 base.py:291
[09:42:22] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-22-09-16">2024-01-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-22 09:16:20.356637</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-22 09:16:36.731888</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
  File "/opt/python/urllib3/connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "/var/lang/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/var/lang/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
  File "/opt/python/urllib3/connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "/var/lang/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/var/lang/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 725, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 725, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 266, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:16:20] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:16:21] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:16:22] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:16:24] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:16:36] ('Connection aborted.', RemoteDisconnected('Remote end handlers.py:36
           closed connection without response'))                                
           Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-21-10-22">2024-01-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-21 10:22:41.910271</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-21 10:22:51.154333</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:22:41] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[10:22:42] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[10:22:43] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:22:45] Deleting batch no. 2 consisting of 11 files               base.py:230
[10:22:46] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:22:48] Committing batch 1 consisting of 92 files                 base.py:291
[10:22:49] Committing batch 2 consisting of 18 files                 base.py:291
[10:22:51] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-20-10-26">2024-01-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-20 10:26:15.401310</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-20 10:26:24.394211</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:26:15] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:26:16] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:26:17] Deleting batch no. 2 consisting of 11 files               base.py:230
[10:26:18] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:26:22] Committing batch 1 consisting of 92 files                 base.py:291
[10:26:23] Committing batch 2 consisting of 18 files                 base.py:291
[10:26:24] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-19-08-36">2024-01-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-19 08:36:50.164049</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-19 08:36:57.973329</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:36:50] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[08:36:51] Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:36:52] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
[08:36:53] Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:36:55] Committing batch 1 consisting of 92 files                 base.py:291
[08:36:56] Committing batch 2 consisting of 18 files                 base.py:291
[08:36:57] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-18-08-31">2024-01-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-18 08:31:09.684288</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-18 08:31:19.427771</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:31:09] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[08:31:10] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[08:31:11] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
           Deleting batch no. 2 consisting of 11 files               base.py:230
[08:31:12] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:31:17] Committing batch 1 consisting of 92 files                 base.py:291
[08:31:18] Committing batch 2 consisting of 18 files                 base.py:291
[08:31:19] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-17-09-51">2024-01-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-17 09:51:13.485635</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-17 09:51:21.890654</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:51:13] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:51:14] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:51:15] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:51:16] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:51:19] Committing batch 1 consisting of 92 files                 base.py:291
[09:51:20] Committing batch 2 consisting of 18 files                 base.py:291
[09:51:21] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-16-09-44">2024-01-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-16 09:44:36.538113</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-16 09:44:45.114628</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:44:36] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:44:37] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:44:38] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:44:39] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:44:42] Committing batch 1 consisting of 92 files                 base.py:291
[09:44:44] Committing batch 2 consisting of 18 files                 base.py:291
[09:44:45] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-15-09-10">2024-01-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-15 09:10:36.819810</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-15 09:10:43.927177</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:36] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[09:10:37] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:10:38] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:10:41] Committing batch 1 consisting of 92 files                 base.py:291
[09:10:42] Committing batch 2 consisting of 18 files                 base.py:291
[09:10:43] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-14-09-59">2024-01-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-14 09:59:26.345560</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-14 09:59:41.864585</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
  File "/opt/python/urllib3/connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "/var/lang/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/var/lang/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
  File "/opt/python/urllib3/connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "/var/lang/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/var/lang/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 725, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 725, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 266, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:59:26] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:59:27] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:59:28] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:59:29] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:59:41] ('Connection aborted.', RemoteDisconnected('Remote end handlers.py:36
           closed connection without response'))                                
           Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-13-10-38">2024-01-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-13 10:38:57.219933</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-13 10:39:05.078694</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:38:57] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:38:58] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:38:59] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:39:02] Committing batch 1 consisting of 92 files                 base.py:291
[10:39:03] Committing batch 2 consisting of 18 files                 base.py:291
[10:39:05] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-12-09-31">2024-01-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-12 09:31:36.828866</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-12 09:31:45.429743</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:31:36] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[09:31:37] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:31:38] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:31:39] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[09:31:42] Committing batch 1 consisting of 92 files                 base.py:291
[09:31:44] Committing batch 2 consisting of 18 files                 base.py:291
[09:31:45] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-11-10-29">2024-01-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-11 10:29:51.754412</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-11 10:29:59.987937</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:29:51] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[10:29:52] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[10:29:53] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:29:54] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:29:57] Committing batch 1 consisting of 92 files                 base.py:291
[10:29:58] Committing batch 2 consisting of 18 files                 base.py:291
[10:29:59] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-10-08-24">2024-01-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-10 08:24:26.299262</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-10 08:24:38.457341</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:26] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:24:27] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:24:28] Deleting batch no. 2 consisting of 11 files               base.py:230
[08:24:29] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:24:35] Committing batch 1 consisting of 92 files                 base.py:291
[08:24:37] Committing batch 2 consisting of 18 files                 base.py:291
[08:24:38] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-09-08-20">2024-01-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-09 08:20:56.928894</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-09 08:21:04.716290</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:20:56] Fetching Scraper for: NGM                              handlers.py:23
           Begin attempting to scrape: NGM                        handlers.py:27
[08:20:57] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:20:58] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[08:21:02] Committing batch 1 consisting of 92 files                 base.py:291
[08:21:03] Committing batch 2 consisting of 18 files                 base.py:291
[08:21:04] Finished attempting to scrape: NGM                        base.py:339
</pre>
  

  


  <h2 id="2024-01-08-10-09">2024-01-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>22 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-01-08 10:09:35.167731</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-01-08 10:09:57.168471</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
  File "/opt/python/urllib3/connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "/var/lang/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/var/lang/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
  File "/opt/python/urllib3/connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "/var/lang/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/var/lang/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 725, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 725, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 266, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:09:35] Fetching Scraper for: NGM                              handlers.py:23
[10:09:39] Begin attempting to scrape: NGM                        handlers.py:27
[10:09:41] Deleting existing data...                                 base.py:251
[10:09:42] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
[10:09:43] Deleting batch no. 1 consisting of 100 files              base.py:230
           Deleting batch no. 2 consisting of 11 files               base.py:230
[10:09:44] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://committee.nottinghamcity.gov.uk/mgWebService.asmx/G           
           etCouncillorsByWard                                                  
[10:09:56] ('Connection aborted.', RemoteDisconnected('Remote end handlers.py:36
           closed connection without response'))                                
[10:09:57] Finished attempting to scrape: NGM                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
