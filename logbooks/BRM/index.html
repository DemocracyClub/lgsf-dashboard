<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-03-14-09-37">2024-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-14 09:37:14.041626</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-14 09:37:19.030759</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:37:14] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:37:15] Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[09:37:16] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:37:17] Committing batch 1 consisting of 62 files                 base.py:291
[09:37:19] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-13-10-02">2024-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-13 10:02:24.648227</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-13 10:02:29.647899</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:02:24] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:02:25] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[10:02:26] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[10:02:28] Committing batch 1 consisting of 62 files                 base.py:291
[10:02:29] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-12-09-54">2024-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-12 09:54:10.689876</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-12 09:54:15.944375</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:54:10] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
[09:54:11] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[09:54:12] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:54:14] Committing batch 1 consisting of 62 files                 base.py:291
[09:54:15] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-11-09-39">2024-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-11 09:39:06.736170</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-11 09:39:11.769621</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:39:06] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
[09:39:07] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:39:08] ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:39:10] Committing batch 1 consisting of 62 files                 base.py:291
[09:39:11] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-10-09-03">2024-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>58 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-10 09:03:20.301145</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-10 09:04:19.253027</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:03:20] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:03:21] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:03:22] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:04:17] Committing batch 1 consisting of 62 files                 base.py:291
[09:04:19] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-09-09-10">2024-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-09 09:10:15.034736</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-09 09:12:26.672401</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f09d07ca5c0>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='moderngovwebpublic.bromsgrove.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f09d07ca5c0>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='moderngovwebpublic.bromsgrove.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f09d07ca5c0>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:15] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:10:16] Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[09:10:17] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:12:26] HTTPConnectionPool(host='moderngovwebpublic.bromsgrove handlers.py:36
           .gov.uk', port=80): Max retries exceeded with url:                   
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f09d07ca5c0>, 'Connection to                            
           moderngovwebpublic.bromsgrove.gov.uk timed out.                      
           (connect timeout=None)'))                                            
           Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-08-09-13">2024-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-08 09:13:53.224110</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-08 09:14:00.594233</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:13:53] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:13:54] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[09:13:55] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:13:59] Committing batch 1 consisting of 62 files                 base.py:291
[09:14:00] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-07-08-19">2024-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-07 08:19:56.579997</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-07 08:20:02.040435</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:19:56] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:19:57] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[08:19:58] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[08:20:00] Committing batch 1 consisting of 62 files                 base.py:291
[08:20:02] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-06-09-54">2024-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-06 09:54:17.767521</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-06 09:54:23.108079</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:54:17] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
[09:54:18] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:54:19] ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:54:22] Committing batch 1 consisting of 62 files                 base.py:291
[09:54:23] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-05-08-19">2024-03-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-05 08:19:35.141090</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-05 08:19:40.015855</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:19:35] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[08:19:36] Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[08:19:37] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[08:19:38] Committing batch 1 consisting of 62 files                 base.py:291
[08:19:40] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-04-10-42">2024-03-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-04 10:42:28.855292</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-04 10:42:35.934349</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:42:28] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
[10:42:29] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[10:42:31] Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[10:42:32] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[10:42:34] Committing batch 1 consisting of 62 files                 base.py:291
[10:42:35] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-03-08-41">2024-03-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-03 08:41:32.360878</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-03 08:41:37.058925</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:41:32] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:41:33] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[08:41:35] Committing batch 1 consisting of 62 files                 base.py:291
[08:41:37] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-02-10-13">2024-03-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-02 10:13:33.140914</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-02 10:15:45.213927</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f7e45545f30>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='moderngovwebpublic.bromsgrove.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7e45545f30>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='moderngovwebpublic.bromsgrove.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7e45545f30>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:13:33] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[10:13:34] Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[10:13:35] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[10:15:44] HTTPConnectionPool(host='moderngovwebpublic.bromsgrove handlers.py:36
           .gov.uk', port=80): Max retries exceeded with url:                   
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f7e45545f30>, 'Connection to                            
           moderngovwebpublic.bromsgrove.gov.uk timed out.                      
           (connect timeout=None)'))                                            
[10:15:45] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-03-01-08-26">2024-03-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-03-01 08:26:52.594345</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-03-01 08:26:57.620400</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:26:52] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:26:53] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[08:26:54] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[08:26:56] Committing batch 1 consisting of 62 files                 base.py:291
[08:26:57] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-02-29-09-06">2024-02-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-02-29 09:06:02.074094</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-02-29 09:06:07.255756</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:06:02] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:06:03] Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[09:06:04] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:06:06] Committing batch 1 consisting of 62 files                 base.py:291
[09:06:07] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-02-28-10-40">2024-02-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-02-28 10:40:28.610601</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-02-28 10:40:33.876594</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:40:28] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:40:29] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[10:40:30] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[10:40:32] Committing batch 1 consisting of 62 files                 base.py:291
[10:40:33] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-02-27-08-43">2024-02-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-02-27 08:43:02.242996</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-02-27 08:43:07.445636</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:43:02] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:43:03] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[08:43:04] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[08:43:06] Committing batch 1 consisting of 62 files                 base.py:291
[08:43:07] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-02-26-09-18">2024-02-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-02-26 09:18:38.656912</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-02-26 09:18:43.715447</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:18:38] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
[09:18:39] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:18:40] ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:18:42] Committing batch 1 consisting of 62 files                 base.py:291
[09:18:43] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-02-25-09-56">2024-02-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-02-25 09:56:50.196981</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-02-25 09:56:54.865831</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:56:50] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:56:51] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[09:56:53] Committing batch 1 consisting of 62 files                 base.py:291
[09:56:54] Finished attempting to scrape: BRM                        base.py:339
</pre>
  

  


  <h2 id="2024-02-24-10-30">2024-02-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>133 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-02-24 10:30:03.816562</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-02-24 10:32:17.579626</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f503c531240>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='moderngovwebpublic.bromsgrove.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f503c531240>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='moderngovwebpublic.bromsgrove.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f503c531240>, 'Connection to moderngovwebpublic.bromsgrove.gov.uk timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:30:03] Fetching Scraper for: BRM                              handlers.py:23
           Begin attempting to scrape: BRM                        handlers.py:27
[10:30:04] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[10:30:05] ...found 31 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 31 files in Councillors/raw                      base.py:219
           ...found 63 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 63 files               base.py:230
[10:30:06] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://moderngovwebpublic.bromsgrove.gov.uk/mgWebService.a           
           smx/GetCouncillorsByWard                                             
[10:32:17] HTTPConnectionPool(host='moderngovwebpublic.bromsgrove handlers.py:36
           .gov.uk', port=80): Max retries exceeded with url:                   
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f503c531240>, 'Connection to                            
           moderngovwebpublic.bromsgrove.gov.uk timed out.                      
           (connect timeout=None)'))                                            
           Finished attempting to scrape: BRM                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
