<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-14-12-09">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 12:09:51.999476</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 12:10:03.738704</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:09:51] Fetching Scraper for: CRW                              handlers.py:22
[12:09:52] Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
[12:09:53] ...found 36 files in CRW/raw                              base.py:202
           ...found 72 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 72 files               base.py:211
[12:09:59] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[12:10:01] Committing batch 1 consisting of 72 files                 base.py:269
[12:10:03] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-13-11-26">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:26:33.153139</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:26:45.575141</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:26:33] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
[11:26:34] Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:26:37] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:26:40] Committing batch 1 consisting of 72 files                 base.py:269
[11:26:45] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-12-11-58">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 11:58:45.064719</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 11:58:55.508512</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:58:55] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-11-11-31">2022-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-11 11:31:44.865201</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-11 11:31:52.916808</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:31:44] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:31:45] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:31:48] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:31:51] Committing batch 1 consisting of 72 files                 base.py:269
[11:31:52] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-10-11-38">2022-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-10 11:38:18.096825</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-10 11:38:23.182510</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:38:18] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
[11:38:19] Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:38:22] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:38:23] No new councillor data found.                             base.py:317
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-09-11-51">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 11:51:23.434918</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 11:51:44.498834</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:51:44] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-08-12-07">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>28 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 12:07:25.260499</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 12:07:54.081356</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:07:50] Created log commit                                        base.py:376
           d1d8c7fba65fcc39e48187204bd7787d8edc4933                             
           Attempting to create merge commit...                      base.py:281
[12:07:53] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[12:07:54] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-07-11-22">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 11:22:38.438836</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 11:22:52.511206</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:22:38] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:22:39] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:22:40] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:22:43] Committing batch 1 consisting of 72 files                 base.py:269
[11:22:52] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-06-18-35">2022-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>24 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-06 18:35:23.066188</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-06 18:35:47.786319</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:35:23] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 72 files in CRW                                  base.py:202
[18:35:24] Deleting batch no. 1 consisting of 72 files               base.py:211
[18:35:25] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[18:35:26] Committing batch 1 consisting of 72 files                 base.py:269
[18:35:32] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 72 files                 base.py:269
[18:35:47] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-06-17-49">2022-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-06 17:49:16.075450</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-06 17:49:21.176170</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:49:16] Fetching Scraper for: CRW                              handlers.py:21
           Begin attempting to scrape: CRW                        handlers.py:24
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[17:49:18] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[17:49:19] Committing batch 1 consisting of 72 files                 base.py:269
[17:49:21] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-06-00-04">2022-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-06 00:04:56.991045</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-06 00:05:04.094682</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:04:56] Fetching Scraper for: CRW                              handlers.py:21
[00:04:57] Begin attempting to scrape: CRW                        handlers.py:24
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
[00:04:58] ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 72 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 72 files               base.py:211
[00:05:00] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:05:02] Committing batch 1 consisting of 72 files                 base.py:269
[00:05:04] No new councillor data found.                             base.py:317
           Finished attempting to scrape: CRW                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
