<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-04-02-12-07">2022-04-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>26 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-02 12:07:07.333258</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-02 12:07:33.848532</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:07:17] Created log commit                                        base.py:376
           e894e757223f5a3278406ebfd04ec192cf5d6cc2                             
           Attempting to create merge commit...                      base.py:281
[12:07:33] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-04-01-11-43">2022-04-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-01 11:43:35.013513</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-01 11:43:49.494739</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:43:45] Created log commit                                        base.py:376
           71ecad4481fdb9de2fc7914e83e3da480c91b216                             
           Attempting to create merge commit...                      base.py:281
[11:43:49] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-31-12-01">2022-03-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-31 12:01:05.144686</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-31 12:01:24.155661</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:01:12] Created log commit                                        base.py:376
           74ef7c7e12c6f23b9b8572569a3f986150b0ad97                             
           Attempting to create merge commit...                      base.py:281
[12:01:23] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
[12:01:24] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-30-11-55">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 11:55:06.346552</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 11:55:14.751458</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:55:06] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
[11:55:07] ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:55:10] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:55:12] Committing batch 1 consisting of 72 files                 base.py:269
[11:55:14] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-30-00-01">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 00:01:09.001931</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 00:01:16.352232</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:01:09] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[00:01:11] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:01:13] Committing batch 1 consisting of 72 files                 base.py:269
[00:01:16] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-28-11-41">2022-03-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-28 11:41:13.792715</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-28 11:41:20.229646</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:41:13] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:41:14] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
[11:41:15] ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:41:19] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:41:20] No new councillor data found.                             base.py:317
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-27-12-04">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>24 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 12:04:41.342502</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 12:05:05.479756</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:04:47] Created log commit                                        base.py:376
           5b39ba41edab907d6b1b0277cd56d134a4ac5f83                             
           Attempting to create merge commit...                      base.py:281
[12:05:05] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-26-11-43">2022-03-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-26 11:43:14.231639</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-26 11:43:22.045554</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:43:14] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
[11:43:15] ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:43:16] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:43:19] Committing batch 1 consisting of 72 files                 base.py:269
[11:43:22] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-25-11-43">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 11:43:09.130255</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 11:43:29.635870</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:43:09] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
[11:43:10] Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:43:16] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:43:17] Committing batch 1 consisting of 72 files                 base.py:269
[11:43:29] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-24-11-16">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 11:16:02.235043</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 11:16:12.789123</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:02] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:16:03] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:16:08] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:16:11] Committing batch 1 consisting of 72 files                 base.py:269
[11:16:12] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-23-11-43">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 11:43:04.582526</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 11:43:23.922726</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:43:23] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-22-11-45">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 11:45:26.123075</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 11:45:42.358467</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:45:26] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:45:28] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:45:29] Committing batch 1 consisting of 72 files                 base.py:269
[11:45:42] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-21-12-00">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 12:00:05.320064</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 12:00:11.553648</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:00:05] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
[12:00:06] ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 72 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 72 files               base.py:211
[12:00:07] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[12:00:09] Committing batch 1 consisting of 72 files                 base.py:269
[12:00:11] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-20-11-51">2022-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-20 11:51:03.339376</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-20 11:51:10.148190</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:51:03] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:51:04] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:51:05] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:51:07] Committing batch 1 consisting of 72 files                 base.py:269
[11:51:10] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-19-11-45">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:45:53.342735</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:46:02.195359</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:45:53] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:45:54] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:45:55] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:45:58] Committing batch 1 consisting of 72 files                 base.py:269
[11:46:02] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-18-11-29">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:29:18.679974</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:29:32.768585</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:29:28] Created log commit                                        base.py:376
           8f559d1ef480ff9c359e168e2ffb75934c238abd                             
           Attempting to create merge commit...                      base.py:281
[11:29:32] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-17-11-37">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:37:24.825219</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:37:39.126921</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:37:24] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:37:25] Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:37:29] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:37:31] Committing batch 1 consisting of 72 files                 base.py:269
[11:37:36] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 72 files                 base.py:269
[11:37:39] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-16-11-52">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:52:55.351687</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:53:01.746505</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:52:55] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
[11:52:56] ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:52:58] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:52:59] Committing batch 1 consisting of 72 files                 base.py:269
[11:53:01] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-15-11-33">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:33:50.493210</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:34:06.480170</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:34:02] Created log commit                                        base.py:376
           1a1826040549bedb865493be09b7f08917c7e023                             
           Attempting to create merge commit...                      base.py:281
[11:34:06] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-14-12-09">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 12:09:51.999476</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 12:10:03.738704</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:09:51] Fetching Scraper for: CRW                              handlers.py:22
[12:09:52] Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
           Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
[12:09:53] ...found 36 files in CRW/raw                              base.py:202
           ...found 72 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 72 files               base.py:211
[12:09:59] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[12:10:01] Committing batch 1 consisting of 72 files                 base.py:269
[12:10:03] Finished attempting to scrape: CRW                        base.py:319
</pre>

  <h2 id="2022-03-13-11-26">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:26:33.153139</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:26:45.575141</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:26:33] Fetching Scraper for: CRW                              handlers.py:22
           Begin attempting to scrape: CRW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in CRW...                               base.py:186
[11:26:34] Getting all files in CRW/json...                          base.py:186
           ...found 36 files in CRW/json                             base.py:202
           Getting all files in CRW/raw...                           base.py:186
           ...found 36 files in CRW/raw                              base.py:202
           ...found 73 files in CRW                                  base.py:202
           Deleting batch no. 1 consisting of 73 files               base.py:211
[11:26:37] ...data deleted.                                          base.py:241
           Scraping from http://democracy.crawley.gov.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:26:40] Committing batch 1 consisting of 72 files                 base.py:269
[11:26:45] Finished attempting to scrape: CRW                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
