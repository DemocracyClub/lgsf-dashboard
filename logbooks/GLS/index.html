<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-07-01-09-15">2024-07-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-07-01 09:15:46.034204</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-07-01 09:16:03.510042</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [Errno 110] Connection timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:15:46] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:15:47] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:16:03] [Errno 110] Connection timed out                       handlers.py:36
           Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-30-09-23">2024-06-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-30 09:23:39.728244</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-30 09:23:57.387487</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [Errno 110] Connection timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:23:39] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[09:23:40] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:23:41] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:23:57] [Errno 110] Connection timed out                       handlers.py:36
           Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-29-09-14">2024-06-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-29 09:14:21.598847</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-29 09:14:39.322940</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [Errno 110] Connection timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:14:21] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[09:14:22] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:14:23] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:14:39] [Errno 110] Connection timed out                       handlers.py:36
           Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-28-10-42">2024-06-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-28 10:42:37.024507</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-28 10:42:54.608301</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [Errno 110] Connection timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:42:37] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:42:38] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[10:42:54] [Errno 110] Connection timed out                       handlers.py:36
           Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-27-08-37">2024-06-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>18 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-27 08:37:37.949317</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-27 08:37:56.781237</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [Errno 110] Connection timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:37:37] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[08:37:38] Deleting existing data...                                 base.py:257
[08:37:39] Getting all files in Councillors...                       base.py:209
[08:37:40] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:37:56] [Errno 110] Connection timed out                       handlers.py:36
           Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-26-09-02">2024-06-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-26 09:02:38.891834</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-26 09:02:59.162758</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [Errno 110] Connection timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:02:38] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[09:02:40] Deleting existing data...                                 base.py:257
[09:02:41] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:02:42] Deleting batch no. 2 consisting of 7 files                base.py:236
[09:02:43] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:02:58] [Errno 110] Connection timed out                       handlers.py:36
[09:02:59] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-25-10-03">2024-06-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>30 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-25 10:03:01.065362</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-25 10:03:31.519034</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:03:01] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:03:02] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:03:03] Deleting batch no. 2 consisting of 7 files                base.py:236
[10:03:04] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[10:03:29] Committing batch 1 consisting of 92 files                 base.py:297
[10:03:30] Committing batch 2 consisting of 14 files                 base.py:297
[10:03:31] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-24-08-47">2024-06-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-24 08:47:30.153705</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-24 08:47:40.977649</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:47:30] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:47:31] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:47:32] Deleting batch no. 2 consisting of 7 files                base.py:236
[08:47:33] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:47:38] Committing batch 1 consisting of 92 files                 base.py:297
[08:47:39] Committing batch 2 consisting of 14 files                 base.py:297
[08:47:40] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-23-10-16">2024-06-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>33 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-23 10:16:24.545177</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-23 10:16:57.610804</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:16:24] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[10:16:25] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:16:26] Deleting batch no. 2 consisting of 7 files                base.py:236
[10:16:27] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[10:16:55] Committing batch 1 consisting of 92 files                 base.py:297
[10:16:56] Committing batch 2 consisting of 14 files                 base.py:297
[10:16:57] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-22-08-25">2024-06-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-22 08:25:54.759470</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-22 08:26:03.687423</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:25:54] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[08:25:55] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[08:25:56] ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 7 files                base.py:236
[08:25:57] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:26:01] Committing batch 1 consisting of 92 files                 base.py:297
[08:26:02] Committing batch 2 consisting of 14 files                 base.py:297
[08:26:03] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-21-09-01">2024-06-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-21 09:01:40.983936</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-21 09:01:53.905232</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:01:40] Fetching Scraper for: GLS                              handlers.py:23
[09:01:41] Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:01:42] Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:01:43] Deleting batch no. 2 consisting of 7 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:01:51] Committing batch 1 consisting of 92 files                 base.py:297
[09:01:52] Committing batch 2 consisting of 14 files                 base.py:297
[09:01:53] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-20-08-41">2024-06-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-20 08:41:02.148356</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-20 08:41:10.927505</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:41:02] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:41:03] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:41:04] Deleting batch no. 2 consisting of 7 files                base.py:236
[08:41:05] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:41:08] Committing batch 1 consisting of 92 files                 base.py:297
[08:41:09] Committing batch 2 consisting of 14 files                 base.py:297
[08:41:10] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-19-09-22">2024-06-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-19 09:22:03.752959</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-19 09:22:12.652026</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:22:03] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[09:22:04] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[09:22:05] ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:22:06] Deleting batch no. 2 consisting of 7 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:22:10] Committing batch 1 consisting of 92 files                 base.py:297
[09:22:11] Committing batch 2 consisting of 14 files                 base.py:297
[09:22:12] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-18-08-38">2024-06-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-18 08:38:40.150599</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-18 08:38:50.762080</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:38:40] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:38:41] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:38:42] Deleting batch no. 2 consisting of 7 files                base.py:236
[08:38:43] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:38:48] Committing batch 1 consisting of 92 files                 base.py:297
[08:38:49] Committing batch 2 consisting of 14 files                 base.py:297
[08:38:50] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-17-09-02">2024-06-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-17 09:02:08.442838</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-17 09:02:21.691221</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:02:08] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:02:09] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:02:10] Deleting batch no. 2 consisting of 7 files                base.py:236
[09:02:11] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:02:19] Committing batch 1 consisting of 92 files                 base.py:297
[09:02:20] Committing batch 2 consisting of 14 files                 base.py:297
[09:02:21] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-16-09-48">2024-06-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-16 09:48:13.468227</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-16 09:48:28.002717</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:48:13] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:48:14] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:48:15] Deleting batch no. 2 consisting of 7 files                base.py:236
[09:48:16] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:48:25] Committing batch 1 consisting of 92 files                 base.py:297
[09:48:26] Committing batch 2 consisting of 14 files                 base.py:297
[09:48:28] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-15-08-42">2024-06-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-15 08:42:19.322549</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-15 08:42:35.659640</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:42:19] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:42:20] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:42:21] Deleting batch no. 2 consisting of 7 files                base.py:236
[08:42:22] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:42:33] Committing batch 1 consisting of 92 files                 base.py:297
[08:42:34] Committing batch 2 consisting of 14 files                 base.py:297
[08:42:35] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-14-10-21">2024-06-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-14 10:21:47.855602</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-14 10:22:01.073087</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:21:47] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[10:21:48] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[10:21:49] ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:21:50] Deleting batch no. 2 consisting of 7 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[10:21:58] Committing batch 1 consisting of 92 files                 base.py:297
[10:22:00] Committing batch 2 consisting of 14 files                 base.py:297
[10:22:01] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-13-08-44">2024-06-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-13 08:44:58.632603</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-13 08:45:09.072306</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:44:58] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
[08:44:59] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[08:45:00] ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 7 files                base.py:236
[08:45:01] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[08:45:07] Committing batch 1 consisting of 92 files                 base.py:297
[08:45:08] Committing batch 2 consisting of 14 files                 base.py:297
[08:45:09] Finished attempting to scrape: GLS                        base.py:345
</pre>
  

  


  <h2 id="2024-06-12-08-59">2024-06-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-06-12 08:59:54.373172</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-06-12 09:00:03.806344</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:59:54] Fetching Scraper for: GLS                              handlers.py:23
           Begin attempting to scrape: GLS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:59:55] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 53 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 53 files in Councillors/raw                      base.py:225
           ...found 107 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:59:56] Deleting batch no. 2 consisting of 7 files                base.py:236
[08:59:57] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://glostext.gloucestershire.gov.uk//mgWebService.asmx/           
           GetCouncillorsByWard                                                 
[09:00:01] Committing batch 1 consisting of 92 files                 base.py:297
[09:00:02] Committing batch 2 consisting of 14 files                 base.py:297
[09:00:03] Finished attempting to scrape: GLS                        base.py:345
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
