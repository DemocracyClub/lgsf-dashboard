<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-11-15-10-20">2024-11-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-15 10:20:10.774797</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-15 10:20:28.023227</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:20:10] Fetching Scraper for: RUH                              handlers.py:23
[10:20:20] Begin attempting to scrape: RUH                        handlers.py:27
[10:20:22] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[10:20:23] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:20:26] Committing batch 1 consisting of 78 files                 base.py:297
[10:20:28] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-14-10-34">2024-11-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-14 10:34:39.125392</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-14 10:34:44.175470</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:34:39] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:34:40] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:34:41] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:34:43] Committing batch 1 consisting of 78 files                 base.py:297
[10:34:44] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-13-10-22">2024-11-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-13 10:22:47.993379</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-13 10:22:52.943935</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:22:47] Fetching Scraper for: RUH                              handlers.py:23
[10:22:48] Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[10:22:49] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:22:50] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:22:51] Committing batch 1 consisting of 78 files                 base.py:297
[10:22:52] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-12-08-53">2024-11-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-12 08:53:41.759937</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-12 08:53:50.809395</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:53:41] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[08:53:42] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
[08:53:43] Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
[08:53:44] Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:53:49] Committing batch 1 consisting of 78 files                 base.py:297
[08:53:50] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-11-09-58">2024-11-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-11 09:58:47.124874</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-11 09:58:52.173374</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:58:47] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:58:48] Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:58:49] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:58:51] Committing batch 1 consisting of 78 files                 base.py:297
[09:58:52] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-10-08-24">2024-11-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-10 08:24:09.991411</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-10 08:24:14.929780</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:09] Fetching Scraper for: RUH                              handlers.py:23
[08:24:10] Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[08:24:11] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:24:13] Committing batch 1 consisting of 78 files                 base.py:297
[08:24:14] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-09-09-05">2024-11-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-09 09:05:26.424608</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-09 09:05:35.347209</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:05:26] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:05:27] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:05:28] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:05:34] Committing batch 1 consisting of 78 files                 base.py:297
[09:05:35] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-08-08-47">2024-11-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-08 08:47:11.261087</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-08 08:47:16.851025</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCouncillorsByWard'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:47:11] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:47:12] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[08:47:13] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:47:16] Server error '503 Service Unavailable' for url         handlers.py:36
           'https://democracy.rushmoor.gov.uk//mgWebService.asmx/               
           GetCouncillorsByWard'                                                
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/503                                                               
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-07-09-32">2024-11-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-07 09:32:15.913562</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-07 09:32:22.669475</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:32:15] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[09:32:16] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:32:17] Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:32:18] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:32:21] Committing batch 1 consisting of 78 files                 base.py:297
[09:32:22] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-06-10-23">2024-11-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-06 10:23:57.374298</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-06 10:24:02.790189</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:23:57] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:23:58] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:23:59] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:24:01] Committing batch 1 consisting of 78 files                 base.py:297
[10:24:02] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-05-10-19">2024-11-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-05 10:19:42.257004</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-05 10:19:47.712370</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:19:42] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:19:43] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:19:44] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:19:46] Committing batch 1 consisting of 78 files                 base.py:297
[10:19:47] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-04-08-46">2024-11-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-04 08:46:39.294628</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-04 08:46:44.679430</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:46:39] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:46:40] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[08:46:41] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:46:43] Committing batch 1 consisting of 78 files                 base.py:297
[08:46:44] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-03-09-34">2024-11-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-03 09:34:38.896208</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-03 09:34:44.526621</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:34:38] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[09:34:39] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[09:34:40] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:34:43] Committing batch 1 consisting of 78 files                 base.py:297
[09:34:44] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-02-08-52">2024-11-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-02 08:52:02.640548</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-02 08:52:08.630631</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:52:02] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[08:52:03] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[08:52:04] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:52:07] Committing batch 1 consisting of 78 files                 base.py:297
[08:52:08] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-01-09-10">2024-11-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-01 09:10:46.832846</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-01 09:10:51.730843</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:46] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[09:10:47] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:10:48] ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:10:50] Committing batch 1 consisting of 78 files                 base.py:297
[09:10:51] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-31-10-00">2024-10-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-31 10:00:44.494067</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-31 10:00:49.639634</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:00:44] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:00:45] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:00:46] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:00:48] Committing batch 1 consisting of 78 files                 base.py:297
[10:00:49] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-30-09-15">2024-10-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-30 09:15:26.515598</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-30 09:15:59.392526</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:15:26] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:15:27] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:15:28] ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:15:59] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-29-08-44">2024-10-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-29 08:44:23.824893</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-29 08:44:30.638921</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:44:23] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[08:44:24] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:44:25] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:44:29] Committing batch 1 consisting of 78 files                 base.py:297
[08:44:30] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-28-08-26">2024-10-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-28 08:26:37.117771</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-28 08:27:09.496499</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:26:37] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:26:38] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:27:09] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-27-09-25">2024-10-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-27 09:25:07.053139</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-27 09:25:39.835341</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:25:07] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:25:08] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:25:09] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:25:39] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright Â© 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
