<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-11-06-10-23">2024-11-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-06 10:23:57.374298</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-06 10:24:02.790189</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:23:57] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:23:58] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:23:59] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:24:01] Committing batch 1 consisting of 78 files                 base.py:297
[10:24:02] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-05-10-19">2024-11-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-05 10:19:42.257004</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-05 10:19:47.712370</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:19:42] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:19:43] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:19:44] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:19:46] Committing batch 1 consisting of 78 files                 base.py:297
[10:19:47] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-04-08-46">2024-11-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-04 08:46:39.294628</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-04 08:46:44.679430</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:46:39] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:46:40] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[08:46:41] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:46:43] Committing batch 1 consisting of 78 files                 base.py:297
[08:46:44] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-03-09-34">2024-11-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-03 09:34:38.896208</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-03 09:34:44.526621</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:34:38] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[09:34:39] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[09:34:40] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:34:43] Committing batch 1 consisting of 78 files                 base.py:297
[09:34:44] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-02-08-52">2024-11-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-02 08:52:02.640548</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-02 08:52:08.630631</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:52:02] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[08:52:03] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[08:52:04] ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:52:07] Committing batch 1 consisting of 78 files                 base.py:297
[08:52:08] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-11-01-09-10">2024-11-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-11-01 09:10:46.832846</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-11-01 09:10:51.730843</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:46] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[09:10:47] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:10:48] ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:10:50] Committing batch 1 consisting of 78 files                 base.py:297
[09:10:51] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-31-10-00">2024-10-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-31 10:00:44.494067</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-31 10:00:49.639634</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:00:44] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:00:45] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:00:46] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:00:48] Committing batch 1 consisting of 78 files                 base.py:297
[10:00:49] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-30-09-15">2024-10-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-30 09:15:26.515598</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-30 09:15:59.392526</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:15:26] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:15:27] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:15:28] ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:15:59] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-29-08-44">2024-10-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-29 08:44:23.824893</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-29 08:44:30.638921</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:44:23] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[08:44:24] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:44:25] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:44:29] Committing batch 1 consisting of 78 files                 base.py:297
[08:44:30] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-28-08-26">2024-10-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-28 08:26:37.117771</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-28 08:27:09.496499</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:26:37] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:26:38] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:27:09] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-27-09-25">2024-10-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-27 09:25:07.053139</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-27 09:25:39.835341</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/opt/python/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/opt/python/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/opt/python/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/opt/python/httpcore/_backends/sync.py", line 124, in read
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:25:07] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:25:08] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:25:09] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:25:39] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-26-09-56">2024-10-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-26 09:56:29.627429</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-26 09:56:39.688587</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:56:29] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:56:30] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:56:31] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:56:38] Committing batch 1 consisting of 78 files                 base.py:297
[09:56:39] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-25-09-14">2024-10-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-25 09:14:48.275513</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-25 09:14:55.286337</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:14:48] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:14:49] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:14:50] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:14:54] Committing batch 1 consisting of 78 files                 base.py:297
[09:14:55] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-24-10-02">2024-10-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-24 10:02:16.201121</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-24 10:02:21.792372</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:02:16] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:02:17] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:02:18] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:02:20] Committing batch 1 consisting of 78 files                 base.py:297
[10:02:21] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-23-10-49">2024-10-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-23 10:49:04.453621</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-23 10:49:10.123935</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:49:04] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:49:05] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:49:06] ...data deleted.                                          base.py:264
[10:49:07] Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:49:09] Committing batch 1 consisting of 78 files                 base.py:297
[10:49:10] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-22-08-19">2024-10-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-22 08:19:25.267147</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-22 08:19:31.864811</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:19:25] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:19:26] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[08:19:27] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:19:30] Committing batch 1 consisting of 78 files                 base.py:297
[08:19:31] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-21-10-18">2024-10-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-21 10:18:43.381777</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-21 10:18:50.376083</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:18:43] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:18:44] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[10:18:45] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[10:18:49] Committing batch 1 consisting of 78 files                 base.py:297
[10:18:50] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-20-08-55">2024-10-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-20 08:55:00.581515</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-20 08:55:05.658002</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:55:00] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
[08:55:01] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[08:55:02] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[08:55:04] Committing batch 1 consisting of 78 files                 base.py:297
[08:55:05] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-19-09-36">2024-10-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-19 09:36:00.518812</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-19 09:36:06.379583</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:36:00] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:36:01] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:36:02] ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:36:05] Committing batch 1 consisting of 78 files                 base.py:297
[09:36:06] Finished attempting to scrape: RUH                        base.py:345
</pre>
  

  


  <h2 id="2024-10-18-09-45">2024-10-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-10-18 09:45:42.218870</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-10-18 09:45:48.889087</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:45:42] Fetching Scraper for: RUH                              handlers.py:23
           Begin attempting to scrape: RUH                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:45:43] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 39 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 39 files in Councillors/raw                      base.py:225
           ...found 79 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 79 files               base.py:236
[09:45:44] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.rushmoor.gov.uk//mgWebService.asmx/GetCo           
           uncillorsByWard                                                      
[09:45:47] Committing batch 1 consisting of 78 files                 base.py:297
[09:45:48] Finished attempting to scrape: RUH                        base.py:345
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
