<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-22-11-41">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>28 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 11:41:53.355103</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 11:42:22.315233</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:41:53] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
[11:41:54] ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:41:55] Deleting batch no. 2 consisting of 35 files               base.py:211
[11:41:59] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[11:42:03] Committing batch 1 consisting of 92 files                 base.py:269
[11:42:10] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:42:22] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-21-11-15">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>34 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 11:15:47.513968</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 11:16:21.887064</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:15:47] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
[11:15:48] ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:15:58] Deleting batch no. 2 consisting of 35 files               base.py:211
[11:16:00] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[11:16:06] Committing batch 1 consisting of 92 files                 base.py:269
[11:16:15] Committing batch 2 consisting of 42 files                 base.py:269
[11:16:21] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-20-11-53">2022-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-20 11:53:22.594829</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-20 11:53:35.146251</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:53:22] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:53:23] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
[11:53:24] ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:53:34] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:53:35] No new councillor data found.                             base.py:317
           Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-19-12-08">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 12:08:52.701919</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 12:09:08.098595</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:08:52] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[12:08:53] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 46 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 46 files in MSU/raw                              base.py:202
           ...found 93 files in MSU                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[12:08:54] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[12:08:59] Committing batch 1 consisting of 92 files                 base.py:269
[12:09:05] Committing batch 2 consisting of 42 files                 base.py:269
[12:09:08] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-18-11-36">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>23 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:36:23.967351</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:36:47.281409</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:36:23] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
[11:36:24] Deleting existing data...                                 base.py:234
           Getting all files in MSU...                               base.py:186
[11:36:25] Getting all files in MSU/raw...                           base.py:186
           ...found 35 files in MSU/raw                              base.py:202
           ...found 36 files in MSU                                  base.py:202
           Deleting batch no. 1 consisting of 36 files               base.py:211
[11:36:32] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[11:36:37] Committing batch 1 consisting of 92 files                 base.py:269
[11:36:45] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:36:47] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-17-11-42">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:42:17.170657</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:42:30.644478</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:17] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:42:24] Deleting batch no. 2 consisting of 35 files               base.py:211
[11:42:30] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-16-11-47">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>22 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:47:24.313904</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:47:47.135564</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:47:41] Created log commit                                        base.py:376
           7d94d22fcca1fdb9d7eedff7d3a73a76d217e294                             
           Attempting to create merge commit...                      base.py:281
[11:47:46] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[11:47:47] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-15-11-44">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>59 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:44:56.968555</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:45:56.865848</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:45:49] Created log commit                                        base.py:376
           338022ec1892bc34a3b94f16bb6342d674c9c11f                             
           Attempting to create merge commit...                      base.py:281
[11:45:56] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
           Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-14-11-37">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>28 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:37:36.272071</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:38:05.261777</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:37:36] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:37:37] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:37:39] Deleting batch no. 2 consisting of 35 files               base.py:211
[11:37:49] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[11:37:55] Committing batch 1 consisting of 92 files                 base.py:269
[11:37:59] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[11:38:05] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-13-11-33">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:33:42.384408</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:33:47.940196</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:33:42] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:33:44] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:33:47] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-13-00-05">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 00:05:33.283364</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 00:05:54.126874</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:05:50] Created log commit                                        base.py:376
           7ab55a6149efe7ae1dbba108a2651979beefbe8e                             
           Attempting to create merge commit...                      base.py:281
[00:05:53] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[00:05:54] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-12-00-06">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:06:47.607893</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:06:58.729346</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:06:47] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:06:48] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/raw...                           base.py:186
           ...found 35 files in MSU/raw                              base.py:202
           ...found 36 files in MSU                                  base.py:202
           Deleting batch no. 1 consisting of 36 files               base.py:211
[00:06:51] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[00:06:55] Committing batch 1 consisting of 92 files                 base.py:269
[00:06:57] Committing batch 2 consisting of 42 files                 base.py:269
[00:06:58] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-10-12-00">2022-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>29 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-10 12:00:20.416239</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-10 12:00:49.722999</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:00:49] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-09-11-27">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>34 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 11:27:10.694979</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 11:27:45.150171</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:27:38] Created log commit                                        base.py:376
           23825aa8832e1902e3142b4279d5d391ccdc8ec0                             
           Attempting to create merge commit...                      base.py:281
[11:27:44] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
[11:27:45] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-08-12-18">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 12:18:34.331684</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 12:18:55.090470</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:18:34] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in MSU...                               base.py:186
           Getting all files in MSU/raw...                           base.py:186
           ...found 35 files in MSU/raw                              base.py:202
           ...found 36 files in MSU                                  base.py:202
           Deleting batch no. 1 consisting of 36 files               base.py:211
[12:18:36] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[12:18:41] Committing batch 1 consisting of 92 files                 base.py:269
[12:18:51] Committing batch 2 consisting of 42 files                 base.py:269
[12:18:55] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-07-12-41">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 12:41:14.816983</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 12:41:29.077449</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:41:14] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[12:41:15] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:41:16] Deleting batch no. 2 consisting of 35 files               base.py:211
[12:41:17] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[12:41:25] Committing batch 1 consisting of 92 files                 base.py:269
[12:41:27] Committing batch 2 consisting of 42 files                 base.py:269
[12:41:29] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-07-00-21">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 00:21:00.933137</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 00:21:20.264737</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:21:15] Created log commit                                        base.py:376
           1b73d2baf380ee49f6c3b0e8cf2c64b82ac3a7ae                             
           Attempting to create merge commit...                      base.py:281
[00:21:19] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[00:21:20] Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-07-00-19">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 00:19:02.405893</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 00:19:14.593409</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:19:02] Fetching Scraper for: MSU                              handlers.py:22
           Begin attempting to scrape: MSU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
[00:19:03] ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 135 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:19:04] Deleting batch no. 2 consisting of 35 files               base.py:211
[00:19:14] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: MSU                        base.py:319
</pre>

  <h2 id="2022-03-05-19-58">2022-03-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-05 19:58:24.361651</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-05 19:58:46.053566</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[19:58:24] Fetching Scraper for: MSU                              handlers.py:21
           Begin attempting to scrape: MSU                        handlers.py:24
           Deleting existing data...                                 base.py:234
[19:58:25] Getting all files in MSU...                               base.py:186
           Getting all files in MSU/json...                          base.py:186
           ...found 67 files in MSU/json                             base.py:202
           Getting all files in MSU/raw...                           base.py:186
           ...found 67 files in MSU/raw                              base.py:202
           ...found 134 files in MSU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[19:58:27] Deleting batch no. 2 consisting of 34 files               base.py:211
[19:58:31] ...data deleted.                                          base.py:241
           Scraping from http://baberghmidsuffolk.moderngov.co.uk/mgW base.py:40
           ebService.asmx/GetCouncillorsByWard                                  
[19:58:36] Committing batch 1 consisting of 92 files                 base.py:269
[19:58:38] Committing batch 2 consisting of 42 files                 base.py:269
[19:58:44] An error occurred (ThrottlingException) when calling   handlers.py:33
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 42 files                 base.py:269
[19:58:46] No new councillor data found.                             base.py:317
           Finished attempting to scrape: MSU                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
