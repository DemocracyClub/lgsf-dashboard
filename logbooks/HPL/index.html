<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2025-10-02-08-32">2025-10-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-02 08:32:29.731304</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-02 08:32:32.116061</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:32:29] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:32:30] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:32:31] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
[08:32:32] Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-10-01-08-20">2025-10-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-01 08:20:45.282446</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-01 08:20:47.573065</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:20:45] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:20:46] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:20:47] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-30-08-18">2025-09-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-30 08:18:22.361143</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-30 08:18:24.928670</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:18:22] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:18:23] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:18:24] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-29-08-37">2025-09-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-29 08:37:36.792999</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-29 08:37:39.219964</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:37:36] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:37:37] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:37:38] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
[08:37:39] Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-28-09-01">2025-09-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-28 09:01:51.454625</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-28 09:01:53.961336</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:01:51] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[09:01:52] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[09:01:53] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-27-08-19">2025-09-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-27 08:19:50.427291</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-27 08:19:53.018009</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:19:50] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:19:51] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:19:52] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
[08:19:53] Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-26-08-24">2025-09-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-26 08:24:19.488992</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-26 08:24:21.887667</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:19] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:24:20] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:24:21] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-25-09-00">2025-09-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-25 09:00:25.615725</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-25 09:00:28.103208</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:00:25] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[09:00:26] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[09:00:27] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
[09:00:28] Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-24-08-43">2025-09-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-24 08:43:11.333630</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-24 08:43:13.638462</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:43:11] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:43:12] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:43:13] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-23-08-20">2025-09-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-23 08:20:26.209929</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-23 08:20:28.681586</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:20:26] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:20:27] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:20:28] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-22-08-33">2025-09-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-22 08:33:55.731710</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-22 08:33:58.307927</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:33:55] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:33:56] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:33:57] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
[08:33:58] Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-21-08-54">2025-09-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-21 08:54:26.954575</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-21 08:54:29.415180</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:54:26] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:54:27] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:54:28] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:54:29] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-20-08-39">2025-09-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-20 08:39:45.984227</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-20 08:39:48.319161</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:39:45] Fetching Scraper for: HPL                              handlers.py:23
[08:39:46] Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:39:47] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
[08:39:48] Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-19-08-24">2025-09-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-19 08:24:24.042304</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-19 08:24:26.397016</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:24] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:24:25] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
[08:24:26] Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-18-09-06">2025-09-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-18 09:06:24.688718</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-18 09:06:27.079383</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:06:24] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[09:06:25] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[09:06:26] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
[09:06:27] Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-17-08-25">2025-09-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-17 08:25:09.083008</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-17 08:25:11.884342</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:25:09] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:25:10] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:25:11] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-16-08-55">2025-09-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-16 08:55:31.660495</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-16 08:55:34.129973</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:55:31] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:55:32] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:55:33] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
[08:55:34] Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-15-08-33">2025-09-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-15 08:33:12.025283</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-15 08:33:15.362165</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:33:12] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[08:33:13] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:33:14] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:33:15] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
           Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-14-09-00">2025-09-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-14 09:00:29.898421</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-14 09:00:32.532916</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:00:29] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
[09:00:30] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[09:00:31] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
[09:00:32] Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-13-08-23">2025-09-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-13 08:23:28.016684</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-13 08:23:30.306551</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 61, in run
    for councillor_html in self.get_councillors():
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 167, in get_councillors
    container = self.get_list_container()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 158, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 147, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 58, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://www.hartlepool.gov.uk/councillors/name'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:23:28] Fetching Scraper for: HPL                              handlers.py:23
           Begin attempting to scrape: HPL                        handlers.py:27
           Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:23:29] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           https://www.hartlepool.gov.uk/councillors/name                       
[08:23:30] Client error '404 Not Found' for url                   handlers.py:36
           'https://www.hartlepool.gov.uk/councillors/name'                     
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/404                                                               
           Finished attempting to scrape: HPL                        base.py:351
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
