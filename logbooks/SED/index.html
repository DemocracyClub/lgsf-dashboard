<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-20-11-13">2022-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-20 11:13:47.870312</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-20 11:14:07.617570</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:13:47] Fetching Scraper for: SED                              handlers.py:22
[11:13:51] Begin attempting to scrape: SED                        handlers.py:25
[11:13:52] Deleting existing data...                                 base.py:234
[11:13:53] Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:13:54] Deleting batch no. 2 consisting of 29 files               base.py:211
[11:13:56] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[11:13:59] Committing batch 1 consisting of 92 files                 base.py:269
[11:14:03] Committing batch 2 consisting of 36 files                 base.py:269
[11:14:07] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-19-11-52">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:52:56.725236</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:53:12.533966</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:52:56] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:52:57] Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:53:03] Deleting batch no. 2 consisting of 29 files               base.py:211
[11:53:06] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[11:53:09] Committing batch 1 consisting of 92 files                 base.py:269
[11:53:11] Committing batch 2 consisting of 36 files                 base.py:269
[11:53:12] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-18-11-21">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:21:22.861100</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:21:29.492134</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:21:22] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:21:23] Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
[11:21:24] ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:21:29] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-17-11-35">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>31 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:35:52.482758</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:36:24.362066</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:52] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:35:53] Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:35:55] Deleting batch no. 2 consisting of 29 files               base.py:211
[11:36:05] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[11:36:09] Committing batch 1 consisting of 92 files                 base.py:269
[11:36:12] Committing batch 2 consisting of 36 files                 base.py:269
[11:36:20] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 36 files                 base.py:269
[11:36:24] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-16-11-19">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:19:43.222018</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:19:53.733027</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:19:43] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 46 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
[11:19:44] ...found 46 files in SED/raw                              base.py:202
           ...found 92 files in SED                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[11:19:46] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[11:19:49] Committing batch 1 consisting of 92 files                 base.py:269
[11:19:51] Committing batch 2 consisting of 36 files                 base.py:269
[11:19:53] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-15-11-29">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:29:34.238168</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:29:47.523138</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:29:34] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
[11:29:35] ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:29:36] Deleting batch no. 2 consisting of 29 files               base.py:211
[11:29:47] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-14-11-46">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:46:42.387921</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:46:56.362585</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:46:42] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           Getting all files in SED/raw...                           base.py:186
[11:46:43] ...found 29 files in SED/raw                              base.py:202
           ...found 30 files in SED                                  base.py:202
           Deleting batch no. 1 consisting of 30 files               base.py:211
[11:46:45] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[11:46:50] Committing batch 1 consisting of 92 files                 base.py:269
[11:46:52] Committing batch 2 consisting of 36 files                 base.py:269
[11:46:56] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-14-00-01">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>26 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 00:01:23.988958</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 00:01:50.407068</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:01:45] Created log commit                                        base.py:376
           ea51ffb81330d498dd2d7603f21582cde946aa47                             
           Attempting to create merge commit...                      base.py:281
[00:01:50] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-11-34">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>25 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 11:34:48.137529</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 11:35:13.621148</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:07] Created log commit                                        base.py:376
           e0537c33d0e60d4c1eab30083d8fbd353b0f67fe                             
           Attempting to create merge commit...                      base.py:281
[11:35:13] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-21">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:21:24.664940</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:21:34.126217</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:21:24] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
[00:21:25] ...found 1 files in SED                                   base.py:202
           Deleting batch no. 1 consisting of 1 files                base.py:211
[00:21:26] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:21:30] Committing batch 1 consisting of 92 files                 base.py:269
[00:21:32] Committing batch 2 consisting of 36 files                 base.py:269
[00:21:34] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-17">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:17:46.072190</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:19:57.755173</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>None: Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by None)</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:17:46] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
[00:17:47] ...found 1 files in SED                                   base.py:202
           Deleting batch no. 1 consisting of 1 files                base.py:211
[00:17:48] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:19:57] HTTPSConnectionPool(host='democracy.westsuffolk.gov.uk handlers.py:34
           ', port=443): Max retries exceeded with url:                         
           /mgWebService.asmx/GetCouncillorsByWard (Caused by New               
           ConnectionError('<urllib3.connection.HTTPSConnection                 
           object at 0x7f3da46220a0>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-16">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:16:51.931263</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:19:03.522485</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>None: Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by None)</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:16:51] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
[00:16:52] Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           SED Does not exist                                        base.py:206
           ...no data to delete.                                     base.py:238
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:19:03] HTTPSConnectionPool(host='democracy.westsuffolk.gov.uk handlers.py:34
           ', port=443): Max retries exceeded with url:                         
           /mgWebService.asmx/GetCouncillorsByWard (Caused by New               
           ConnectionError('<urllib3.connection.HTTPSConnection                 
           object at 0x7f1b4faeed30>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-15">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:15:24.478573</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:17:35.794084</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>None: Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by None)</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:15:24] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           ...found 1 files in SED                                   base.py:202
           Deleting batch no. 1 consisting of 1 files                base.py:211
[00:15:25] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:17:35] HTTPSConnectionPool(host='democracy.westsuffolk.gov.uk handlers.py:34
           ', port=443): Max retries exceeded with url:                         
           /mgWebService.asmx/GetCouncillorsByWard (Caused by New               
           ConnectionError('<urllib3.connection.HTTPSConnection                 
           object at 0x7f633b5c1e80>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-10">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>133 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:10:53.643352</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:13:06.830543</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>None: Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by None)</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:10:53] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
[00:10:54] Deleting existing data...                                 base.py:234
[00:10:55] Getting all files in SED...                               base.py:186
           ...found 1 files in SED                                   base.py:202
           Deleting batch no. 1 consisting of 1 files                base.py:211
[00:10:56] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:13:06] HTTPSConnectionPool(host='democracy.westsuffolk.gov.uk handlers.py:34
           ', port=443): Max retries exceeded with url:                         
           /mgWebService.asmx/GetCouncillorsByWard (Caused by New               
           ConnectionError('<urllib3.connection.HTTPSConnection                 
           object at 0x7fc3e19fc6d0>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-09">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:09:03.531143</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:11:15.427384</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>None: Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by None)</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:09:03] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
[00:09:04] SED Does not exist                                        base.py:206
           ...no data to delete.                                     base.py:238
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:11:15] HTTPSConnectionPool(host='democracy.westsuffolk.gov.uk handlers.py:34
           ', port=443): Max retries exceeded with url:                         
           /mgWebService.asmx/GetCouncillorsByWard (Caused by New               
           ConnectionError('<urllib3.connection.HTTPSConnection                 
           object at 0x7f88c01e7100>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-12-00-08">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>130 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 00:08:20.709758</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 00:10:31.511099</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>None: Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by None)</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:08:20] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:08:21] Getting all files in SED...                               base.py:186
           SED Does not exist                                        base.py:206
           ...no data to delete.                                     base.py:238
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:10:31] HTTPSConnectionPool(host='democracy.westsuffolk.gov.uk handlers.py:34
           ', port=443): Max retries exceeded with url:                         
           /mgWebService.asmx/GetCouncillorsByWard (Caused by New               
           ConnectionError('<urllib3.connection.HTTPSConnection                 
           object at 0x7f9ce0c776a0>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-10-12-03">2022-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>27 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-10 12:03:43.517682</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-10 12:04:10.561916</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:03:43] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
[12:03:44] Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 128 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:03:52] Deleting batch no. 2 consisting of 28 files               base.py:211
[12:03:53] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[12:03:58] Committing batch 1 consisting of 92 files                 base.py:269
[12:04:07] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[12:04:10] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-09-11-40">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 11:40:36.253834</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 11:40:46.931000</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:40:36] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           Getting all files in SED/raw...                           base.py:186
           ...found 29 files in SED/raw                              base.py:202
           ...found 30 files in SED                                  base.py:202
           Deleting batch no. 1 consisting of 30 files               base.py:211
[11:40:46] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-08-11-31">2022-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-08 11:31:56.838539</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-08 11:32:07.971394</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:31:56] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:31:57] Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:32:00] Deleting batch no. 2 consisting of 29 files               base.py:211
[11:32:07] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-07-12-12">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 12:12:12.788085</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 12:12:22.897994</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:12:12] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
[12:12:13] Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 64 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
           ...found 64 files in SED/raw                              base.py:202
           ...found 129 files in SED                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:12:14] Deleting batch no. 2 consisting of 29 files               base.py:211
[12:12:15] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[12:12:19] Committing batch 1 consisting of 92 files                 base.py:269
[12:12:20] Committing batch 2 consisting of 36 files                 base.py:269
[12:12:22] Finished attempting to scrape: SED                        base.py:319
</pre>

  <h2 id="2022-03-07-00-44">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>26 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 00:44:49.288921</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 00:45:15.937452</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:44:49] Fetching Scraper for: SED                              handlers.py:22
           Begin attempting to scrape: SED                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in SED...                               base.py:186
           Getting all files in SED/json...                          base.py:186
           ...found 46 files in SED/json                             base.py:202
           Getting all files in SED/raw...                           base.py:186
[00:44:50] ...found 46 files in SED/raw                              base.py:202
           ...found 93 files in SED                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[00:44:51] ...data deleted.                                          base.py:241
           Scraping from https://democracy.westsuffolk.gov.uk/mgWebSe base.py:40
           rvice.asmx/GetCouncillorsByWard                                      
[00:44:55] Committing batch 1 consisting of 92 files                 base.py:269
[00:45:03] Committing batch 2 consisting of 36 files                 base.py:269
[00:45:15] Finished attempting to scrape: SED                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
