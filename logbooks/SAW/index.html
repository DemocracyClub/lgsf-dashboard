<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2022-05-07-14-26">2022-05-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-07 14:26:06.934489</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-07 14:26:19.159976</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:26:06] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
[14:26:07] Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[14:26:08] ...found 72 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 72 files in SAW/raw                              base.py:198
           ...found 145 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[14:26:09] Deleting batch no. 2 consisting of 45 files               base.py:207
[14:26:10] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[14:26:16] Committing batch 1 consisting of 92 files                 base.py:265
[14:26:17] Committing batch 2 consisting of 52 files                 base.py:265
[14:26:19] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-05-06-14-18">2022-05-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-06 14:18:12.033704</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-06 14:18:25.697019</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:18:12] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[14:18:13] ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[14:18:14] Deleting batch no. 2 consisting of 41 files               base.py:207
[14:18:15] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[14:18:21] Committing batch 1 consisting of 92 files                 base.py:265
[14:18:24] Committing batch 2 consisting of 52 files                 base.py:265
[14:18:25] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-05-05-12-54">2022-05-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-05 12:54:53.104520</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-05 12:55:05.798963</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:54:53] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
[12:54:54] Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:54:55] Deleting batch no. 2 consisting of 41 files               base.py:207
[12:54:56] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[12:55:02] Committing batch 1 consisting of 92 files                 base.py:265
[12:55:04] Committing batch 2 consisting of 48 files                 base.py:265
[12:55:05] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-05-04-13-04">2022-05-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-04 13:04:45.023826</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-04 13:04:56.674313</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:04:45] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[13:04:46] ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:04:47] Deleting batch no. 2 consisting of 41 files               base.py:207
[13:04:48] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[13:04:53] Committing batch 1 consisting of 92 files                 base.py:265
[13:04:55] Committing batch 2 consisting of 48 files                 base.py:265
[13:04:56] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-05-03-13-00">2022-05-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-03 13:00:33.277507</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-03 13:00:47.067152</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:00:33] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[13:00:34] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:00:36] Deleting batch no. 2 consisting of 41 files               base.py:207
[13:00:37] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[13:00:43] Committing batch 1 consisting of 92 files                 base.py:265
[13:00:45] Committing batch 2 consisting of 48 files                 base.py:265
[13:00:47] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-05-02-12-44">2022-05-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-02 12:44:46.718885</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-02 12:44:57.662336</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:44:46] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[12:44:47] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[12:44:48] ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:44:49] Deleting batch no. 2 consisting of 41 files               base.py:207
[12:44:50] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[12:44:54] Committing batch 1 consisting of 92 files                 base.py:265
[12:44:56] Committing batch 2 consisting of 48 files                 base.py:265
[12:44:57] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-05-01-14-37">2022-05-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-01 14:37:05.835576</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-01 14:37:17.432742</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:37:05] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[14:37:06] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[14:37:07] ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[14:37:08] Deleting batch no. 2 consisting of 41 files               base.py:207
[14:37:09] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[14:37:13] Committing batch 1 consisting of 92 files                 base.py:265
[14:37:15] Committing batch 2 consisting of 48 files                 base.py:265
[14:37:17] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-30-14-31">2022-04-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-30 14:31:00.554337</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-30 14:31:12.577722</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:31:00] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[14:31:01] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
[14:31:02] Deleting batch no. 1 consisting of 100 files              base.py:207
[14:31:03] Deleting batch no. 2 consisting of 41 files               base.py:207
           ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[14:31:09] Committing batch 1 consisting of 92 files                 base.py:265
[14:31:11] Committing batch 2 consisting of 48 files                 base.py:265
[14:31:12] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-29-11-36">2022-04-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-29 11:36:58.211161</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-29 11:37:08.941024</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:36:58] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
[11:36:59] Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[11:37:00] Deleting batch no. 2 consisting of 41 files               base.py:207
[11:37:01] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[11:37:05] Committing batch 1 consisting of 92 files                 base.py:265
[11:37:07] Committing batch 2 consisting of 48 files                 base.py:265
[11:37:08] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-28-11-35">2022-04-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-28 11:35:33.237898</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-28 11:35:45.536103</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:33] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
[11:35:34] Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
[11:35:35] Deleting batch no. 1 consisting of 100 files              base.py:207
           Deleting batch no. 2 consisting of 41 files               base.py:207
[11:35:37] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[11:35:42] Committing batch 1 consisting of 92 files                 base.py:265
[11:35:44] Committing batch 2 consisting of 48 files                 base.py:265
[11:35:45] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-27-11-18">2022-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-27 11:18:21.290742</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-27 11:18:33.613758</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:18:21] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[11:18:22] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[11:18:23] Deleting batch no. 2 consisting of 41 files               base.py:207
[11:18:24] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[11:18:30] Committing batch 1 consisting of 92 files                 base.py:265
[11:18:31] Committing batch 2 consisting of 48 files                 base.py:265
[11:18:33] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-26-13-14">2022-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-26 13:14:41.856121</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-26 13:14:53.667668</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:14:41] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[13:14:42] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[13:14:43] ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:14:44] Deleting batch no. 2 consisting of 41 files               base.py:207
[13:14:45] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[13:14:50] Committing batch 1 consisting of 92 files                 base.py:265
[13:14:52] Committing batch 2 consisting of 48 files                 base.py:265
[13:14:53] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-25-14-21">2022-04-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-25 14:21:54.782624</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-25 14:22:05.820611</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:21:54] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[14:21:55] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
[14:21:56] ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
           Deleting batch no. 2 consisting of 41 files               base.py:207
[14:21:57] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[14:22:03] Committing batch 1 consisting of 92 files                 base.py:265
[14:22:04] Committing batch 2 consisting of 48 files                 base.py:265
[14:22:05] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-24-18-01">2022-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-24 18:01:32.882379</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-24 18:01:43.559587</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:01:32] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
[18:01:34] Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
           ...found 1 files in SAW                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[18:01:35] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[18:01:40] Committing batch 1 consisting of 92 files                 base.py:265
[18:01:41] Committing batch 2 consisting of 48 files                 base.py:265
[18:01:43] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-23-13-44">2022-04-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-23 13:44:20.706487</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-23 13:46:32.910639</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fd83d851100>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd83d851100>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 243, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd83d851100>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:44:20] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:228
[13:44:21] Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[13:44:22] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[13:46:32] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7fd83d851100>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
           Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  


  <h2 id="2022-04-22-11-35">2022-04-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-22 11:35:46.055589</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-22 11:37:57.504316</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f942d327190>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f942d327190>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 243, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f942d327190>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:46] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:35:47] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[11:37:57] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7f942d327190>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
           Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  


  <h2 id="2022-04-21-21-22">2022-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>138 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-21 21:22:00.362014</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-21 21:24:19.137656</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f011b442520>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f011b442520>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 235, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f011b442520>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[21:22:00] Fetching Scraper for: SAW                              handlers.py:23
[21:22:04] Begin attempting to scrape: SAW                        handlers.py:27
[21:22:05] Deleting existing data...                                 base.py:228
[21:22:06] Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[21:22:07] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[21:24:18] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7f011b442520>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
[21:24:19] Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  

  

  


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
