<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2022-04-27-11-18">2022-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-27 11:18:21.290742</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-27 11:18:33.613758</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:18:21] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[11:18:22] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[11:18:23] Deleting batch no. 2 consisting of 41 files               base.py:207
[11:18:24] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[11:18:30] Committing batch 1 consisting of 92 files                 base.py:265
[11:18:31] Committing batch 2 consisting of 48 files                 base.py:265
[11:18:33] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-26-13-14">2022-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-26 13:14:41.856121</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-26 13:14:53.667668</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:14:41] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[13:14:42] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
[13:14:43] ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
           ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:14:44] Deleting batch no. 2 consisting of 41 files               base.py:207
[13:14:45] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[13:14:50] Committing batch 1 consisting of 92 files                 base.py:265
[13:14:52] Committing batch 2 consisting of 48 files                 base.py:265
[13:14:53] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-25-14-21">2022-04-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-25 14:21:54.782624</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-25 14:22:05.820611</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:21:54] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:230
[14:21:55] Getting all files in SAW...                               base.py:182
           Getting all files in SAW/json...                          base.py:182
           ...found 70 files in SAW/json                             base.py:198
           Getting all files in SAW/raw...                           base.py:182
[14:21:56] ...found 70 files in SAW/raw                              base.py:198
           ...found 141 files in SAW                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
           Deleting batch no. 2 consisting of 41 files               base.py:207
[14:21:57] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[14:22:03] Committing batch 1 consisting of 92 files                 base.py:265
[14:22:04] Committing batch 2 consisting of 48 files                 base.py:265
[14:22:05] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-24-18-01">2022-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-24 18:01:32.882379</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-24 18:01:43.559587</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:01:32] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
[18:01:34] Deleting existing data...                                 base.py:230
           Getting all files in SAW...                               base.py:182
           ...found 1 files in SAW                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[18:01:35] ...data deleted.                                          base.py:237
           Scraping from https://sandwell.moderngov.co.uk/mgWebServic base.py:42
           e.asmx/GetCouncillorsByWard                                          
[18:01:40] Committing batch 1 consisting of 92 files                 base.py:265
[18:01:41] Committing batch 2 consisting of 48 files                 base.py:265
[18:01:43] Finished attempting to scrape: SAW                        base.py:315
</pre>
  

  


  <h2 id="2022-04-23-13-44">2022-04-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-23 13:44:20.706487</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-23 13:46:32.910639</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fd83d851100>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd83d851100>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 243, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd83d851100>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:44:20] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:228
[13:44:21] Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[13:44:22] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[13:46:32] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7fd83d851100>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
           Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  


  <h2 id="2022-04-22-11-35">2022-04-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-22 11:35:46.055589</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-22 11:37:57.504316</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f942d327190>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f942d327190>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 243, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f942d327190>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:35:46] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:35:47] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[11:37:57] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7f942d327190>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
           Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  


  <h2 id="2022-04-21-21-22">2022-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>138 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-21 21:22:00.362014</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-21 21:24:19.137656</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f011b442520>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f011b442520>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 235, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f011b442520>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[21:22:00] Fetching Scraper for: SAW                              handlers.py:23
[21:22:04] Begin attempting to scrape: SAW                        handlers.py:27
[21:22:05] Deleting existing data...                                 base.py:228
[21:22:06] Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[21:22:07] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[21:24:18] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7f011b442520>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
[21:24:19] Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  


  <h2 id="2022-04-20-22-07">2022-04-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-20 22:07:05.421625</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-20 22:09:18.055796</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6c88a41310>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6c88a41310>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 235, in get_councillors
    req = self.get(self.base_url)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmis.sandwell.gov.uk', port=443): Max retries exceeded with url: /cmis5/People/tabid/62/ScreenMode/Alphabetical/Default.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6c88a41310>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[22:07:05] Fetching Scraper for: SAW                              handlers.py:23
           Begin attempting to scrape: SAW                        handlers.py:27
           Deleting existing data...                                 base.py:228
[22:07:06] Getting all files in SAW...                               base.py:180
           ...found 1 files in SAW                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[22:07:07] ...data deleted.                                          base.py:235
           Scraping from https://cmis.sandwell.gov.uk/cmis5/People/ta base.py:40
           bid/62/ScreenMode/Alphabetical/Default.aspx                          
[22:09:17] HTTPSConnectionPool(host='cmis.sandwell.gov.uk',       handlers.py:36
           port=443): Max retries exceeded with url: /cmis5/Peopl               
           e/tabid/62/ScreenMode/Alphabetical/Default.aspx                      
           (Caused by NewConnectionError('<urllib3.connection.HTT               
           PSConnection object at 0x7f6c88a41310>: Failed to                    
           establish a new connection: [Errno 110] Connection                   
           timed out'))                                                         
[22:09:18] Finished attempting to scrape: SAW                        base.py:313
</pre>
  

  

  

  

  

  

  

  

  

  

  

  

  


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
