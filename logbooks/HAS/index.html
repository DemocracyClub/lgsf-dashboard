<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-25-11-17">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 11:17:22.257422</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 11:17:41.716726</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:17:35] Created log commit                                        base.py:376
           544c2e4f40c39f75c9a3e54ea67876c7e3433075                             
           Attempting to create merge commit...                      base.py:281
[11:17:41] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-24-11-24">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 11:24:43.415891</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 11:24:52.076838</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:24:43] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:24:44] Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
[11:24:45] ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:24:46] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:24:49] Committing batch 1 consisting of 64 files                 base.py:269
[11:24:52] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-23-11-17">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 11:17:27.122098</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 11:17:43.431239</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:17:36] Created log commit                                        base.py:376
           6ae7ff6695be71d49ad600a7d6c80a5269de512c                             
           Attempting to create merge commit...                      base.py:281
[11:17:43] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-22-11-37">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 11:37:55.351384</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 11:38:10.238282</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:37:55] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
[11:37:56] ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 64 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 64 files               base.py:211
[11:37:59] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:38:01] Committing batch 1 consisting of 64 files                 base.py:269
[11:38:07] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 64 files                 base.py:269
[11:38:10] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-21-11-32">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 11:32:27.026750</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 11:32:34.919335</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:32:27] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:32:29] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:32:33] Committing batch 1 consisting of 64 files                 base.py:269
[11:32:34] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-21-00-08">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 00:08:26.957250</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 00:08:40.455030</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:08:35] Created log commit                                        base.py:376
           076c62b25eafb874e82373454d59775a1f37127f                             
           Attempting to create merge commit...                      base.py:281
[00:08:40] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-19-11-42">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:42:26.265143</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:42:37.672851</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:26] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:42:27] Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:42:28] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:42:32] Committing batch 1 consisting of 64 files                 base.py:269
[11:42:37] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-18-11-55">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:55:47.560710</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:56:06.622013</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:55:47] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
[11:55:48] Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 64 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 64 files               base.py:211
[11:55:52] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[11:55:56] Committing batch 1 consisting of 64 files                 base.py:269
[11:56:04] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 64 files                 base.py:269
[11:56:06] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-17-11-24">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:24:16.055247</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:24:30.557893</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:24:24] Created log commit                                        base.py:376
           c458cc3493c8dc5558a670b472067ebb324a0ef0                             
           Attempting to create merge commit...                      base.py:281
[11:24:30] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-16-11-31">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>18 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:31:26.487640</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:31:44.938437</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:31:39] Created log commit                                        base.py:376
           cdd0a3a6628fb1ec75b08eabddbf3e1d5c4529d0                             
           Attempting to create merge commit...                      base.py:281
[11:31:44] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-15-11-18">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:18:43.972844</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:18:57.661095</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:18:43] Fetching Scraper for: HAS                              handlers.py:22
[11:18:47] Begin attempting to scrape: HAS                        handlers.py:25
[11:18:48] Deleting existing data...                                 base.py:234
[11:18:49] Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:18:57] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-14-11-28">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:28:13.234592</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:28:23.165945</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:28:13] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
[11:28:14] ...found 32 files in HAS/raw                              base.py:202
           ...found 64 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 64 files               base.py:211
[11:28:22] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:28:23] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-13-11-21">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 11:21:39.998474</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 11:21:48.073844</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:21:39] Fetching Scraper for: HAS                              handlers.py:22
[11:21:40] Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
[11:21:41] ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:21:47] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:21:48] No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-13-00-08">2022-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-13 00:08:30.093721</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-13 00:08:38.426579</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:08:30] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[00:08:32] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:08:36] Committing batch 1 consisting of 64 files                 base.py:269
[00:08:38] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-11-11-41">2022-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-11 11:41:26.825909</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-11 11:41:46.720177</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:41:46] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-10-11-20">2022-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-10 11:20:03.535288</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-10 11:20:09.915891</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:20:03] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:20:04] Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:20:09] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-09-11-51">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 11:51:20.296535</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 11:51:25.270470</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:51:20] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
[11:51:21] ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[11:51:24] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:51:25] No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-09-00-01">2022-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-09 00:01:54.814335</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-09 00:02:01.551468</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:01:54] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:01:55] Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
           ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
[00:01:56] ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[00:01:57] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[00:02:00] Committing batch 1 consisting of 64 files                 base.py:269
[00:02:01] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-07-11-27">2022-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-07 11:27:06.953556</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-07 11:27:26.725763</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:27:26] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-06-18-20">2022-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-06 18:20:50.332956</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-06 18:21:01.158381</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:20:50] Fetching Scraper for: HAS                              handlers.py:22
           Begin attempting to scrape: HAS                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
[18:20:51] ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 65 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 65 files               base.py:211
[18:20:57] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[18:20:59] Committing batch 1 consisting of 64 files                 base.py:269
[18:21:01] Finished attempting to scrape: HAS                        base.py:319
</pre>

  <h2 id="2022-03-06-17-43">2022-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-06 17:43:02.216814</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-06 17:43:13.694870</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:43:02] Fetching Scraper for: HAS                              handlers.py:21
           Begin attempting to scrape: HAS                        handlers.py:24
           Deleting existing data...                                 base.py:234
           Getting all files in HAS...                               base.py:186
           Getting all files in HAS/json...                          base.py:186
[17:43:03] ...found 32 files in HAS/json                             base.py:202
           Getting all files in HAS/raw...                           base.py:186
           ...found 32 files in HAS/raw                              base.py:202
           ...found 64 files in HAS                                  base.py:202
           Deleting batch no. 1 consisting of 64 files               base.py:211
[17:43:04] ...data deleted.                                          base.py:241
           Scraping from http://hastings.moderngov.co.uk/mgWebService base.py:40
           .asmx/GetCouncillorsByWard                                           
[17:43:07] Committing batch 1 consisting of 64 files                 base.py:269
[17:43:13] Finished attempting to scrape: HAS                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
