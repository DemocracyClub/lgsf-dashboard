<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2023-10-27-09-26">2023-10-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-27 09:26:40.146432</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-27 09:26:51.842047</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:26:40] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[09:26:41] Getting all files in Councillors/json...                  base.py:191
           ...found 57 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 57 files in Councillors/raw                      base.py:207
           ...found 115 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[09:26:42] Deleting batch no. 2 consisting of 15 files               base.py:216
[09:26:43] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[09:26:49] Committing batch 1 consisting of 92 files                 base.py:274
[09:26:50] Committing batch 2 consisting of 22 files                 base.py:274
[09:26:51] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-26-08-56">2023-10-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-26 08:56:48.205495</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-26 08:56:58.879444</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:56:48] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[08:56:49] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 57 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 57 files in Councillors/raw                      base.py:207
           ...found 115 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[08:56:50] Deleting batch no. 2 consisting of 15 files               base.py:216
[08:56:51] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[08:56:56] Committing batch 1 consisting of 92 files                 base.py:274
[08:56:57] Committing batch 2 consisting of 22 files                 base.py:274
[08:56:58] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-25-10-36">2023-10-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-25 10:36:58.990421</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-25 10:37:09.504754</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:36:58] Fetching Scraper for: BRY                              handlers.py:23
[10:36:59] Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[10:37:00] Getting all files in Councillors/json...                  base.py:191
           ...found 57 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 57 files in Councillors/raw                      base.py:207
           ...found 115 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[10:37:01] Deleting batch no. 2 consisting of 15 files               base.py:216
[10:37:02] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[10:37:07] Committing batch 1 consisting of 92 files                 base.py:274
[10:37:08] Committing batch 2 consisting of 22 files                 base.py:274
[10:37:09] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-24-09-42">2023-10-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-24 09:42:43.640556</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-24 09:42:54.392408</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:42:43] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[09:42:44] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[09:42:45] ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[09:42:46] Deleting batch no. 2 consisting of 17 files               base.py:216
[09:42:47] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[09:42:51] Committing batch 1 consisting of 92 files                 base.py:274
[09:42:53] Committing batch 2 consisting of 22 files                 base.py:274
[09:42:54] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-23-08-23">2023-10-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-23 08:23:02.751154</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-23 08:23:13.897132</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:23:02] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
[08:23:04] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[08:23:05] ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[08:23:06] Deleting batch no. 2 consisting of 17 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[08:23:11] Committing batch 1 consisting of 92 files                 base.py:274
[08:23:12] Committing batch 2 consisting of 24 files                 base.py:274
[08:23:13] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-22-09-58">2023-10-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-22 09:58:04.152155</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-22 09:58:14.569620</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:58:04] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[09:58:05] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[09:58:06] Deleting batch no. 2 consisting of 17 files               base.py:216
[09:58:07] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[09:58:11] Committing batch 1 consisting of 92 files                 base.py:274
[09:58:13] Committing batch 2 consisting of 24 files                 base.py:274
[09:58:14] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-21-10-08">2023-10-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-21 10:08:15.106628</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-21 10:08:27.693442</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:08:15] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[10:08:16] Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[10:08:17] Deleting batch no. 2 consisting of 17 files               base.py:216
[10:08:18] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[10:08:24] Committing batch 1 consisting of 92 files                 base.py:274
[10:08:26] Committing batch 2 consisting of 24 files                 base.py:274
[10:08:27] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-20-10-18">2023-10-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-20 10:18:15.033081</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-20 10:18:27.499394</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:18:15] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[10:18:16] Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[10:18:17] Deleting batch no. 2 consisting of 17 files               base.py:216
[10:18:18] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[10:18:24] Committing batch 1 consisting of 92 files                 base.py:274
[10:18:26] Committing batch 2 consisting of 24 files                 base.py:274
[10:18:27] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-19-08-41">2023-10-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-19 08:41:14.213583</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-19 08:41:24.713198</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:41:14] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[08:41:15] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[08:41:16] Deleting batch no. 2 consisting of 17 files               base.py:216
[08:41:17] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[08:41:22] Committing batch 1 consisting of 92 files                 base.py:274
[08:41:23] Committing batch 2 consisting of 24 files                 base.py:274
[08:41:24] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-18-09-01">2023-10-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-18 09:01:41.519784</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-18 09:02:02.433951</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:01:41] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[09:01:42] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[09:01:43] Deleting batch no. 2 consisting of 17 files               base.py:216
[09:01:44] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[09:01:59] Committing batch 1 consisting of 92 files                 base.py:274
[09:02:01] Committing batch 2 consisting of 24 files                 base.py:274
[09:02:02] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-17-08-32">2023-10-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-17 08:32:23.255171</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-17 08:32:33.874673</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:32:23] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[08:32:24] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[08:32:25] Deleting batch no. 2 consisting of 17 files               base.py:216
[08:32:26] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[08:32:30] Committing batch 1 consisting of 92 files                 base.py:274
[08:32:32] Committing batch 2 consisting of 24 files                 base.py:274
[08:32:33] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-16-10-18">2023-10-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-16 10:18:49.788875</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-16 10:19:01.348581</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:18:49] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
[10:18:50] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[10:18:51] ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[10:18:52] Deleting batch no. 2 consisting of 17 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[10:18:58] Committing batch 1 consisting of 92 files                 base.py:274
[10:19:00] Committing batch 2 consisting of 24 files                 base.py:274
[10:19:01] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-15-09-51">2023-10-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-15 09:51:01.492986</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-15 09:51:13.418635</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:51:01] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[09:51:02] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[09:51:04] Deleting batch no. 2 consisting of 17 files               base.py:216
[09:51:05] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[09:51:10] Committing batch 1 consisting of 92 files                 base.py:274
[09:51:12] Committing batch 2 consisting of 24 files                 base.py:274
[09:51:13] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-14-09-58">2023-10-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-14 09:58:31.171311</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-14 09:58:41.477800</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:58:31] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[09:58:32] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 58 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 58 files in Councillors/raw                      base.py:207
           ...found 117 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[09:58:33] Deleting batch no. 2 consisting of 17 files               base.py:216
[09:58:34] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[09:58:39] Committing batch 1 consisting of 92 files                 base.py:274
[09:58:40] Committing batch 2 consisting of 24 files                 base.py:274
[09:58:41] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-13-10-52">2023-10-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-13 10:52:56.968319</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-13 10:53:07.501873</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:52:56] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
[10:52:57] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[10:52:58] ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[10:52:59] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillor           
           sByWard                                                              
[10:53:04] Committing batch 1 consisting of 92 files                 base.py:274
[10:53:06] Committing batch 2 consisting of 24 files                 base.py:274
[10:53:07] Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-13-09-19">2023-10-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>133 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-13 09:19:14.547597</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-13 09:21:27.781494</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 714, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 415, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/python/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/var/lang/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f64eae3a610>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 798, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f64eae3a610>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f64eae3a610>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:19:14] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[09:19:15] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[09:19:16] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           http://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillors           
           ByWard                                                               
[09:21:27] HTTPConnectionPool(host='cds.bromley.gov.uk',          handlers.py:36
           port=80): Max retries exceeded with url:                             
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7f64eae3a610>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-12-13-08">2023-10-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-12 13:08:56.848911</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-12 13:11:08.528205</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 714, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 415, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/python/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/var/lang/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f8fc3282fd0>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 798, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8fc3282fd0>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8fc3282fd0>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:08:56] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
[13:08:57] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[13:08:58] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           http://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillors           
           ByWard                                                               
[13:11:08] HTTPConnectionPool(host='cds.bromley.gov.uk',          handlers.py:36
           port=80): Max retries exceeded with url:                             
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7f8fc3282fd0>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-11-12-59">2023-10-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>133 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-11 12:59:45.633274</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-11 13:01:58.662957</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 714, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 415, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/python/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/var/lang/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fcc386c0250>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 798, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc386c0250>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc386c0250>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:59:45] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[12:59:46] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[12:59:47] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           http://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillors           
           ByWard                                                               
[13:01:58] HTTPConnectionPool(host='cds.bromley.gov.uk',          handlers.py:36
           port=80): Max retries exceeded with url:                             
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7fcc386c0250>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-10-12-56">2023-10-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>133 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-10 12:56:56.643708</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-10 12:59:09.661084</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 714, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 415, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/python/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/var/lang/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f913d091130>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 798, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f913d091130>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f913d091130>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:56:56] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
[12:56:57] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[12:56:58] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           http://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillors           
           ByWard                                                               
[12:59:09] HTTPConnectionPool(host='cds.bromley.gov.uk',          handlers.py:36
           port=80): Max retries exceeded with url:                             
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7f913d091130>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
           Finished attempting to scrape: BRY                        base.py:324
</pre>
  

  


  <h2 id="2023-10-09-12-39">2023-10-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-10-09 12:39:37.166576</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-10-09 12:41:50.065796</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 714, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 415, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/python/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/var/lang/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f86ccf3f280>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 798, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f86ccf3f280>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cds.bromley.gov.uk', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f86ccf3f280>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:39:37] Fetching Scraper for: BRY                              handlers.py:23
           Begin attempting to scrape: BRY                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[12:39:38] ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           http://cds.bromley.gov.uk/mgWebService.asmx/GetCouncillors           
           ByWard                                                               
[12:41:49] HTTPConnectionPool(host='cds.bromley.gov.uk',          handlers.py:36
           port=80): Max retries exceeded with url:                             
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7f86ccf3f280>: Failed to establish a new                 
           connection: [Errno 110] Connection timed out'))                      
[12:41:50] Finished attempting to scrape: BRY                        base.py:324
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
