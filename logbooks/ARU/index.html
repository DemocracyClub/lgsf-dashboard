<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-04-04-11-38">2022-04-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-04 11:38:57.016987</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-04 11:39:12.542707</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:38:57] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           ARU Does not exist                                        base.py:206
           ...no data to delete.                                     base.py:238
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[11:39:01] Committing batch 1 consisting of 92 files                 base.py:269
[11:39:07] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:39:08] Committing batch 1 consisting of 92 files                 base.py:269
[11:39:12] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-04-03-11-24">2022-04-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-03 11:24:32.331660</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-03 11:24:47.601830</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:24:32] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
[11:24:33] Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:24:34] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:24:37] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[11:24:41] Committing batch 1 consisting of 92 files                 base.py:269
[11:24:43] Committing batch 2 consisting of 16 files                 base.py:269
[11:24:47] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-04-02-11-29">2022-04-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-02 11:29:41.428519</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-02 11:29:50.147902</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:29:41] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:29:42] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:29:49] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:29:50] No new councillor data found.                             base.py:317
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-04-02-00-09">2022-04-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-02 00:09:35.278936</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-02 00:09:54.475645</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:09:35] Fetching Scraper for: ARU                              handlers.py:22
[00:09:41] Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:09:42] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:09:54] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-04-01-00-02">2022-04-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-01 00:02:19.399776</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-01 00:02:30.791144</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:02:19] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:02:20] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:02:21] Deleting batch no. 2 consisting of 9 files                base.py:211
[00:02:30] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-30-12-05">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 12:05:43.429163</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 12:05:52.114468</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:05:43] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
[12:05:44] ...found 46 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 46 files in ARU/raw                              base.py:202
           ...found 93 files in ARU                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[12:05:45] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[12:05:49] Committing batch 1 consisting of 92 files                 base.py:269
[12:05:50] Committing batch 2 consisting of 16 files                 base.py:269
[12:05:52] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-30-00-02">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 00:02:25.978008</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 00:02:43.300397</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:02:25] Fetching Scraper for: ARU                              handlers.py:22
[00:02:26] Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 46 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 46 files in ARU/raw                              base.py:202
           ...found 92 files in ARU                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[00:02:28] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[00:02:31] Committing batch 1 consisting of 92 files                 base.py:269
[00:02:41] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 1 consisting of 92 files                 base.py:269
[00:02:43] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-28-11-56">2022-03-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>38 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-28 11:56:41.910180</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-28 11:57:20.101880</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:57:13] Created log commit                                        base.py:376
           516aab5cdd6dc9232ccca3dd014a1fb65d6e1e2a                             
           Attempting to create merge commit...                      base.py:281
[11:57:19] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
[11:57:20] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-27-11-34">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 11:34:09.370620</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 11:34:18.632403</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:34:09] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
[11:34:10] ...found 46 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 46 files in ARU/raw                              base.py:202
           ...found 93 files in ARU                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[11:34:18] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-26-11-37">2022-03-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-26 11:37:50.349947</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-26 11:38:11.513347</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:38:11] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-25-11-46">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 11:46:41.903651</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 11:46:49.089387</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:46:41] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:46:42] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 108 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:46:48] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:46:49] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-24-11-39">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 11:39:22.024798</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 11:39:30.486174</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:39:22] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
[11:39:23] ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:39:30] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-23-11-42">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>18 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 11:42:35.461570</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 11:42:53.945841</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:48] Created log commit                                        base.py:376
           98f954a865b5a51234164f45621261234eefec26                             
           Attempting to create merge commit...                      base.py:281
[11:42:53] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
           Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-22-11-34">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 11:34:14.105764</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 11:34:20.243437</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:34:14] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/raw...                           base.py:186
           ...found 9 files in ARU/raw                               base.py:202
           ...found 9 files in ARU                                   base.py:202
           Deleting batch no. 1 consisting of 9 files                base.py:211
[11:34:19] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:34:20] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-21-11-59">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 11:59:43.853799</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 11:59:54.639891</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:59:43] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:59:44] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/raw...                           base.py:186
           ...found 9 files in ARU/raw                               base.py:202
           ...found 10 files in ARU                                  base.py:202
           Deleting batch no. 1 consisting of 10 files               base.py:211
[11:59:47] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[11:59:51] Committing batch 1 consisting of 92 files                 base.py:269
[11:59:53] Committing batch 2 consisting of 16 files                 base.py:269
[11:59:54] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-21-00-01">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>37 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 00:01:56.238390</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 00:02:34.112299</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ConcurrentReferenceUpdateException) when calling the MergeBranchesBySquash operation: The merge cannot be completed because the following branch has been modified: refs/heads/main. Another user might have modified this branch while the merge was in progress. Wait a few minutes, and then try again.</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:02:28] Created log commit                                        base.py:376
           39043deedda3128d514ae86dd3da32637abc1602                             
           Attempting to create merge commit...                      base.py:281
[00:02:33] An error occurred (ConcurrentReferenceUpdateException) handlers.py:34
           when calling the MergeBranchesBySquash operation: The                
           merge cannot be completed because the following branch               
           has been modified: refs/heads/main. Another user might               
           have modified this branch while the merge was in                     
           progress. Wait a few minutes, and then try again.                    
[00:02:34] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-19-11-46">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>35 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:46:29.784434</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:47:05.052763</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:47:04] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:47:05] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-18-11-16">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:16:29.431529</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:16:43.127336</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:29] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:16:30] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:16:32] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:16:34] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[11:16:39] Committing batch 1 consisting of 92 files                 base.py:269
[11:16:41] Committing batch 2 consisting of 16 files                 base.py:269
[11:16:43] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-17-12-17">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 12:17:51.701179</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 12:18:01.920002</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:17:51] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
[12:17:52] Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 46 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
           ...found 46 files in ARU/raw                              base.py:202
           ...found 92 files in ARU                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[12:17:53] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[12:17:57] Committing batch 1 consisting of 92 files                 base.py:269
[12:17:59] Committing batch 2 consisting of 16 files                 base.py:269
[12:18:01] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-16-12-21">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 12:21:07.544874</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 12:21:18.449668</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:21:07] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
[12:21:08] Getting all files in ARU/raw...                           base.py:186
           ...found 9 files in ARU/raw                               base.py:202
           ...found 10 files in ARU                                  base.py:202
           Deleting batch no. 1 consisting of 10 files               base.py:211
[12:21:09] ...data deleted.                                          base.py:241
           Scraping from http://democracy.arun.gov.uk/mgWebService.as base.py:40
           mx/GetCouncillorsByWard                                              
[12:21:13] Committing batch 1 consisting of 92 files                 base.py:269
[12:21:15] Committing batch 2 consisting of 16 files                 base.py:269
[12:21:18] Finished attempting to scrape: ARU                        base.py:319
</pre>

  <h2 id="2022-03-15-11-50">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:50:34.379522</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:50:40.038688</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:50:34] Fetching Scraper for: ARU                              handlers.py:22
           Begin attempting to scrape: ARU                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in ARU...                               base.py:186
           Getting all files in ARU/json...                          base.py:186
           ...found 54 files in ARU/json                             base.py:202
           Getting all files in ARU/raw...                           base.py:186
[11:50:35] ...found 54 files in ARU/raw                              base.py:202
           ...found 109 files in ARU                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:50:39] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:50:40] No new councillor data found.                             base.py:317
           Finished attempting to scrape: ARU                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
