<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2023-12-09-09-38">2023-12-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-09 09:38:23.043791</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-09 09:38:25.504232</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:38:23] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:38:24] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:38:25] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-08-10-22">2023-12-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-08 10:22:10.990749</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-08 10:22:13.400724</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:22:10] Fetching Scraper for: GRE                              handlers.py:23
[10:22:11] Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[10:22:12] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
[10:22:13] Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-07-09-45">2023-12-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-07 09:45:02.570798</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-07 09:45:04.952898</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:45:02] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:45:03] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:45:04] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-06-09-13">2023-12-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-06 09:13:50.947245</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-06 09:13:53.202403</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:13:50] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[09:13:51] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:13:52] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
[09:13:53] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-05-08-41">2023-12-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-05 08:41:54.187551</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-05 08:41:56.430708</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:41:54] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:41:55] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:41:56] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-04-10-25">2023-12-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-04 10:25:25.642365</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-04 10:25:27.924990</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:25:25] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:25:26] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:25:27] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-03-10-31">2023-12-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-03 10:31:54.742176</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-03 10:31:56.989055</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:31:54] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[10:31:55] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:31:56] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-02-08-18">2023-12-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-02 08:18:04.551275</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-02 08:18:07.019805</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:18:04] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:18:05] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:18:06] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
[08:18:07] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-12-01-09-47">2023-12-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-01 09:47:44.664991</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-01 09:47:46.981070</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:47:44] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[09:47:45] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:47:46] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-30-09-32">2023-11-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-30 09:32:44.415231</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-30 09:32:46.570796</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:32:44] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:32:45] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:32:46] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-29-10-31">2023-11-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-29 10:31:22.061664</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-29 10:31:24.225625</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:31:22] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[10:31:23] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
[10:31:24] HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-28-10-43">2023-11-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-28 10:43:58.702268</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-28 10:44:00.864907</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:43:58] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[10:43:59] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:44:00] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-27-10-42">2023-11-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-27 10:42:56.783196</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-27 10:42:58.932519</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:42:56] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[10:42:57] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:42:58] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-26-10-39">2023-11-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-26 10:39:11.266897</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-26 10:39:13.405266</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:39:11] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:39:12] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:39:13] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-25-09-46">2023-11-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-25 09:46:58.589932</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-25 09:47:01.007653</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:46:58] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:46:59] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:47:00] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
[09:47:01] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-24-09-04">2023-11-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-24 09:04:48.787839</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-24 09:04:52.178402</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 56, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 277, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='committees.royalgreenwich.gov.uk', port=443): Max retries exceeded with url: /Councillors/tabid/63/ScreenMode/Alphabetical/Default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:04:48] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[09:04:49] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[09:04:50] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:04:51] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
           HTTPSConnectionPool(host='committees.royalgreenwich.go handlers.py:36
           v.uk', port=443): Max retries exceeded with url:                     
           /Councillors/tabid/63/ScreenMode/Alphabetical/Default.               
           aspx (Caused by SSLError(SSLCertVerificationError(1,                 
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)')))                                                    
[09:04:52] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-23-08-25">2023-11-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>129 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-23 08:25:17.023440</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-23 08:27:26.309109</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:25:17] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[08:25:18] Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:25:19] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
[08:25:21] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/336/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:24] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/354/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:26] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/337/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:27] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/75/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:25:30] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/345/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:31] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/348/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/314/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/76/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:25:39] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/315/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:42] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/355/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:44] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/96/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:25:46] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/102/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:49] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/346/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:51] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/334/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:53] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/107/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/110/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:25:56] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/79/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:25:59] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/81/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:26:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/349/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:05] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/86/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:26:08] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/92/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:26:10] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/105/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:12] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/341/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:14] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/116/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:16] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/123/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:18] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/338/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:20] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/122/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:22] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/125/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:23] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/121/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:27] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/120/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:28] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/316/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:30] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/112/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:32] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/342/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:34] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/109/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:36] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/357/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:38] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/103/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:40] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/340/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:42] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/356/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:44] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/350/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:45] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/352/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:49] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/351/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:51] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/344/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/99/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:26:57] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/317/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:26:58] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/97/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:27:01] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/95/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:27:03] Committing batch 1 consisting of 92 files                 base.py:291
[08:27:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/347/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:27:08] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/333/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:27:10] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/332/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:27:12] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/353/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:27:15] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/82/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:27:17] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/339/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:27:19] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/80/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:27:21] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/77/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:27:23] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/343/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:27:24] Committing batch 2 consisting of 18 files                 base.py:291
[08:27:26] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-22-08-32">2023-11-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>130 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-22 08:32:40.123989</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-22 08:34:50.813782</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:32:40] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[08:32:41] Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:32:42] Deleting batch no. 2 consisting of 11 files               base.py:230
[08:32:43] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
[08:32:44] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/336/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:32:46] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/354/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:32:48] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/337/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:32:50] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/75/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:32:53] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/345/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:32:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/348/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:32:57] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/314/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:00] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/76/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:33:02] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/315/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/355/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:06] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/96/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:33:08] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/102/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:11] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/346/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:12] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/334/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:14] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/107/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:16] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/110/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:18] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/79/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:33:22] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/81/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:33:25] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/349/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:26] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/86/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:33:29] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/92/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:33:31] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/105/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/341/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/116/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:37] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/123/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:39] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/338/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:41] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/122/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:45] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/125/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:47] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/121/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:49] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/120/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:50] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/316/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:52] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/112/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:54] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/342/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:56] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/109/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:33:58] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/357/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:00] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/103/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:02] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/340/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/356/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:08] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/350/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:11] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/352/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:13] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/351/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:14] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/344/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:17] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/99/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:34:18] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/317/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:20] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/97/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:34:22] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/95/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:34:24] Committing batch 1 consisting of 92 files                 base.py:291
[08:34:25] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/347/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:27] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/333/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:29] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/332/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/353/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/82/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:34:37] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/339/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:41] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/80/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:34:45] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/77/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:34:47] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/343/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:34:49] Committing batch 2 consisting of 18 files                 base.py:291
[08:34:50] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-21-08-40">2023-11-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>125 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-21 08:40:34.676550</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-21 08:42:40.351494</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:40:34] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[08:40:35] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[08:40:36] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:40:37] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
[08:40:39] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/336/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:41] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/354/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:42] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/337/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:44] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/75/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:40:47] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/345/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:48] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/348/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:50] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/314/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:53] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/76/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:40:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/315/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:40:58] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/355/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:00] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/96/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:41:02] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/102/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/346/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:06] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/334/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:09] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/107/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:10] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/110/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:12] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/79/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:41:16] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/81/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:41:19] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/349/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:20] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/86/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:41:23] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/92/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:41:25] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/105/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:27] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/341/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:29] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/116/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:31] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/123/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/338/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/122/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:38] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/125/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:41] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/121/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:43] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/120/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:45] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/316/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:47] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/112/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:49] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/342/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:51] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/109/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:53] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/357/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/103/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:57] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/340/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:41:59] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/356/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:02] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/350/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/352/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:07] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/351/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:09] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/344/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:11] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/99/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:42:13] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/317/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:15] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/97/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:42:17] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/95/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:42:19] Committing batch 1 consisting of 92 files                 base.py:291
[08:42:20] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/347/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:22] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/333/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:24] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/332/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:27] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/353/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:29] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/82/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:42:31] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/339/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/80/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:42:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/77/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:42:37] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/343/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:42:39] Committing batch 2 consisting of 18 files                 base.py:291
[08:42:40] Finished attempting to scrape: GRE                        base.py:339
</pre>
  

  


  <h2 id="2023-11-20-08-51">2023-11-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>129 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-11-20 08:51:59.732729</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-11-20 08:54:08.810641</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:51:59] Fetching Scraper for: GRE                              handlers.py:23
           Begin attempting to scrape: GRE                        handlers.py:27
[08:52:00] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
[08:52:01] Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:52:02] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://committees.royalgreenwich.gov.uk/Councillors/tabid           
           /63/ScreenMode/Alphabetical/Default.aspx                             
[08:52:04] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/336/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:06] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/354/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:08] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/337/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:10] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/75/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:12] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/345/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:14] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/348/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:16] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/314/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:18] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/76/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:20] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/315/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:23] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/355/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:25] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/96/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:29] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/102/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:31] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/346/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/334/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/107/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:37] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/110/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:38] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/79/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:42] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/81/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:46] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/349/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:48] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/86/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:50] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/92/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:52:52] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/105/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/341/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:57] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/116/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:52:59] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/123/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:01] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/338/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:03] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/122/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:06] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/125/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:08] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/121/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:10] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/120/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:12] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/316/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:14] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/112/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:16] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/342/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:18] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/109/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:21] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/357/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:22] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/103/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:25] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/340/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:28] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/356/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:29] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/350/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:31] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/352/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:33] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/351/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:35] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/344/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:37] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/99/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:53:39] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/317/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:41] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/97/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:53:43] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/95/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:53:46] Committing batch 1 consisting of 92 files                 base.py:291
[08:53:47] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/347/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:49] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/333/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:52] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/332/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:54] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/353/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:53:55] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/82/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:53:58] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/339/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:54:01] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/80/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:54:03] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/77/ScreenMode/Alphabetic           
           al/Default.aspx                                                      
[08:54:05] Scraping from                                              base.py:41
           http://committees.royalgreenwich.gov.uk/Councillors/tabid/           
           63/ctl/ViewCMIS_Person/mid/383/id/343/ScreenMode/Alphabeti           
           cal/Default.aspx                                                     
[08:54:07] Committing batch 2 consisting of 18 files                 base.py:291
[08:54:08] Finished attempting to scrape: GRE                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
