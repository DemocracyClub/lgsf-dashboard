<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-03-31-11-49">2022-03-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-31 11:49:12.739330</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-31 11:49:34.078774</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:49:12] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:49:13] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 46 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 46 files in HAV/raw                              base.py:202
           ...found 92 files in HAV                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[11:49:15] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:49:17] Committing batch 1 consisting of 92 files                 base.py:269
[11:49:30] Committing batch 2 consisting of 16 files                 base.py:269
[11:49:34] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-30-11-46">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 11:46:03.471666</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 11:46:15.602642</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:46:03] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:46:04] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
[11:46:05] ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:46:06] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:46:09] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:46:12] Committing batch 1 consisting of 92 files                 base.py:269
[11:46:13] Committing batch 2 consisting of 16 files                 base.py:269
[11:46:15] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-29-11-20">2022-03-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-29 11:20:13.262772</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-29 11:20:25.964897</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:20:13] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:20:14] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:20:16] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:20:19] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:20:22] Committing batch 1 consisting of 92 files                 base.py:269
[11:20:24] Committing batch 2 consisting of 16 files                 base.py:269
[11:20:25] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-29-00-06">2022-03-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-29 00:06:27.603578</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-29 00:06:37.668148</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:06:27] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
[00:06:28] Getting all files in HAV/raw...                           base.py:186
           ...found 9 files in HAV/raw                               base.py:202
           ...found 10 files in HAV                                  base.py:202
           Deleting batch no. 1 consisting of 10 files               base.py:211
[00:06:29] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[00:06:32] Committing batch 1 consisting of 92 files                 base.py:269
[00:06:33] Committing batch 2 consisting of 16 files                 base.py:269
[00:06:37] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-27-12-02">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>18 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 12:02:31.511408</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 12:02:49.529493</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:02:31] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
[12:02:32] ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:02:33] Deleting batch no. 2 consisting of 9 files                base.py:211
[12:02:41] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[12:02:44] Committing batch 1 consisting of 92 files                 base.py:269
[12:02:45] Committing batch 2 consisting of 16 files                 base.py:269
[12:02:49] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-26-11-30">2022-03-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-26 11:30:48.085967</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-26 11:30:55.997342</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:30:48] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
[11:30:49] ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:30:55] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-25-11-23">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 11:23:49.764298</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 11:24:02.585621</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:23:49] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:23:50] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:23:51] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:23:53] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:23:57] Committing batch 1 consisting of 92 files                 base.py:269
[11:24:00] Committing batch 2 consisting of 16 files                 base.py:269
[11:24:02] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-24-12-02">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 12:02:24.971718</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 12:02:28.203243</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:02:24] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
[12:02:25] Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
[12:02:26] ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:02:27] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[12:02:28] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-23-11-31">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>19 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 11:31:52.371629</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 11:32:11.549294</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:31:52] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/raw...                           base.py:186
[11:31:53] ...found 9 files in HAV/raw                               base.py:202
           ...found 9 files in HAV                                   base.py:202
           Deleting batch no. 1 consisting of 9 files                base.py:211
[11:31:54] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:31:57] Committing batch 1 consisting of 92 files                 base.py:269
[11:31:58] Committing batch 2 consisting of 16 files                 base.py:269
[11:32:09] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 16 files                 base.py:269
[11:32:11] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-23-00-05">2022-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>23 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-23 00:05:51.405593</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-23 00:06:14.655529</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:05:51] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/raw...                           base.py:186
[00:05:52] ...found 9 files in HAV/raw                               base.py:202
           ...found 9 files in HAV                                   base.py:202
           Deleting batch no. 1 consisting of 9 files                base.py:211
[00:05:56] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[00:05:59] Committing batch 1 consisting of 92 files                 base.py:269
[00:06:13] Committing batch 2 consisting of 16 files                 base.py:269
[00:06:14] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-22-00-00">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 00:00:39.231317</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 00:00:48.174402</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:00:39] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:00:40] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 46 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 46 files in HAV/raw                              base.py:202
           ...found 93 files in HAV                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[00:00:41] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[00:00:44] Committing batch 1 consisting of 92 files                 base.py:269
[00:00:46] Committing batch 2 consisting of 16 files                 base.py:269
[00:00:48] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-20-12-06">2022-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-20 12:06:14.148375</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-20 12:06:26.253238</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:06:14] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 46 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
[12:06:15] ...found 46 files in HAV/raw                              base.py:202
           ...found 92 files in HAV                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[12:06:25] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[12:06:26] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-19-11-15">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:15:25.018731</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:15:30.849807</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:15:25] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
[11:15:26] Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:15:30] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-18-11-27">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>20 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 11:27:46.732187</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 11:28:06.947954</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:27:46] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:27:47] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
[11:27:48] ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:27:51] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:27:52] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:27:54] Committing batch 1 consisting of 92 files                 base.py:269
[11:27:59] Committing batch 2 consisting of 16 files                 base.py:269
[11:28:06] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-18-00-10">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 00:10:22.522352</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 00:10:31.007309</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:10:22] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
[00:10:23] ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:10:24] Deleting batch no. 2 consisting of 9 files                base.py:211
[00:10:25] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[00:10:28] Committing batch 1 consisting of 92 files                 base.py:269
[00:10:29] Committing batch 2 consisting of 16 files                 base.py:269
[00:10:31] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-16-11-54">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:54:04.638741</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:54:11.552155</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:54:04] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:54:05] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
[11:54:06] ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:54:11] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-15-11-46">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 11:46:43.406577</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 11:46:54.661520</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:46:43] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
[11:46:44] ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:46:54] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-14-11-49">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 11:49:24.696424</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 11:49:35.894235</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:49:24] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:49:25] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
           ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:49:27] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:49:28] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[11:49:31] Committing batch 1 consisting of 92 files                 base.py:269
[11:49:33] Committing batch 2 consisting of 16 files                 base.py:269
[11:49:35] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-14-00-04">2022-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-14 00:04:18.880370</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-14 00:04:27.210098</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:04:18] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[00:04:19] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/raw...                           base.py:186
[00:04:20] ...found 9 files in HAV/raw                               base.py:202
           ...found 10 files in HAV                                  base.py:202
           Deleting batch no. 1 consisting of 10 files               base.py:211
[00:04:21] ...data deleted.                                          base.py:241
           Scraping from http://democracy.havering.gov.uk/mgWebServic base.py:40
           e.asmx/GetCouncillorsByWard                                          
[00:04:24] Committing batch 1 consisting of 92 files                 base.py:269
[00:04:25] Committing batch 2 consisting of 16 files                 base.py:269
[00:04:27] Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-12-11-25">2022-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-12 11:25:18.213523</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-12 11:25:21.543961</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:25:18] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in HAV...                               base.py:186
[11:25:19] Getting all files in HAV/raw...                           base.py:186
           ...found 9 files in HAV/raw                               base.py:202
           ...found 10 files in HAV                                  base.py:202
           Deleting batch no. 1 consisting of 10 files               base.py:211
[11:25:21] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           No new councillor data found.                             base.py:317
           Finished attempting to scrape: HAV                        base.py:319
</pre>

  <h2 id="2022-03-11-11-41">2022-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-11 11:41:04.824360</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-11 11:41:15.566851</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:41:04] Fetching Scraper for: HAV                              handlers.py:22
           Begin attempting to scrape: HAV                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:41:05] Getting all files in HAV...                               base.py:186
           Getting all files in HAV/json...                          base.py:186
[11:41:06] ...found 54 files in HAV/json                             base.py:202
           Getting all files in HAV/raw...                           base.py:186
           ...found 54 files in HAV/raw                              base.py:202
           ...found 109 files in HAV                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:41:08] Deleting batch no. 2 consisting of 9 files                base.py:211
[11:41:15] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: HAV                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
