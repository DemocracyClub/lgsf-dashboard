<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-05-02-10-04">2024-05-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-02 10:04:18.577821</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-02 10:04:24.342847</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:04:18] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[10:04:19] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 40 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[10:04:20] ...found 40 files in Councillors/raw                      base.py:225
           ...found 81 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 81 files               base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://meetings.derrycityandstrabanedistrict.com/mgWebSer           
           vice.asmx/GetCouncillorsByWard                                       
[10:04:22] Committing batch 1 consisting of 80 files                 base.py:297
[10:04:24] Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-05-01-10-24">2024-05-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-01 10:24:42.917320</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-01 10:24:48.610788</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:24:42] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[10:24:43] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:24:44] Getting all files in Councillors/json...                  base.py:209
           ...found 40 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 40 files in Councillors/raw                      base.py:225
           ...found 81 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 81 files               base.py:236
[10:24:45] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://meetings.derrycityandstrabanedistrict.com/mgWebSer           
           vice.asmx/GetCouncillorsByWard                                       
[10:24:47] Committing batch 1 consisting of 80 files                 base.py:297
[10:24:48] Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-30-09-47">2024-04-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-30 09:47:24.743115</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-30 09:47:30.900872</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:47:24] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[09:47:25] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[09:47:26] ...found 40 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 40 files in Councillors/raw                      base.py:225
           ...found 81 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 81 files               base.py:236
[09:47:27] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://meetings.derrycityandstrabanedistrict.com/mgWebSer           
           vice.asmx/GetCouncillorsByWard                                       
[09:47:29] Committing batch 1 consisting of 80 files                 base.py:297
[09:47:30] Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-29-10-46">2024-04-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-29 10:46:56.039887</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-29 10:47:01.476929</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:46:56] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:46:57] Getting all files in Councillors/json...                  base.py:209
           ...found 40 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 40 files in Councillors/raw                      base.py:225
           ...found 81 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 81 files               base.py:236
[10:46:58] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://meetings.derrycityandstrabanedistrict.com/mgWebSer           
           vice.asmx/GetCouncillorsByWard                                       
[10:47:00] Committing batch 1 consisting of 80 files                 base.py:297
[10:47:01] Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-28-09-23">2024-04-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-28 09:23:16.258264</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-28 09:23:21.925638</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:23:16] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:23:17] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 40 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 40 files in Councillors/raw                      base.py:225
           ...found 81 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 81 files               base.py:236
[09:23:18] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://meetings.derrycityandstrabanedistrict.com/mgWebSer           
           vice.asmx/GetCouncillorsByWard                                       
[09:23:20] Committing batch 1 consisting of 80 files                 base.py:297
[09:23:21] Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-27-17-47">2024-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-27 17:47:22.618791</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-27 17:47:29.013249</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:47:22] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[17:47:23] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[17:47:24] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://meetings.derrycityandstrabanedistrict.com/mgWebSer           
           vice.asmx/GetCouncillorsByWard                                       
[17:47:27] Committing batch 1 consisting of 80 files                 base.py:297
[17:47:29] Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-27-09-54">2024-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>32 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-27 09:54:06.568561</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-27 09:54:38.991445</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:54:06] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[09:54:07] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:54:08] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[09:54:38] timed out                                              handlers.py:36
           Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-15-43">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 15:43:04.289749</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 15:43:11.210080</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 199, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 218, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:43:04] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:257
[15:43:05] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[15:43:06] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[15:43:11] timed out                                              handlers.py:36
           Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-11-11">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 11:11:46.072556</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 11:11:53.000110</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 199, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 218, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:11:46] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[11:11:47] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[11:11:52] timed out                                              handlers.py:36
           Finished attempting to scrape: DRS                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-08-49">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 08:49:24.228124</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 08:51:36.942830</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f9549666c20>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f9549666c20>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f9549666c20>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:49:24] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:49:25] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[08:51:36] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f9549666c20>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-25-10-01">2024-04-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-25 10:01:49.563280</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-25 10:04:02.258415</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7fcc2edf2500>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fcc2edf2500>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fcc2edf2500>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:01:49] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[10:01:50] Deleting existing data...                                 base.py:251
[10:01:51] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:01:52] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[10:04:01] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7fcc2edf2500>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
[10:04:02] Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-24-08-36">2024-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-24 08:36:31.329783</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-24 08:38:43.158090</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7fa131e921d0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fa131e921d0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fa131e921d0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:36:31] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:36:32] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:36:33] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[08:38:42] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7fa131e921d0>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
[08:38:43] Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-23-09-40">2024-04-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-23 09:40:35.030235</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-23 09:42:46.464221</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f0b62e19ea0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f0b62e19ea0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f0b62e19ea0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:40:35] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[09:40:36] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[09:42:46] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f0b62e19ea0>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-22-10-21">2024-04-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-22 10:21:05.061552</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-22 10:23:16.886022</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f292e00f190>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f292e00f190>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f292e00f190>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:21:05] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[10:21:06] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[10:23:16] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f292e00f190>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-21-08-38">2024-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>133 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-21 08:38:59.940909</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-21 08:41:12.988249</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f95740cc400>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f95740cc400>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f95740cc400>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:38:59] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[08:39:00] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:39:01] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[08:41:12] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f95740cc400>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-20-10-27">2024-04-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-20 10:27:54.480712</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-20 10:30:06.758833</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f6922165690>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f6922165690>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f6922165690>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:27:54] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:27:55] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:27:56] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[10:30:06] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f6922165690>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-19-09-00">2024-04-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-19 09:00:36.543091</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-19 09:02:48.729779</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f4c3b4566b0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f4c3b4566b0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f4c3b4566b0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:00:36] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:00:37] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:00:38] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[09:02:48] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f4c3b4566b0>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-18-09-51">2024-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-18 09:51:10.846186</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-18 09:53:22.179343</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f7762dc49a0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7762dc49a0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7762dc49a0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:51:10] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[09:51:11] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:51:12] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[09:53:21] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f7762dc49a0>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
[09:53:22] Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-17-08-48">2024-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-17 08:48:20.444073</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-17 08:50:32.420070</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f0902e38100>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f0902e38100>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f0902e38100>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:48:20] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:48:21] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:48:22] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[08:50:32] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f0902e38100>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  

  


  <h2 id="2024-04-16-09-50">2024-04-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-16 09:50:29.923790</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-16 09:52:41.473551</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f7a876f45b0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7a876f45b0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='meetings.derrycityandstrabanedistrict.com', port=80): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7a876f45b0>, 'Connection to meetings.derrycityandstrabanedistrict.com timed out. (connect timeout=None)'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:50:29] Fetching Scraper for: DRS                              handlers.py:23
           Begin attempting to scrape: DRS                        handlers.py:27
[09:50:30] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:50:31] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://meetings.derrycityandstrabanedistrict.com/mgWebServ           
           ice.asmx/GetCouncillorsByWard                                        
[09:52:41] HTTPConnectionPool(host='meetings.derrycityandstrabane handlers.py:36
           district.com', port=80): Max retries exceeded with                   
           url: /mgWebService.asmx/GetCouncillorsByWard (Caused                 
           by                                                                   
           ConnectTimeoutError(<urllib3.connection.HTTPConnection               
           object at 0x7f7a876f45b0>, 'Connection to                            
           meetings.derrycityandstrabanedistrict.com timed out.                 
           (connect timeout=None)'))                                            
           Finished attempting to scrape: DRS                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
