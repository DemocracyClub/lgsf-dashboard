<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2022-05-29-14-10">2022-05-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-29 14:10:37.821525</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-29 14:10:47.504965</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:10:37] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[14:10:38] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[14:10:39] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[14:10:40] Deleting batch no. 2 consisting of 11 files               base.py:207
[14:10:41] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[14:10:44] Committing batch 1 consisting of 92 files                 base.py:265
[14:10:46] Committing batch 2 consisting of 18 files                 base.py:265
[14:10:47] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-28-13-02">2022-05-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-28 13:02:20.726908</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-28 13:02:30.312269</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:02:20] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[13:02:21] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[13:02:22] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:02:23] Deleting batch no. 2 consisting of 11 files               base.py:207
[13:02:24] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[13:02:27] Committing batch 1 consisting of 92 files                 base.py:265
[13:02:28] Committing batch 2 consisting of 18 files                 base.py:265
[13:02:30] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-27-12-30">2022-05-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-27 12:30:51.968700</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-27 12:31:04.356235</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:30:51] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
[12:30:52] Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
[12:30:53] Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:30:55] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:30:56] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:31:01] Committing batch 1 consisting of 92 files                 base.py:265
[12:31:02] Committing batch 2 consisting of 18 files                 base.py:265
[12:31:04] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-26-13-02">2022-05-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-26 13:02:36.733072</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-26 13:02:47.133426</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:02:36] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[13:02:37] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
[13:02:38] ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:02:39] Deleting batch no. 2 consisting of 11 files               base.py:207
[13:02:40] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[13:02:44] Committing batch 1 consisting of 92 files                 base.py:265
[13:02:45] Committing batch 2 consisting of 18 files                 base.py:265
[13:02:47] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-25-11-44">2022-05-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-25 11:44:48.744746</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-25 11:44:58.336205</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:44:48] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[11:44:49] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
[11:44:50] ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[11:44:51] Deleting batch no. 2 consisting of 11 files               base.py:207
           ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[11:44:55] Committing batch 1 consisting of 92 files                 base.py:265
[11:44:56] Committing batch 2 consisting of 18 files                 base.py:265
[11:44:58] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-24-11-31">2022-05-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-24 11:31:02.359556</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-24 11:31:12.615704</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:31:02] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[11:31:03] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[11:31:04] Deleting batch no. 2 consisting of 11 files               base.py:207
[11:31:05] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[11:31:09] Committing batch 1 consisting of 92 files                 base.py:265
[11:31:11] Committing batch 2 consisting of 18 files                 base.py:265
[11:31:12] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-23-11-28">2022-05-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-23 11:28:01.888972</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-23 11:28:11.887368</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:28:01] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[11:28:02] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[11:28:03] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[11:28:04] Deleting batch no. 2 consisting of 11 files               base.py:207
[11:28:05] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[11:28:09] Committing batch 1 consisting of 92 files                 base.py:265
[11:28:10] Committing batch 2 consisting of 18 files                 base.py:265
[11:28:11] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-22-12-06">2022-05-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-22 12:06:30.139897</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-22 12:06:41.024946</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:06:30] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
[12:06:31] Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:06:32] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:06:33] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:06:38] Committing batch 1 consisting of 92 files                 base.py:265
[12:06:39] Committing batch 2 consisting of 18 files                 base.py:265
[12:06:41] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-21-13-38">2022-05-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-21 13:38:10.142851</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-21 13:38:17.970957</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:38:10] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
           ...found 1 files in LCE                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[13:38:11] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[13:38:15] Committing batch 1 consisting of 92 files                 base.py:265
[13:38:16] Committing batch 2 consisting of 18 files                 base.py:265
[13:38:17] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-20-12-41">2022-05-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>15 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-20 12:41:45.875329</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-20 12:42:01.848266</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/var/lang/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/var/lang/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/var/lang/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/var/lang/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/var/lang/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/var/lang/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 173, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 190, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:41:45] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
[12:41:46] Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[12:41:47] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:41:48] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:41:49] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:42:01] ('Connection aborted.', ConnectionResetError(104,      handlers.py:36
           'Connection reset by peer'))                                         
           Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-19-13-15">2022-05-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-19 13:15:12.536333</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-19 13:15:22.775756</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:15:12] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[13:15:13] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:15:15] Deleting batch no. 2 consisting of 11 files               base.py:207
[13:15:16] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[13:15:19] Committing batch 1 consisting of 92 files                 base.py:265
[13:15:21] Committing batch 2 consisting of 18 files                 base.py:265
[13:15:22] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-18-12-28">2022-05-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-18 12:28:44.945730</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-18 12:28:59.388084</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:28:44] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
[12:28:45] Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[12:28:46] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:28:47] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:28:48] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:28:56] Committing batch 1 consisting of 92 files                 base.py:265
[12:28:57] Committing batch 2 consisting of 18 files                 base.py:265
[12:28:59] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-17-14-14">2022-05-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-17 14:14:23.079813</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-17 14:14:33.298791</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:14:23] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
[14:14:24] Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[14:14:25] Deleting batch no. 2 consisting of 11 files               base.py:207
[14:14:26] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[14:14:30] Committing batch 1 consisting of 92 files                 base.py:265
[14:14:31] Committing batch 2 consisting of 18 files                 base.py:265
[14:14:33] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-16-12-32">2022-05-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-16 12:32:34.799062</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-16 12:32:46.161472</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:32:34] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
[12:32:36] Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[12:32:37] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:32:38] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:32:39] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:32:43] Committing batch 1 consisting of 92 files                 base.py:265
[12:32:44] Committing batch 2 consisting of 18 files                 base.py:265
[12:32:46] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-15-12-06">2022-05-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-15 12:06:44.019106</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-15 12:06:51.565942</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:06:44] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
           ...found 1 files in LCE                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[12:06:45] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:06:48] Committing batch 1 consisting of 92 files                 base.py:265
[12:06:50] Committing batch 2 consisting of 18 files                 base.py:265
[12:06:51] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-14-12-01">2022-05-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-14 12:01:21.802251</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-14 12:01:29.409156</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/var/lang/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/var/lang/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/var/lang/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/var/lang/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/var/lang/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/var/lang/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 173, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 190, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:01:21] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[12:01:22] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[12:01:23] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:01:24] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:01:25] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:01:29] ('Connection aborted.', ConnectionResetError(104,      handlers.py:36
           'Connection reset by peer'))                                         
           Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-13-13-27">2022-05-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-13 13:27:29.019501</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-13 13:27:40.557520</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:27:29] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
[13:27:30] Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:27:32] Deleting batch no. 2 consisting of 11 files               base.py:207
[13:27:33] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[13:27:37] Committing batch 1 consisting of 92 files                 base.py:265
[13:27:39] Committing batch 2 consisting of 18 files                 base.py:265
[13:27:40] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-12-12-42">2022-05-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-12 12:42:21.582096</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-12 12:42:31.949659</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:42:21] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
[12:42:22] Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
[12:42:23] ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:42:24] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:42:25] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:42:29] Committing batch 1 consisting of 92 files                 base.py:265
[12:42:30] Committing batch 2 consisting of 18 files                 base.py:265
[12:42:31] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-11-12-30">2022-05-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-11 12:30:16.026079</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-11 12:30:27.663772</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:30:16] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
           Getting all files in LCE/json...                          base.py:182
[12:30:17] ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[12:30:19] Deleting batch no. 2 consisting of 11 files               base.py:207
[12:30:20] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[12:30:24] Committing batch 1 consisting of 92 files                 base.py:265
[12:30:26] Committing batch 2 consisting of 18 files                 base.py:265
[12:30:27] Finished attempting to scrape: LCE                        base.py:315
</pre>
  

  


  <h2 id="2022-05-10-13-26">2022-05-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-10 13:26:19.186433</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-10 13:26:29.666113</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:26:19] Fetching Scraper for: LCE                              handlers.py:23
           Begin attempting to scrape: LCE                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in LCE...                               base.py:182
[13:26:20] Getting all files in LCE/json...                          base.py:182
           ...found 55 files in LCE/json                             base.py:198
           Getting all files in LCE/raw...                           base.py:182
           ...found 55 files in LCE/raw                              base.py:198
           ...found 111 files in LCE                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[13:26:21] Deleting batch no. 2 consisting of 11 files               base.py:207
[13:26:22] ...data deleted.                                          base.py:237
           Scraping from https://cabinet.leicester.gov.uk//mgWebServi base.py:42
           ce.asmx/GetCouncillorsByWard                                         
[13:26:26] Committing batch 1 consisting of 92 files                 base.py:265
[13:26:28] Committing batch 2 consisting of 18 files                 base.py:265
[13:26:29] Finished attempting to scrape: LCE                        base.py:315
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright Â© 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
