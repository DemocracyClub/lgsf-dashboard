<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2023-12-24-10-06">2023-12-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-24 10:06:06.406066</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-24 10:06:08.459700</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fe4a5ae28f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe4a5ae28f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe4a5ae28f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:06:06] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:06:07] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:06:08] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
           HTTPConnectionPool(host='politics.leics.gov.uk',       handlers.py:36
           port=80): Max retries exceeded with url:                             
           //mgWebService.asmx/GetCouncillorsByWard (Caused by                  
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7fe4a5ae28f0>: Failed to establish a new                 
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-23-08-58">2023-12-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-23 08:58:48.649539</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-23 08:58:50.759576</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fd5e8db79a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd5e8db79a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd5e8db79a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:58:48] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
[08:58:49] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:58:50] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
           HTTPConnectionPool(host='politics.leics.gov.uk',       handlers.py:36
           port=80): Max retries exceeded with url:                             
           //mgWebService.asmx/GetCouncillorsByWard (Caused by                  
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7fd5e8db79a0>: Failed to establish a new                 
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-22-08-59">2023-12-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>1 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-22 08:59:56.271693</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-22 08:59:58.187361</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f5e556f5c30>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5e556f5c30>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5e556f5c30>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:59:56] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:59:57] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
           HTTPConnectionPool(host='politics.leics.gov.uk',       handlers.py:36
           port=80): Max retries exceeded with url:                             
           //mgWebService.asmx/GetCouncillorsByWard (Caused by                  
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7f5e556f5c30>: Failed to establish a new                 
           connection: [Errno 111] Connection refused'))                        
[08:59:58] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-21-10-23">2023-12-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-21 10:23:51.698691</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-21 10:23:55.022970</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 497, in _make_request
    conn.request(
  File "/opt/python/urllib3/connection.py", line 395, in request
    self.endheaders()
  File "/var/lang/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/var/lang/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/var/lang/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/opt/python/urllib3/connection.py", line 243, in connect
    self.sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f5138e19270>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5138e19270>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='politics.leics.gov.uk', port=80): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5138e19270>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:23:51] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:23:52] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[10:23:53] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
           Deleting batch no. 2 consisting of 11 files               base.py:230
[10:23:54] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
           HTTPConnectionPool(host='politics.leics.gov.uk',       handlers.py:36
           port=80): Max retries exceeded with url:                             
           //mgWebService.asmx/GetCouncillorsByWard (Caused by                  
           NewConnectionError('<urllib3.connection.HTTPConnection               
           object at 0x7f5138e19270>: Failed to establish a new                 
           connection: [Errno 111] Connection refused'))                        
[10:23:55] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-20-09-54">2023-12-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-20 09:54:54.235155</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-20 09:55:03.891112</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:54:54] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:54:55] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:54:56] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:54:57] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:55:01] Committing batch 1 consisting of 92 files                 base.py:291
[09:55:02] Committing batch 2 consisting of 18 files                 base.py:291
[09:55:03] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-19-09-48">2023-12-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-19 09:48:44.599387</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-19 09:48:54.006177</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:48:44] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
[09:48:45] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:48:46] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:48:50] Committing batch 1 consisting of 92 files                 base.py:291
[09:48:52] Committing batch 2 consisting of 18 files                 base.py:291
[09:48:54] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-18-09-45">2023-12-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-18 09:45:13.687663</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-18 09:45:17.237046</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f78b2833f40>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='politics.leics.gov.uk', port=443): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f78b2833f40>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 725, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 725, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 266, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='politics.leics.gov.uk', port=443): Max retries exceeded with url: //mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f78b2833f40>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:45:13] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
[09:45:14] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[09:45:15] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:45:16] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:45:17] HTTPSConnectionPool(host='politics.leics.gov.uk',      handlers.py:36
           port=443): Max retries exceeded with url:                            
           //mgWebService.asmx/GetCouncillorsByWard (Caused by                  
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f78b2833f40>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-17-09-34">2023-12-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-17 09:34:31.422547</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-17 09:34:42.897883</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:34:31] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:34:32] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:34:33] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:34:34] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:34:40] Committing batch 1 consisting of 92 files                 base.py:291
[09:34:41] Committing batch 2 consisting of 18 files                 base.py:291
[09:34:42] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-16-09-49">2023-12-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-16 09:49:11.279289</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-16 09:49:21.548078</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:49:11] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:49:12] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:49:13] Deleting batch no. 2 consisting of 11 files               base.py:230
[09:49:14] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:49:19] Committing batch 1 consisting of 92 files                 base.py:291
[09:49:20] Committing batch 2 consisting of 18 files                 base.py:291
[09:49:21] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-15-10-20">2023-12-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-15 10:20:29.837864</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-15 10:20:39.763031</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:20:29] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
[10:20:30] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[10:20:31] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:20:32] Deleting batch no. 2 consisting of 11 files               base.py:230
[10:20:33] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[10:20:37] Committing batch 1 consisting of 92 files                 base.py:291
[10:20:38] Committing batch 2 consisting of 18 files                 base.py:291
[10:20:39] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-14-09-42">2023-12-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-14 09:42:43.483381</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-14 09:42:54.611980</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:42:43] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:42:44] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:42:46] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:42:52] Committing batch 1 consisting of 92 files                 base.py:291
[09:42:53] Committing batch 2 consisting of 18 files                 base.py:291
[09:42:54] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-13-09-12">2023-12-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-13 09:12:55.594153</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-13 09:13:05.483054</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:12:55] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:12:56] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:12:57] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
           Deleting batch no. 2 consisting of 11 files               base.py:230
[09:12:58] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:13:03] Committing batch 1 consisting of 92 files                 base.py:291
[09:13:04] Committing batch 2 consisting of 18 files                 base.py:291
[09:13:05] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-12-08-54">2023-12-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-12 08:54:05.632925</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-12 08:54:15.579437</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:54:05] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:54:06] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[08:54:07] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:54:08] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[08:54:13] Committing batch 1 consisting of 92 files                 base.py:291
[08:54:14] Committing batch 2 consisting of 18 files                 base.py:291
[08:54:15] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-11-08-32">2023-12-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-11 08:32:44.627178</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-11 08:32:55.711501</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:32:44] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:32:45] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[08:32:46] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
           Deleting batch no. 2 consisting of 11 files               base.py:230
[08:32:47] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[08:32:53] Committing batch 1 consisting of 92 files                 base.py:291
[08:32:54] Committing batch 2 consisting of 18 files                 base.py:291
[08:32:55] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-10-09-19">2023-12-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-10 09:19:49.972006</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-10 09:19:59.238941</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:19:49] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
[09:19:50] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[09:19:51] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[09:19:52] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:19:57] Committing batch 1 consisting of 92 files                 base.py:291
[09:19:58] Committing batch 2 consisting of 18 files                 base.py:291
[09:19:59] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-09-09-02">2023-12-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-09 09:02:56.596701</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-09 09:03:06.594201</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:02:56] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:02:57] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:02:58] ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
           Deleting batch no. 2 consisting of 11 files               base.py:230
[09:02:59] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[09:03:04] Committing batch 1 consisting of 92 files                 base.py:291
[09:03:05] Committing batch 2 consisting of 18 files                 base.py:291
[09:03:06] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-08-10-32">2023-12-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-08 10:32:32.092480</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-08 10:32:42.577892</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:32:32] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:32:33] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:32:34] Deleting batch no. 2 consisting of 11 files               base.py:230
[10:32:35] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[10:32:40] Committing batch 1 consisting of 92 files                 base.py:291
[10:32:41] Committing batch 2 consisting of 18 files                 base.py:291
[10:32:42] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-07-10-34">2023-12-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-07 10:34:50.437313</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-07 10:35:00.340565</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:34:50] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:34:51] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:34:52] Deleting batch no. 2 consisting of 11 files               base.py:230
[10:34:53] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[10:34:57] Committing batch 1 consisting of 92 files                 base.py:291
[10:34:59] Committing batch 2 consisting of 18 files                 base.py:291
[10:35:00] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-06-08-35">2023-12-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-06 08:35:46.775269</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-06 08:35:57.909770</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:35:46] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
[08:35:47] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[08:35:48] ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[08:35:49] Deleting batch no. 2 consisting of 11 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[08:35:55] Committing batch 1 consisting of 92 files                 base.py:291
[08:35:56] Committing batch 2 consisting of 18 files                 base.py:291
[08:35:57] Finished attempting to scrape: LEC                        base.py:339
</pre>
  

  


  <h2 id="2023-12-05-10-16">2023-12-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-12-05 10:16:40.318638</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-12-05 10:16:49.989797</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:16:40] Fetching Scraper for: LEC                              handlers.py:23
           Begin attempting to scrape: LEC                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:16:41] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 55 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 55 files in Councillors/raw                      base.py:219
           ...found 111 files in Councillors                         base.py:219
           Deleting batch no. 1 consisting of 100 files              base.py:230
[10:16:42] Deleting batch no. 2 consisting of 11 files               base.py:230
[10:16:43] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           http://politics.leics.gov.uk//mgWebService.asmx/GetCouncil           
           lorsByWard                                                           
[10:16:47] Committing batch 1 consisting of 92 files                 base.py:291
[10:16:48] Committing batch 2 consisting of 18 files                 base.py:291
[10:16:49] Finished attempting to scrape: LEC                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
