<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>
        <nav>
          <ul>
            <li><a href="/lgsf-dashboard/">Logbooks</a></li>
            <li><a href="/lgsf-dashboard/service-links/">Service Links</a></li>
          </ul>
        </nav>
      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2025-10-04-14-29">2025-10-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-04 14:29:36.930258</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-04 14:29:44.425994</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:29:36] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[14:29:39] Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
</pre>
  

  


  <h2 id="2025-10-04-08-19">2025-10-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-04 08:19:46.681673</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-04 08:19:53.665040</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:19:46] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:19:47] Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
</pre>
  

  


  <h2 id="2025-10-03-08-33">2025-10-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-03 08:33:37.219065</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-03 08:33:41.187387</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:33:37] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:33:38] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:33:39] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:33:41] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-10-02-08-25">2025-10-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-02 08:25:43.054748</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-02 08:25:55.847073</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 224, in get_councillors
    req = self.get(self.format_councillor_api_url(), extra_headers=self.extra_headers)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 57, in get
    response = self.http_client.get(url, headers=headers, timeout=self.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1053, in get
    return self.request(
           ^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:25:43] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:25:44] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:25:45] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:25:55] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-10-01-08-38">2025-10-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-01 08:38:26.580614</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-01 08:38:32.690450</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:38:26] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:38:27] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:38:28] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:38:32] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-30-08-24">2025-09-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-30 08:24:05.737046</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-30 08:24:18.490978</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 224, in get_councillors
    req = self.get(self.format_councillor_api_url(), extra_headers=self.extra_headers)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 57, in get
    response = self.http_client.get(url, headers=headers, timeout=self.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1053, in get
    return self.request(
           ^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:05] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:24:06] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:24:07] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:24:18] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-29-08-49">2025-09-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-29 08:49:08.694336</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-29 08:49:21.331598</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 224, in get_councillors
    req = self.get(self.format_councillor_api_url(), extra_headers=self.extra_headers)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 57, in get
    response = self.http_client.get(url, headers=headers, timeout=self.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1053, in get
    return self.request(
           ^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:49:08] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:49:09] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:49:10] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:49:20] The read operation timed out                           handlers.py:36
[08:49:21] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-28-08-35">2025-09-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-28 08:35:02.010803</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-28 08:35:05.524245</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:35:02] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:35:03] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:35:04] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:35:05] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-27-08-49">2025-09-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-27 08:49:06.681942</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-27 08:49:10.997941</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:49:06] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:49:07] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:49:08] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:49:10] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-26-08-57">2025-09-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-26 08:57:00.268776</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-26 08:57:06.065605</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:57:00] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:57:01] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:57:02] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:57:05] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:57:06] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-25-08-29">2025-09-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-25 08:29:37.677463</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-25 08:29:42.205753</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:29:37] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:29:38] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:29:39] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:29:41] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:29:42] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-24-08-26">2025-09-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-24 08:26:13.143374</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-24 08:26:16.680163</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:26:13] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:26:14] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:26:15] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:26:16] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-23-08-26">2025-09-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-23 08:26:24.806505</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-23 08:26:28.923943</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:26:24] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:26:25] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:26:26] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:26:28] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-22-08-59">2025-09-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-22 08:59:40.534267</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-22 08:59:45.147054</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:59:40] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:59:41] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:59:42] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:59:44] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:59:45] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-21-08-36">2025-09-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-21 08:36:37.765685</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-21 08:36:42.022614</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:36:37] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:36:38] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:36:39] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:36:41] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:36:42] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-20-08-52">2025-09-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-20 08:52:29.178026</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-20 08:52:33.062410</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:52:29] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:52:30] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:52:31] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:52:32] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:52:33] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-19-08-36">2025-09-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-19 08:36:03.040253</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-19 08:36:06.647595</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:36:03] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:36:04] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:36:05] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:36:06] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-18-08-28">2025-09-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-18 08:28:51.110552</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-18 08:28:55.042069</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:28:51] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:28:52] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:28:53] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:28:54] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:28:55] Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-17-08-31">2025-09-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-17 08:31:56.780932</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-17 08:32:00.742838</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:31:56] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
[08:31:57] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:31:58] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:32:00] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  

  


  <h2 id="2025-09-16-08-35">2025-09-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-16 08:35:18.355837</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-16 08:35:22.399259</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:35:18] Fetching Scraper for: HAL                              handlers.py:23
           Begin attempting to scrape: HAL                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:35:19] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:35:20] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://councillors.halton.gov.uk/mgWebService.asmx/GetCoun           
           cillorsByWard                                                        
[08:35:22] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: HAL                        base.py:351
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
