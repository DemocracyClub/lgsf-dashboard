<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-05-06-09-42">2024-05-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-06 09:42:17.985185</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-06 09:42:27.160461</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:42:17] Fetching Scraper for: SOL                              handlers.py:23
[09:42:18] Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:42:19] Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:42:20] Deleting batch no. 2 consisting of 3 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[09:42:25] Committing batch 1 consisting of 92 files                 base.py:297
[09:42:26] Committing batch 2 consisting of 10 files                 base.py:297
[09:42:27] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-05-05-10-16">2024-05-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-05 10:16:02.108817</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-05 10:16:13.919928</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:16:02] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[10:16:03] Deleting existing data...                                 base.py:257
[10:16:04] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:16:05] Deleting batch no. 2 consisting of 3 files                base.py:236
[10:16:06] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[10:16:11] Committing batch 1 consisting of 92 files                 base.py:297
[10:16:12] Committing batch 2 consisting of 10 files                 base.py:297
[10:16:13] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-05-04-08-27">2024-05-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-04 08:27:22.870481</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-04 08:27:32.366509</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:27:22] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[08:27:23] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[08:27:24] ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:27:25] Deleting batch no. 2 consisting of 3 files                base.py:236
[08:27:26] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[08:27:30] Committing batch 1 consisting of 92 files                 base.py:297
[08:27:31] Committing batch 2 consisting of 10 files                 base.py:297
[08:27:32] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-05-03-08-52">2024-05-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-03 08:52:30.932524</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-03 08:52:40.163216</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:52:30] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[08:52:31] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[08:52:32] Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:52:33] Deleting batch no. 2 consisting of 3 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[08:52:38] Committing batch 1 consisting of 92 files                 base.py:297
[08:52:39] Committing batch 2 consisting of 10 files                 base.py:297
[08:52:40] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-05-02-10-21">2024-05-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-02 10:21:19.848699</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-02 10:21:28.606372</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:21:19] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[10:21:20] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
[10:21:21] ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[10:21:22] Deleting batch no. 2 consisting of 3 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[10:21:26] Committing batch 1 consisting of 92 files                 base.py:297
[10:21:27] Committing batch 2 consisting of 10 files                 base.py:297
[10:21:28] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-05-01-10-30">2024-05-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-05-01 10:30:46.727123</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-05-01 10:30:56.294509</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:30:46] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[10:30:47] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[10:30:48] ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 3 files                base.py:236
[10:30:49] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[10:30:54] Committing batch 1 consisting of 92 files                 base.py:297
[10:30:55] Committing batch 2 consisting of 10 files                 base.py:297
[10:30:56] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-30-08-22">2024-04-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-30 08:22:54.015469</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-30 08:23:02.882942</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:22:54] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[08:22:55] Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[08:22:56] Deleting batch no. 2 consisting of 3 files                base.py:236
[08:22:57] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[08:23:00] Committing batch 1 consisting of 92 files                 base.py:297
[08:23:01] Committing batch 2 consisting of 10 files                 base.py:297
[08:23:02] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-29-09-40">2024-04-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-29 09:40:07.252939</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-29 09:40:18.812177</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:40:07] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[09:40:09] Deleting existing data...                                 base.py:257
[09:40:10] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[09:40:11] Deleting batch no. 2 consisting of 3 files                base.py:236
[09:40:12] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[09:40:16] Committing batch 1 consisting of 92 files                 base.py:297
[09:40:17] Committing batch 2 consisting of 10 files                 base.py:297
[09:40:18] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-28-09-10">2024-04-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-28 09:10:49.552889</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-28 09:10:59.242152</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:49] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:10:50] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
[09:10:51] ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
           Deleting batch no. 2 consisting of 3 files                base.py:236
[09:10:52] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[09:10:56] Committing batch 1 consisting of 92 files                 base.py:297
[09:10:57] Committing batch 2 consisting of 10 files                 base.py:297
[09:10:59] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-27-17-58">2024-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-27 17:58:33.483046</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-27 17:58:44.788001</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:58:33] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:257
[17:58:34] Getting all files in Councillors...                       base.py:209
           Getting all files in Councillors/json...                  base.py:209
           ...found 51 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 51 files in Councillors/raw                      base.py:225
           ...found 103 files in Councillors                         base.py:225
           Deleting batch no. 1 consisting of 100 files              base.py:236
[17:58:35] Deleting batch no. 2 consisting of 3 files                base.py:236
[17:58:36] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[17:58:42] Committing batch 1 consisting of 92 files                 base.py:297
[17:58:43] Committing batch 2 consisting of 10 files                 base.py:297
[17:58:44] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-27-08-33">2024-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-27 08:33:04.685923</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-27 08:33:12.571052</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:33:04] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[08:33:05] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:33:06] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://democracy.solihull.gov.uk/mgWebService.asmx/GetCou           
           ncillorsByWard                                                       
[08:33:10] Committing batch 1 consisting of 92 files                 base.py:297
[08:33:11] Committing batch 2 consisting of 10 files                 base.py:297
[08:33:12] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-16-33">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 16:33:39.782532</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 16:33:42.032633</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 199, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 218, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[16:33:39] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[16:33:40] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[16:33:41] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           [Errno 111] Connection refused                         handlers.py:36
[16:33:42] Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-10-39">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 10:39:53.352953</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 10:39:55.368861</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 199, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 218, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:39:53] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:39:54] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:39:55] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           [Errno 111] Connection refused                         handlers.py:36
           Finished attempting to scrape: SOL                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-08-58">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 08:58:24.791210</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 08:58:26.807008</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f95498943a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f95498943a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f95498943a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:58:24] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[08:58:25] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:58:26] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f95498943a0>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: SOL                        base.py:339
</pre>
  

  


  <h2 id="2024-04-25-09-04">2024-04-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-25 09:04:33.590514</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-25 09:04:35.683871</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f065f743e20>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f065f743e20>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f065f743e20>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:04:33] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:04:34] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:04:35] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f065f743e20>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: SOL                        base.py:339
</pre>
  

  


  <h2 id="2024-04-24-08-31">2024-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>1 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-24 08:31:40.019433</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-24 08:31:42.004857</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fa1329b3220>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa1329b3220>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa1329b3220>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:31:40] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[08:31:41] ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7fa1329b3220>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
[08:31:42] Finished attempting to scrape: SOL                        base.py:339
</pre>
  

  


  <h2 id="2024-04-23-09-53">2024-04-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>1 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-23 09:53:53.693460</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-23 09:53:55.662034</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f0b5f20a8f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f0b5f20a8f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f0b5f20a8f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:53:53] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[09:53:54] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[09:53:55] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f0b5f20a8f0>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: SOL                        base.py:339
</pre>
  

  


  <h2 id="2024-04-22-10-09">2024-04-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-22 10:09:25.333831</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-22 10:09:27.374562</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f292e63b460>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f292e63b460>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f292e63b460>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:09:25] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:09:26] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:09:27] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f292e63b460>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: SOL                        base.py:339
</pre>
  

  


  <h2 id="2024-04-21-08-56">2024-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-21 08:56:26.555511</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-21 08:56:28.595989</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f9573c50d30>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9573c50d30>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9573c50d30>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:56:26] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:56:27] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:56:28] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f9573c50d30>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: SOL                        base.py:339
</pre>
  

  


  <h2 id="2024-04-20-10-16">2024-04-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-20 10:16:38.792483</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-20 10:16:40.844657</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f93ff872890>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f93ff872890>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='eservices.solihull.gov.uk', port=443): Max retries exceeded with url: /mgInternet/mgWebService.asmx/GetCouncillorsByWard (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f93ff872890>: Failed to establish a new connection: [Errno 111] Connection refused'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:16:38] Fetching Scraper for: SOL                              handlers.py:23
           Begin attempting to scrape: SOL                        handlers.py:27
[10:16:39] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[10:16:40] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://eservices.solihull.gov.uk/mgInternet/mgWebService.           
           asmx/GetCouncillorsByWard                                            
           HTTPSConnectionPool(host='eservices.solihull.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgInternet/mgWebService.asmx/GetCouncillorsByWard                   
           (Caused by                                                           
           NewConnectionError('<urllib3.connection.HTTPSConnectio               
           n object at 0x7f93ff872890>: Failed to establish a new               
           connection: [Errno 111] Connection refused'))                        
           Finished attempting to scrape: SOL                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
