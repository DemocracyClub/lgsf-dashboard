<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-04-21-13-36">2022-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-21 13:36:20.850527</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-21 13:36:31.112326</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:36:20] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[13:36:21] Getting all files in HRY...                               base.py:180
           Getting all files in HRY/json...                          base.py:180
[13:36:22] ...found 57 files in HRY/json                             base.py:196
           Getting all files in HRY/raw...                           base.py:180
           ...found 57 files in HRY/raw                              base.py:196
           ...found 115 files in HRY                                 base.py:196
           Deleting batch no. 1 consisting of 100 files              base.py:205
[13:36:23] Deleting batch no. 2 consisting of 15 files               base.py:205
[13:36:24] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[13:36:28] Committing batch 1 consisting of 92 files                 base.py:263
[13:36:29] Committing batch 2 consisting of 22 files                 base.py:263
[13:36:31] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-20-16-07">2022-04-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-20 16:07:22.109638</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-20 16:07:32.352681</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[16:07:22] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
[16:07:23] Getting all files in HRY/json...                          base.py:180
           ...found 57 files in HRY/json                             base.py:196
           Getting all files in HRY/raw...                           base.py:180
           ...found 57 files in HRY/raw                              base.py:196
           ...found 115 files in HRY                                 base.py:196
           Deleting batch no. 1 consisting of 100 files              base.py:205
[16:07:24] Deleting batch no. 2 consisting of 15 files               base.py:205
[16:07:25] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[16:07:29] Committing batch 1 consisting of 92 files                 base.py:263
[16:07:30] Committing batch 2 consisting of 22 files                 base.py:263
[16:07:32] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-19-11-17">2022-04-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-19 11:17:05.908497</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-19 11:17:16.096021</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:17:05] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
[11:17:06] Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
           Getting all files in HRY/json...                          base.py:180
[11:17:07] ...found 57 files in HRY/json                             base.py:196
           Getting all files in HRY/raw...                           base.py:180
           ...found 57 files in HRY/raw                              base.py:196
           ...found 115 files in HRY                                 base.py:196
           Deleting batch no. 1 consisting of 100 files              base.py:205
[11:17:08] Deleting batch no. 2 consisting of 15 files               base.py:205
[11:17:09] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[11:17:13] Committing batch 1 consisting of 92 files                 base.py:263
[11:17:14] Committing batch 2 consisting of 22 files                 base.py:263
[11:17:16] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-18-17-57">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 17:57:11.478107</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 17:57:21.527053</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:57:11] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[17:57:12] Getting all files in HRY...                               base.py:180
           Getting all files in HRY/json...                          base.py:180
           ...found 57 files in HRY/json                             base.py:196
           Getting all files in HRY/raw...                           base.py:180
           ...found 57 files in HRY/raw                              base.py:196
           ...found 115 files in HRY                                 base.py:196
           Deleting batch no. 1 consisting of 100 files              base.py:205
[17:57:14] Deleting batch no. 2 consisting of 15 files               base.py:205
[17:57:15] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[17:57:18] Committing batch 1 consisting of 92 files                 base.py:263
[17:57:20] Committing batch 2 consisting of 22 files                 base.py:263
[17:57:21] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-18-17-20">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 17:20:08.007447</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 17:20:18.250460</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:20:08] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
           Getting all files in HRY/json...                          base.py:180
[17:20:09] ...found 57 files in HRY/json                             base.py:196
           Getting all files in HRY/raw...                           base.py:180
           ...found 57 files in HRY/raw                              base.py:196
           ...found 115 files in HRY                                 base.py:196
           Deleting batch no. 1 consisting of 100 files              base.py:205
[17:20:10] Deleting batch no. 2 consisting of 15 files               base.py:205
[17:20:11] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[17:20:15] Committing batch 1 consisting of 92 files                 base.py:263
[17:20:16] Committing batch 2 consisting of 22 files                 base.py:263
[17:20:18] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-18-08-01">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 08:01:48.081339</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 08:01:56.870028</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:01:48] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
[08:01:49] ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
           ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[08:01:53] Committing batch 1 consisting of 92 files                 base.py:263
[08:01:55] Committing batch 2 consisting of 22 files                 base.py:263
[08:01:56] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-18-02-19">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>400 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 02:19:48.347646</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 02:26:28.914921</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[02:19:48] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[02:19:49] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[02:19:50] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[02:26:28] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-18-02-05">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>315 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 02:05:47.709678</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 02:11:03.348185</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[02:05:47] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[02:05:48] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[02:05:49] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[02:11:02] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
[02:11:03] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-18-01-43">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>226 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 01:43:17.516588</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 01:47:04.329519</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[01:43:17] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[01:43:18] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[01:43:19] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[01:47:03] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
[01:47:04] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-23-19">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>243 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 23:19:46.900369</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 23:23:50.305676</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 667, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 667, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[23:19:46] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
[23:19:47] Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[23:19:48] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[23:23:49] ('Connection aborted.', RemoteDisconnected('Remote end handlers.py:36
           closed connection without response'))                                
[23:23:50] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-22-15">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>329 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 22:15:47.319142</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 22:21:16.646690</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[22:15:47] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[22:15:48] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[22:15:49] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[22:21:16] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-22-10">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>295 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 22:10:33.861810</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 22:15:29.164035</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[22:10:33] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[22:10:34] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[22:10:35] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[22:15:28] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
[22:15:29] Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-21-58">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>210 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 21:58:17.615190</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 22:01:48.002363</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 667, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 667, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[21:58:17] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[21:58:18] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[21:58:19] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[22:01:47] ('Connection aborted.', RemoteDisconnected('Remote end handlers.py:36
           closed connection without response'))                                
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-21-38">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>316 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 21:38:16.465016</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 21:43:32.476368</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[21:38:16] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[21:38:17] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[21:38:18] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[21:43:32] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-21-21">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>371 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 21:21:48.185768</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 21:27:59.426581</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[21:21:48] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
[21:21:49] ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[21:21:50] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[21:27:59] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-17-31">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>216 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 17:31:17.495744</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 17:34:53.811389</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[17:31:17] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[17:31:18] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[17:31:19] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[17:34:53] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-16-52">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>181 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 16:52:43.962256</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 16:55:44.970018</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[16:52:43] Fetching Scraper for: HRY                              handlers.py:23
[16:52:44] Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[16:52:45] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[16:55:44] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-16-18">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>359 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 16:18:00.381551</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 16:23:59.776638</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[16:18:00] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[16:18:01] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[16:18:02] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[16:23:59] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-13-31">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>413 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 13:31:09.709715</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 13:38:02.847348</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:31:09] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[13:31:10] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[13:31:11] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[13:38:02] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-11-51">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>223 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 11:51:26.640697</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 11:55:10.588518</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/opt/python/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/opt/python/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/var/lang/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/var/lang/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/var/lang/lib/python3.8/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 46, in get
    response = requests.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/python/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 667, in send
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 667, in <listcomp>
    history = [resp for resp in gen]
  File "/opt/python/requests/sessions.py", line 237, in resolve_redirects
    resp = self.send(
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:51:26] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
           Deleting existing data...                                 base.py:228
[11:51:27] Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:51:28] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[11:55:10] ('Connection aborted.', RemoteDisconnected('Remote end handlers.py:36
           closed connection without response'))                                
           Finished attempting to scrape: HRY                        base.py:313
</pre>

  <h2 id="2022-04-17-11-03">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>207 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 11:03:07.984285</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 11:06:35.826681</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 166, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 183, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.minutes.haringey.gov.uk/mgError.aspx
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:03:07] Fetching Scraper for: HRY                              handlers.py:23
           Begin attempting to scrape: HRY                        handlers.py:27
[11:03:08] Deleting existing data...                                 base.py:228
           Getting all files in HRY...                               base.py:180
           ...found 1 files in HRY                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:03:09] ...data deleted.                                          base.py:235
           Scraping from http://www.minutes.haringey.gov.uk/mgWebServ base.py:40
           ice.asmx/GetCouncillorsByWard                                        
[11:06:35] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.minutes.haringey.gov.uk/mgError.aspx                     
           Finished attempting to scrape: HRY                        base.py:313
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
