<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  

  

  


  <h2 id="2022-06-27-15-30">2022-06-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-06-27 15:30:29.521799</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-06-27 15:32:42.205988</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fb04e543340>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb04e543340>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 242, in get_councillors
    req = self.get(self.base_url, extra_headers=self.extra_headers)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb04e543340>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:30:29] Fetching Scraper for: WLL                              handlers.py:23
           Begin attempting to scrape: WLL                        handlers.py:27
           Deleting existing data...                                 base.py:230
[15:30:30] Getting all files in WLL...                               base.py:182
           ...found 1 files in WLL                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[15:30:31] ...data deleted.                                          base.py:237
           Scraping from                                              base.py:42
           https://cmispublic.walsall.gov.uk/cmis/Councillors.aspx              
[15:32:41] HTTPSConnectionPool(host='cmispublic.walsall.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /cmis/Councillors.aspx (Caused by NewConnectionError('               
           <urllib3.connection.HTTPSConnection object at                        
           0x7fb04e543340>: Failed to establish a new connection:               
           [Errno 110] Connection timed out'))                                  
[15:32:42] Finished attempting to scrape: WLL                        base.py:315
</pre>
  

  

  

  

  

  

  

  


  <h2 id="2022-06-20-14-07">2022-06-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>131 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-06-20 14:07:11.930570</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-06-20 14:09:23.441421</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7ff81bc27190>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff81bc27190>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 242, in get_councillors
    req = self.get(self.base_url, extra_headers=self.extra_headers)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff81bc27190>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:07:11] Fetching Scraper for: WLL                              handlers.py:23
           Begin attempting to scrape: WLL                        handlers.py:27
[14:07:12] Deleting existing data...                                 base.py:230
           Getting all files in WLL...                               base.py:182
           ...found 1 files in WLL                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[14:07:13] ...data deleted.                                          base.py:237
           Scraping from                                              base.py:42
           https://cmispublic.walsall.gov.uk/cmis/Councillors.aspx              
[14:09:23] HTTPSConnectionPool(host='cmispublic.walsall.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /cmis/Councillors.aspx (Caused by NewConnectionError('               
           <urllib3.connection.HTTPSConnection object at                        
           0x7ff81bc27190>: Failed to establish a new connection:               
           [Errno 110] Connection timed out'))                                  
           Finished attempting to scrape: WLL                        base.py:315
</pre>
  

  

  

  

  

  

  

  


  <h2 id="2022-06-13-18-00">2022-06-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>134 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-06-13 18:00:23.585482</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-06-13 18:02:37.619320</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f4bde890ee0>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4bde890ee0>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 242, in get_councillors
    req = self.get(self.base_url, extra_headers=self.extra_headers)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4bde890ee0>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:00:23] Fetching Scraper for: WLL                              handlers.py:23
           Begin attempting to scrape: WLL                        handlers.py:27
           Deleting existing data...                                 base.py:230
[18:00:24] Getting all files in WLL...                               base.py:182
           Getting all files in WLL/json...                          base.py:182
           ...found 60 files in WLL/json                             base.py:198
           Getting all files in WLL/raw...                           base.py:182
[18:00:25] ...found 60 files in WLL/raw                              base.py:198
           ...found 121 files in WLL                                 base.py:198
           Deleting batch no. 1 consisting of 100 files              base.py:207
[18:00:26] Deleting batch no. 2 consisting of 21 files               base.py:207
[18:00:27] ...data deleted.                                          base.py:237
           Scraping from                                              base.py:42
           https://cmispublic.walsall.gov.uk/cmis/Councillors.aspx              
[18:02:37] HTTPSConnectionPool(host='cmispublic.walsall.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /cmis/Councillors.aspx (Caused by NewConnectionError('               
           <urllib3.connection.HTTPSConnection object at                        
           0x7f4bde890ee0>: Failed to establish a new connection:               
           [Errno 110] Connection timed out'))                                  
           Finished attempting to scrape: WLL                        base.py:315
</pre>
  

  


  <h2 id="2022-06-12-12-53">2022-06-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>283 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-06-12 12:53:54.455592</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-06-12 12:58:38.036002</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:53:54] Fetching Scraper for: WLL                              handlers.py:23
           Begin attempting to scrape: WLL                        handlers.py:27
           Deleting existing data...                                 base.py:230
[12:53:55] Getting all files in WLL...                               base.py:182
           ...found 1 files in WLL                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[12:53:56] ...data deleted.                                          base.py:237
           Scraping from                                              base.py:42
           https://cmispublic.walsall.gov.uk/cmis/Councillors.aspx              
[12:53:57] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/520/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:02] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/470/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:07] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/36/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:54:14] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/578/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:15] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/522/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:19] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/41/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:54:27] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/334/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:31] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/31/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:54:38] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/30/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:54:44] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/584/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:46] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/57/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:54:51] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/457/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:54:56] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/229/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:02] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/472/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:06] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/559/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:11] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/455/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:16] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/561/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:20] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/454/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:24] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/563/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:27] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/580/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:29] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/473/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:33] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/9/ScreenMode           
           /Alphabetical/Default.aspx                                           
[12:55:41] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/64/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:55:46] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/459/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:52] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/583/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:53] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/557/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:57] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/585/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:55:58] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/368/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:06] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/581/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:07] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/68/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:56:11] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/524/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:15] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/373/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:18] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/519/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:23] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/579/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:25] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/558/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:30] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/32/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:56:36] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/523/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:40] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/582/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:42] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/560/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:47] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/29/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:56:53] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/518/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:56:56] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/397/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:04] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/474/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:08] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/556/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:11] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/38/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:57:17] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/501/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:23] Committing batch 1 consisting of 92 files                 base.py:265
[12:57:24] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/367/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:30] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/504/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:37] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/5/ScreenMode           
           /Alphabetical/Default.aspx                                           
[12:57:44] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/382/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:49] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/564/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:52] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/521/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:55] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/500/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:57:59] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/42/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:58:05] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/63/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:58:10] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/505/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:58:17] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/562/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:58:20] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/379/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:58:25] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/384/ScreenMo           
           de/Alphabetical/Default.aspx                                         
[12:58:31] Scraping from http://cmispublic.walsall.gov.uk/cmis/Counci base.py:42
           llors/tabid/63/ctl/ViewCMIS_Person/mid/383/id/18/ScreenMod           
           e/Alphabetical/Default.aspx                                          
[12:58:35] Committing batch 2 consisting of 28 files                 base.py:265
[12:58:38] Finished attempting to scrape: WLL                        base.py:315
</pre>
  

  


  <h2 id="2022-06-11-12-45">2022-06-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-06-11 12:45:37.269097</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-06-11 12:47:49.493662</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7face509c580>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7face509c580>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 242, in get_councillors
    req = self.get(self.base_url, extra_headers=self.extra_headers)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7face509c580>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:45:37] Fetching Scraper for: WLL                              handlers.py:23
           Begin attempting to scrape: WLL                        handlers.py:27
           Deleting existing data...                                 base.py:230
[12:45:38] Getting all files in WLL...                               base.py:182
           ...found 1 files in WLL                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[12:45:39] ...data deleted.                                          base.py:237
           Scraping from                                              base.py:42
           https://cmispublic.walsall.gov.uk/cmis/Councillors.aspx              
[12:47:49] HTTPSConnectionPool(host='cmispublic.walsall.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /cmis/Councillors.aspx (Caused by NewConnectionError('               
           <urllib3.connection.HTTPSConnection object at                        
           0x7face509c580>: Failed to establish a new connection:               
           [Errno 110] Connection timed out'))                                  
           Finished attempting to scrape: WLL                        base.py:315
</pre>
  

  


  <h2 id="2022-06-10-14-39">2022-06-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>132 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-06-10 14:39:02.745407</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-06-10 14:41:15.366291</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/opt/python/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/opt/python/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 358, in connect
    conn = self._new_conn()
  File "/opt/python/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7faad3a7bca0>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7faad3a7bca0>: Failed to establish a new connection: [Errno 110] Connection timed out'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 242, in get_councillors
    req = self.get(self.base_url, extra_headers=self.extra_headers)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/opt/python/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cmispublic.walsall.gov.uk', port=443): Max retries exceeded with url: /cmis/Councillors.aspx (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7faad3a7bca0>: Failed to establish a new connection: [Errno 110] Connection timed out'))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:39:02] Fetching Scraper for: WLL                              handlers.py:23
           Begin attempting to scrape: WLL                        handlers.py:27
           Deleting existing data...                                 base.py:230
[14:39:03] Getting all files in WLL...                               base.py:182
           ...found 1 files in WLL                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[14:39:04] ...data deleted.                                          base.py:237
           Scraping from                                              base.py:42
           https://cmispublic.walsall.gov.uk/cmis/Councillors.aspx              
[14:41:15] HTTPSConnectionPool(host='cmispublic.walsall.gov.uk',  handlers.py:36
           port=443): Max retries exceeded with url:                            
           /cmis/Councillors.aspx (Caused by NewConnectionError('               
           <urllib3.connection.HTTPSConnection object at                        
           0x7faad3a7bca0>: Failed to establish a new connection:               
           [Errno 110] Connection timed out'))                                  
           Finished attempting to scrape: WLL                        base.py:315
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
