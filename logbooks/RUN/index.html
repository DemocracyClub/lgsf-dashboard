<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2022-05-01-11-42">2022-05-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-05-01 11:42:11.909621</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-05-01 11:42:20.020585</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:42:11] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
[11:42:12] Deleting existing data...                                 base.py:230
           Getting all files in RUN...                               base.py:182
           Getting all files in RUN/json...                          base.py:182
[11:42:13] ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[11:42:14] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[11:42:18] Committing batch 1 consisting of 82 files                 base.py:265
[11:42:20] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-30-14-03">2022-04-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-30 14:03:50.230286</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-30 14:03:59.588271</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:03:50] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in RUN...                               base.py:182
[14:03:51] Getting all files in RUN/json...                          base.py:182
           ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[14:03:52] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[14:03:57] Committing batch 1 consisting of 82 files                 base.py:265
[14:03:59] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-29-14-45">2022-04-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-29 14:45:49.082700</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-29 14:45:56.987298</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:45:49] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in RUN...                               base.py:182
[14:45:50] Getting all files in RUN/json...                          base.py:182
           ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[14:45:51] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[14:45:55] Committing batch 1 consisting of 82 files                 base.py:265
[14:45:56] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-28-14-10">2022-04-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-28 14:10:49.159798</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-28 14:10:58.000628</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:10:49] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in RUN...                               base.py:182
[14:10:50] Getting all files in RUN/json...                          base.py:182
           ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[14:10:51] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[14:10:56] Committing batch 1 consisting of 82 files                 base.py:265
[14:10:57] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-27-13-17">2022-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>34 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-27 13:17:56.041687</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-27 13:18:30.654835</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:17:56] Fetching Scraper for: RUN                              handlers.py:23
[13:18:01] Begin attempting to scrape: RUN                        handlers.py:27
[13:18:02] Deleting existing data...                                 base.py:230
[13:18:03] Getting all files in RUN...                               base.py:182
           Getting all files in RUN/json...                          base.py:182
           ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[13:18:04] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[13:18:28] Committing batch 1 consisting of 82 files                 base.py:265
[13:18:30] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-26-11-59">2022-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-26 11:59:02.038659</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-26 11:59:10.961284</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:59:02] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in RUN...                               base.py:182
           Getting all files in RUN/json...                          base.py:182
[11:59:03] ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[11:59:04] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[11:59:09] Committing batch 1 consisting of 82 files                 base.py:265
[11:59:10] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-25-11-27">2022-04-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-25 11:27:29.533783</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-25 11:27:38.866011</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:27:29] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:230
[11:27:30] Getting all files in RUN...                               base.py:182
           Getting all files in RUN/json...                          base.py:182
           ...found 41 files in RUN/json                             base.py:198
           Getting all files in RUN/raw...                           base.py:182
           ...found 41 files in RUN/raw                              base.py:198
           ...found 83 files in RUN                                  base.py:198
           Deleting batch no. 1 consisting of 83 files               base.py:207
[11:27:31] ...data deleted.                                          base.py:237
           Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[11:27:37] Committing batch 1 consisting of 82 files                 base.py:265
[11:27:38] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-24-18-16">2022-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-24 18:16:20.008240</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-24 18:16:27.601344</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[18:16:20] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:230
           Getting all files in RUN...                               base.py:182
           ...found 1 files in RUN                                   base.py:198
           Deleting batch no. 1 consisting of 1 files                base.py:207
[18:16:21] ...data deleted.                                          base.py:237
[18:16:22] Scraping from https://democracy.runnymede.gov.uk/mgWebServ base.py:42
           ice.asmx/GetCouncillorsByWard                                        
[18:16:26] Committing batch 1 consisting of 82 files                 base.py:265
[18:16:27] Finished attempting to scrape: RUN                        base.py:315
</pre>
  

  


  <h2 id="2022-04-23-13-38">2022-04-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-23 13:38:15.125207</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-23 13:38:17.479151</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 142, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 138, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 123, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:38:15] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
           Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
[13:38:16] Deleting batch no. 1 consisting of 1 files                base.py:205
           ...data deleted.                                          base.py:235
[13:38:17] Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-22-11-58">2022-04-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-22 11:58:07.453895</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-22 11:58:10.007576</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 142, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 138, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 123, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:58:07] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[11:58:08] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:58:09] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
[11:58:10] Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-21-15-47">2022-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-21 15:47:05.719581</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-21 15:47:08.970133</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:47:05] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[15:47:06] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[15:47:07] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
[15:47:08] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-20-11-21">2022-04-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-20 11:21:11.397205</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-20 11:21:14.275719</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:21:11] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[11:21:12] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:21:13] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
[11:21:14] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-19-11-16">2022-04-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-19 11:16:16.336615</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-19 11:16:18.709186</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:16] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[11:16:17] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[11:16:18] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-18-13-47">2022-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-18 13:47:20.879328</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-18 13:47:23.350053</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:47:20] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[13:47:21] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[13:47:22] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
[13:47:23] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-17-13-04">2022-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-17 13:04:46.917831</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-17 13:04:49.282587</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:04:46] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
[13:04:47] Deleting existing data...                                 base.py:228
           Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[13:04:48] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
[13:04:49] 404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-16-12-18">2022-04-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-16 12:18:42.516492</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-16 12:18:44.915606</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:18:42] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[12:18:43] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[12:18:44] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-15-13-32">2022-04-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-15 13:32:06.850654</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-15 13:32:09.203200</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:32:06] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[13:32:07] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[13:32:08] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
[13:32:09] Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-14-12-56">2022-04-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-14 12:56:01.408406</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-14 12:56:03.837439</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:56:01] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[12:56:02] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[12:56:03] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-13-14-44">2022-04-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-13 14:44:37.422561</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-13 14:44:39.890560</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:44:37] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:27
           Deleting existing data...                                 base.py:228
[14:44:38] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[14:44:39] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:36
           https://www.runnymede.gov.uk/article/15001/Councillors               
           Finished attempting to scrape: RUN                        base.py:313
</pre>
  

  


  <h2 id="2022-04-12-12-41">2022-04-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-12 12:41:04.670267</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-12 12:41:07.180749</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 31, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 46, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 134, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 130, in get_list_container
    soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 115, in get_page
    page = self.get(url).text
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response.raise_for_status()
  File "/opt/python/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.runnymede.gov.uk/article/15001/Councillors
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:41:04] Fetching Scraper for: RUN                              handlers.py:23
           Begin attempting to scrape: RUN                        handlers.py:26
           Deleting existing data...                                 base.py:228
[12:41:05] Getting all files in RUN...                               base.py:180
           ...found 1 files in RUN                                   base.py:196
           Deleting batch no. 1 consisting of 1 files                base.py:205
[12:41:06] ...data deleted.                                          base.py:235
           Scraping from                                              base.py:40
           https://www.runnymede.gov.uk/article/15001/Councillors               
           404 Client Error: Not Found for url:                   handlers.py:35
           https://www.runnymede.gov.uk/article/15001/Councillors               
[12:41:07] Finished attempting to scrape: RUN                        base.py:313
</pre>
  


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
