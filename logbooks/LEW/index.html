<!doctype html>
<html>
  <head>
    <title>Page title</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <style>



    </style>

  </head>
  <body>



    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  <h2 id="2022-04-03-11-37">2022-04-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-03 11:37:31.249679</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-03 11:37:39.971216</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:37:31] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
           ...found 55 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
[11:37:32] ...found 55 files in LEW/raw                              base.py:202
           ...found 111 files in LEW                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:37:34] Deleting batch no. 2 consisting of 11 files               base.py:211
[11:37:39] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-04-02-11-36">2022-04-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-02 11:36:44.314310</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-02 11:36:51.377222</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:36:44] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
           ...found 55 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
[11:36:45] ...found 55 files in LEW/raw                              base.py:202
           ...found 111 files in LEW                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:36:51] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-04-01-11-15">2022-04-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-01 11:15:49.180542</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-01 11:16:05.988484</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:16:05] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-04-01-00-02">2022-04-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>25 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-04-01 00:02:22.206011</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-04-01 00:02:47.408068</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:02:47] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-30-11-17">2022-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-30 11:17:13.664636</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-30 11:17:22.840970</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:17:13] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:17:14] Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
           ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
[11:17:15] ...found 46 files in LEW/raw                              base.py:202
           ...found 93 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[11:17:16] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:17:19] Committing batch 1 consisting of 92 files                 base.py:269
[11:17:20] Committing batch 2 consisting of 18 files                 base.py:269
[11:17:22] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-29-11-46">2022-03-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-29 11:46:22.543149</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-29 11:46:32.430920</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:46:22] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
[11:46:23] Getting all files in LEW/json...                          base.py:186
           ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 46 files in LEW/raw                              base.py:202
           ...found 92 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[11:46:32] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-28-11-36">2022-03-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-28 11:36:17.923320</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-28 11:36:23.195431</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:36:17] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
[11:36:18] Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
           ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
[11:36:19] ...found 46 files in LEW/raw                              base.py:202
           ...found 92 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[11:36:22] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[11:36:23] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-27-11-14">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>16 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 11:14:36.673580</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 11:14:53.529753</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (InvalidTargetBranchException) when calling the MergeBranchesBySquash operation: Target branch parameter must point to either source or destination tip commit. Verify your target branch value is valid and then try again</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:14:49] Created log commit                                        base.py:376
           300819825afbe72d322eb2d6c99296a5ff993c69                             
           Attempting to create merge commit...                      base.py:281
[11:14:53] An error occurred (InvalidTargetBranchException) when  handlers.py:34
           calling the MergeBranchesBySquash operation: Target                  
           branch parameter must point to either source or                      
           destination tip commit. Verify your target branch                    
           value is valid and then try again                                    
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-27-00-03">2022-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-27 00:03:03.390263</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-27 00:03:12.421137</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:03:03] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
[00:03:04] ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 46 files in LEW/raw                              base.py:202
           ...found 92 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[00:03:05] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[00:03:07] Committing batch 1 consisting of 92 files                 base.py:269
[00:03:09] Committing batch 2 consisting of 18 files                 base.py:269
[00:03:12] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-26-11-19">2022-03-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-26 11:19:20.244244</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-26 11:19:25.027260</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:19:20] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           ...found 1 files in LEW                                   base.py:202
           Deleting batch no. 1 consisting of 1 files                base.py:211
[11:19:22] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:19:25] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-25-11-40">2022-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-25 11:40:44.959979</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-25 11:41:06.444839</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:40:44] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
[11:40:45] Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
[11:40:46] ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 46 files in LEW/raw                              base.py:202
           ...found 93 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[11:40:47] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:40:51] Committing batch 1 consisting of 92 files                 base.py:269
[11:40:54] Committing batch 2 consisting of 18 files                 base.py:269
[11:41:03] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 18 files                 base.py:269
[11:41:06] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-24-11-34">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 11:34:32.591579</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 11:34:42.676424</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:34:32] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
[11:34:33] Getting all files in LEW/json...                          base.py:186
           ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 46 files in LEW/raw                              base.py:202
           ...found 92 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[11:34:42] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-24-00-04">2022-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>14 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-24 00:04:25.978708</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-24 00:04:40.073603</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[00:04:25] Fetching Scraper for: LEW                              handlers.py:22
[00:04:26] Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
[00:04:27] ...found 55 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 55 files in LEW/raw                              base.py:202
           ...found 111 files in LEW                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[00:04:29] Deleting batch no. 2 consisting of 11 files               base.py:211
[00:04:34] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[00:04:37] Committing batch 1 consisting of 92 files                 base.py:269
[00:04:38] Committing batch 2 consisting of 18 files                 base.py:269
[00:04:40] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-22-12-05">2022-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-22 12:05:09.878652</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-22 12:05:20.046089</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:05:09] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[12:05:10] Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
           ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 46 files in LEW/raw                              base.py:202
           ...found 92 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 92 files               base.py:211
[12:05:13] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[12:05:17] Committing batch 1 consisting of 92 files                 base.py:269
[12:05:18] Committing batch 2 consisting of 18 files                 base.py:269
[12:05:20] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-21-12-11">2022-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-21 12:11:55.600890</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-21 12:12:07.098745</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:11:55] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
[12:11:56] Getting all files in LEW/raw...                           base.py:186
           ...found 11 files in LEW/raw                              base.py:202
           ...found 12 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 12 files               base.py:211
[12:12:06] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
[12:12:07] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-20-11-17">2022-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>11 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-20 11:17:05.866274</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-20 11:17:17.612278</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:17:05] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:17:06] Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
[11:17:07] ...found 55 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 55 files in LEW/raw                              base.py:202
           ...found 111 files in LEW                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:17:09] Deleting batch no. 2 consisting of 11 files               base.py:211
[11:17:10] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:17:14] Committing batch 1 consisting of 92 files                 base.py:269
[11:17:15] Committing batch 2 consisting of 18 files                 base.py:269
[11:17:17] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-19-11-28">2022-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>21 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-19 11:28:26.402462</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-19 11:28:48.373695</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:28:26] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[11:28:27] Getting all files in LEW...                               base.py:186
           Getting all files in LEW/raw...                           base.py:186
           ...found 11 files in LEW/raw                              base.py:202
           ...found 12 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 12 files               base.py:211
[11:28:29] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:28:32] Committing batch 1 consisting of 92 files                 base.py:269
[11:28:34] Committing batch 2 consisting of 18 files                 base.py:269
[11:28:45] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Committing batch 2 consisting of 18 files                 base.py:269
[11:28:48] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-18-12-08">2022-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-18 12:08:58.378453</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-18 12:09:06.539864</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:08:58] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
[12:08:59] ...found 55 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 55 files in LEW/raw                              base.py:202
           ...found 111 files in LEW                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[12:09:03] Deleting batch no. 2 consisting of 11 files               base.py:211
[12:09:06] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-17-11-15">2022-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-17 11:15:07.509477</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-17 11:15:18.447949</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:15:07] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
[11:15:08] ...found 55 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 55 files in LEW/raw                              base.py:202
           ...found 111 files in LEW                                 base.py:202
           Deleting batch no. 1 consisting of 100 files              base.py:211
[11:15:09] Deleting batch no. 2 consisting of 11 files               base.py:211
[11:15:10] ...data deleted.                                          base.py:241
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:15:14] Committing batch 1 consisting of 92 files                 base.py:269
[11:15:16] Committing batch 2 consisting of 18 files                 base.py:269
[11:15:18] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-16-11-39">2022-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-16 11:39:42.302274</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-16 11:39:51.791695</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>200</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[11:39:42] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
           Getting all files in LEW...                               base.py:186
           LEW Does not exist                                        base.py:206
           ...no data to delete.                                     base.py:238
           Scraping from http://councilmeetings.lewisham.gov.uk/mgWeb base.py:40
           Service.asmx/GetCouncillorsByWard                                    
[11:39:46] Committing batch 1 consisting of 92 files                 base.py:269
[11:39:47] Committing batch 2 consisting of 18 files                 base.py:269
[11:39:51] Finished attempting to scrape: LEW                        base.py:319
</pre>

  <h2 id="2022-03-15-12-02">2022-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2022-03-15 12:02:28.689669</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2022-03-15 12:02:42.622021</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd></dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>An error occurred (ThrottlingException) when calling the CreateCommit operation (reached max retries: 4): Rate exceeded</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:02:28] Fetching Scraper for: LEW                              handlers.py:22
           Begin attempting to scrape: LEW                        handlers.py:25
           Deleting existing data...                                 base.py:234
[12:02:29] Getting all files in LEW...                               base.py:186
           Getting all files in LEW/json...                          base.py:186
           ...found 46 files in LEW/json                             base.py:202
           Getting all files in LEW/raw...                           base.py:186
           ...found 46 files in LEW/raw                              base.py:202
           ...found 93 files in LEW                                  base.py:202
           Deleting batch no. 1 consisting of 93 files               base.py:211
[12:02:42] An error occurred (ThrottlingException) when calling   handlers.py:34
           the CreateCommit operation (reached max retries: 4):                 
           Rate exceeded                                                        
           Finished attempting to scrape: LEW                        base.py:319
</pre>


      </main>
      <footer class="ds-footer">...</footer>
    </div>
  </body>
