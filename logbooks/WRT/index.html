<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2025-03-24-09-41">2025-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-24 09:41:04.660193</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-24 09:41:08.793840</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:41:04] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:41:05] Deleting existing data...                                 base.py:257
[09:41:07] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:41:08] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-23-09-14">2025-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-23 09:14:51.601483</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-23 09:14:53.966786</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:14:51] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:14:52] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:14:53] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-22-09-29">2025-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-22 09:29:15.728672</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-22 09:29:17.940649</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:29:15] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:29:16] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:29:17] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-21-09-11">2025-03-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-21 09:11:09.933659</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-21 09:11:12.198682</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:11:09] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:11:10] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:11:11] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[09:11:12] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-20-09-18">2025-03-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-20 09:18:10.856487</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-20 09:18:12.987002</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:18:10] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:18:11] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:18:12] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-19-10-11">2025-03-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-19 10:11:34.018083</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-19 10:11:36.589995</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:11:34] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:11:35] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:11:36] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-18-10-19">2025-03-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-18 10:19:04.595752</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-18 10:19:07.010539</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:19:04] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:19:05] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:19:06] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[10:19:07] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-17-08-34">2025-03-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-17 08:34:35.739695</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-17 08:34:38.256329</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:34:35] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[08:34:36] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[08:34:37] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[08:34:38] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-16-09-53">2025-03-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-16 09:53:12.164606</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-16 09:53:14.310484</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:53:12] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:53:13] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:53:14] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-15-10-34">2025-03-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-15 10:34:03.898537</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-15 10:34:06.331022</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:34:03] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:34:04] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:34:05] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
[10:34:06] Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-14-10-20">2025-03-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-14 10:20:52.884098</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-14 10:20:55.153301</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:20:52] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:20:53] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:20:54] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[10:20:55] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-13-09-38">2025-03-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-13 09:38:13.167896</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-13 09:38:15.494759</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:38:13] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:38:14] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:38:15] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-12-09-10">2025-03-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-12 09:10:43.542332</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-12 09:10:45.819543</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:43] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:10:44] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:10:45] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-11-08-39">2025-03-11</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-11 08:39:28.474161</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-11 08:39:30.751152</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:39:28] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:39:29] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:39:30] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-10-10-19">2025-03-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-10 10:19:05.049204</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-10 10:19:07.159474</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:19:05] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:19:06] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[10:19:07] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-09-08-41">2025-03-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-09 08:41:57.928795</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-09 08:42:00.144712</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:41:57] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[08:41:58] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[08:41:59] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[08:42:00] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-08-08-23">2025-03-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-08 08:23:35.526045</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-08 08:23:38.037361</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:23:35] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[08:23:36] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:23:37] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[08:23:38] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-07-10-02">2025-03-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-07 10:02:48.697986</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-07 10:02:50.758315</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:02:48] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:02:49] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:02:50] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-06-09-04">2025-03-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-06 09:04:26.478212</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-06 09:04:28.718994</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:04:26] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:04:27] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:04:28] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-05-09-15">2025-03-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-05 09:15:06.549359</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-05 09:15:08.839634</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:15:06] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:15:07] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:15:08] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
