<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2025-04-10-09-49">2025-04-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-10 09:49:22.423318</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-10 09:49:24.698075</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:49:22] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:49:23] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:49:24] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-09-09-27">2025-04-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-09 09:27:20.802667</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-09 09:27:23.332648</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:27:20] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:27:21] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[09:27:22] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
[09:27:23] Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-08-09-40">2025-04-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-08 09:40:38.827323</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-08 09:40:41.230078</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:40:38] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:40:39] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:40:40] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[09:40:41] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-07-09-34">2025-04-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-07 09:34:27.362822</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-07 09:34:29.980642</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:34:27] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:34:28] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:34:29] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-06-08-39">2025-04-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-06 08:39:32.782169</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-06 08:39:35.026926</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:39:32] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[08:39:33] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:39:34] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[08:39:35] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-05-09-49">2025-04-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-05 09:49:32.431482</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-05 09:49:34.706685</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:49:32] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:49:33] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:49:34] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-04-10-02">2025-04-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-04 10:02:39.035644</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-04 10:02:41.496631</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:02:39] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[10:02:40] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:02:41] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-03-09-01">2025-04-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-03 09:01:18.166753</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-03 09:01:20.767437</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:01:18] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:01:19] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:01:20] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-02-08-27">2025-04-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-02 08:27:40.048216</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-02 08:27:42.181560</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:27:40] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[08:27:41] ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[08:27:42] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-04-01-10-42">2025-04-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-04-01 10:42:33.819154</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-04-01 10:42:35.913370</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:42:33] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:42:34] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:42:35] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-31-10-14">2025-03-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-31 10:14:47.349145</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-31 10:14:49.890433</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:14:47] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:14:48] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:14:49] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-30-08-35">2025-03-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-30 08:35:06.440669</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-30 08:35:08.682649</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:35:06] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[08:35:07] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:35:08] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-29-10-06">2025-03-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-29 10:06:47.859364</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-29 10:06:50.127185</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:06:47] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[10:06:48] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:06:49] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
[10:06:50] Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-28-10-17">2025-03-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-28 10:17:35.079006</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-28 10:17:37.518196</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:17:35] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:17:36] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:17:37] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-27-08-47">2025-03-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-27 08:47:33.631869</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-27 08:47:37.473535</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:47:33] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[08:47:34] Deleting existing data...                                 base.py:257
[08:47:36] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[08:47:37] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-26-09-57">2025-03-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-26 09:57:14.663147</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-26 09:57:16.982674</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:57:14] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:57:15] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:57:16] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-25-09-22">2025-03-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-25 09:22:29.350403</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-25 09:22:31.582170</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:22:29] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
           Deleting existing data...                                 base.py:257
[09:22:30] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:22:31] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-24-09-41">2025-03-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-24 09:41:04.660193</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-24 09:41:08.793840</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:41:04] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:41:05] Deleting existing data...                                 base.py:257
[09:41:07] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:41:08] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-23-09-14">2025-03-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-23 09:14:51.601483</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-23 09:14:53.966786</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:14:51] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:14:52] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:14:53] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  

  


  <h2 id="2025-03-22-09-29">2025-03-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-03-22 09:29:15.728672</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-03-22 09:29:17.940649</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 55, in run
    for councillor_html in self.get_councillors():
  File "/var/task/lgsf/councillors/scrapers.py", line 161, in get_councillors
    container = self.get_list_container()
  File "/var/task/lgsf/councillors/scrapers.py", line 152, in get_list_container
    self.base_url_soup = self.get_page(self.base_url)
  File "/var/task/lgsf/councillors/scrapers.py", line 141, in get_page
    page = self.get(url, extra_headers=self.extra_headers).text
  File "/var/task/lgsf/scrapers/base.py", line 56, in get
    response.raise_for_status()
  File "/opt/python/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://www.warrington.gov.uk/councillors'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:29:15] Fetching Scraper for: WRT                              handlers.py:23
           Begin attempting to scrape: WRT                        handlers.py:27
[09:29:16] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:29:17] ...data deleted.                                          base.py:264
           Scraping from https://www.warrington.gov.uk/councillors    base.py:49
           Client error '403 Forbidden' for url                   handlers.py:36
           'https://www.warrington.gov.uk/councillors'                          
           For more information check:                                          
           https://developer.mozilla.org/en-US/docs/Web/HTTP/Stat               
           us/403                                                               
           Finished attempting to scrape: WRT                        base.py:345
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright © 2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
