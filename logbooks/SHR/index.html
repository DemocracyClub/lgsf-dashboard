<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2023-08-21-14-53">2023-08-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-21 14:53:00.255057</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-21 14:53:09.963365</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:53:00] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:53:01] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:53:02] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:53:03] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:53:07] Committing batch 1 consisting of 92 files                 base.py:274
[14:53:08] Committing batch 2 consisting of 56 files                 base.py:274
[14:53:09] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-08-14-14-52">2023-08-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-14 14:52:32.343455</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-14 14:52:40.138015</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:52:32] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:52:33] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[14:52:34] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:52:37] Committing batch 1 consisting of 92 files                 base.py:274
[14:52:38] Committing batch 2 consisting of 56 files                 base.py:274
[14:52:40] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-08-07-15-23">2023-08-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-07 15:23:41.825956</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-07 15:23:44.115956</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:23:41] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:23:42] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[15:23:43] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
[15:23:44] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-31-15-09">2023-07-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-31 15:09:52.850402</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-31 15:09:54.892506</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:09:52] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:09:53] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[15:09:54] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-24-15-08">2023-07-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-24 15:08:37.893142</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-24 15:08:40.375639</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:08:37] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:08:38] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[15:08:39] ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
           ...data deleted.                                          base.py:246
[15:08:40] Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-17-14-48">2023-07-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-17 14:48:12.284908</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-17 14:48:14.386073</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:48:12] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:48:13] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:48:14] HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-10-13-16">2023-07-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-10 13:16:06.987322</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-10 13:16:09.372152</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:16:06] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[13:16:07] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[13:16:08] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
[13:16:09] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-03-15-23">2023-07-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-03 15:23:35.957574</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-03 15:23:39.307961</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:23:35] Fetching Scraper for: SHR                              handlers.py:23
[15:23:36] Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[15:23:37] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:23:38] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:23:39] HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-26-13-55">2023-06-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-26 13:55:14.355580</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-26 13:55:23.376110</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:55:14] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[13:55:15] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[13:55:16] Deleting batch no. 2 consisting of 49 files               base.py:216
[13:55:17] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[13:55:20] Committing batch 1 consisting of 92 files                 base.py:274
[13:55:22] Committing batch 2 consisting of 56 files                 base.py:274
[13:55:23] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-19-15-19">2023-06-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-19 15:19:46.341827</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-19 15:19:57.244862</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:19:46] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[15:19:47] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:19:48] Deleting batch no. 2 consisting of 49 files               base.py:216
[15:19:49] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:19:54] Committing batch 1 consisting of 92 files                 base.py:274
[15:19:55] Committing batch 2 consisting of 56 files                 base.py:274
[15:19:57] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-12-14-41">2023-06-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-12 14:41:20.941556</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-12 14:41:31.739622</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:41:20] Fetching Scraper for: SHR                              handlers.py:23
[14:41:21] Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[14:41:22] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:41:23] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:41:24] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:41:29] Committing batch 1 consisting of 92 files                 base.py:274
[14:41:30] Committing batch 2 consisting of 56 files                 base.py:274
[14:41:31] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-05-15-32">2023-06-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-05 15:32:00.625782</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-05 15:32:11.036830</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:32:00] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[15:32:01] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[15:32:02] ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:32:03] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:32:08] Committing batch 1 consisting of 92 files                 base.py:274
[15:32:09] Committing batch 2 consisting of 56 files                 base.py:274
[15:32:11] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-05-29-14-41">2023-05-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-05-29 14:41:16.686147</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-05-29 14:41:25.234516</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:41:16] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[14:41:17] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:41:18] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:41:19] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:41:22] Committing batch 1 consisting of 92 files                 base.py:274
[14:41:24] Committing batch 2 consisting of 56 files                 base.py:274
[14:41:25] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-05-22-15-39">2023-05-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-05-22 15:39:36.452381</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-05-22 15:39:45.552885</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:39:36] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[15:39:37] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:39:38] Deleting batch no. 2 consisting of 49 files               base.py:216
[15:39:39] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:39:42] Committing batch 1 consisting of 92 files                 base.py:274
[15:39:44] Committing batch 2 consisting of 56 files                 base.py:274
[15:39:45] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-05-15-15-04">2023-05-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-05-15 15:04:29.945433</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-05-15 15:04:38.904369</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:04:29] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:04:30] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[15:04:31] Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:04:32] Deleting batch no. 2 consisting of 49 files               base.py:216
[15:04:33] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:04:36] Committing batch 1 consisting of 92 files                 base.py:274
[15:04:37] Committing batch 2 consisting of 56 files                 base.py:274
[15:04:38] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-05-08-14-37">2023-05-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-05-08 14:37:18.915454</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-05-08 14:37:27.636478</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:37:18] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[14:37:19] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[14:37:20] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:37:21] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:37:25] Committing batch 1 consisting of 92 files                 base.py:274
[14:37:26] Committing batch 2 consisting of 56 files                 base.py:274
[14:37:27] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-05-01-13-38">2023-05-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-05-01 13:38:39.635523</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-05-01 13:38:49.073471</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:38:39] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[13:38:40] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[13:38:41] ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
           Deleting batch no. 2 consisting of 49 files               base.py:216
[13:38:42] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[13:38:46] Committing batch 1 consisting of 92 files                 base.py:274
[13:38:47] Committing batch 2 consisting of 56 files                 base.py:274
[13:38:49] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-04-24-14-57">2023-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-04-24 14:57:45.095559</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-04-24 14:57:54.233352</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:57:45] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[14:57:46] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:57:47] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:57:51] Committing batch 1 consisting of 92 files                 base.py:274
[14:57:52] Committing batch 2 consisting of 56 files                 base.py:274
[14:57:54] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-04-17-14-32">2023-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-04-17 14:32:08.678358</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-04-17 14:32:17.947648</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:32:08] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[14:32:09] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[14:32:10] ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:32:11] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:32:15] Committing batch 1 consisting of 92 files                 base.py:274
[14:32:16] Committing batch 2 consisting of 56 files                 base.py:274
[14:32:17] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-04-10-15-16">2023-04-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-04-10 15:16:42.932231</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-04-10 15:16:53.354965</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:16:42] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:16:43] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[15:16:44] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:16:45] Deleting batch no. 2 consisting of 49 files               base.py:216
[15:16:46] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:16:50] Committing batch 1 consisting of 92 files                 base.py:274
[15:16:52] Committing batch 2 consisting of 56 files                 base.py:274
[15:16:53] Finished attempting to scrape: SHR                        base.py:324
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
