<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2023-09-09-12-14">2023-09-09</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-09-09 12:14:28.699114</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-09-09 12:14:38.034000</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:14:28] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[12:14:29] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[12:14:30] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[12:14:31] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[12:14:35] Committing batch 1 consisting of 92 files                 base.py:274
[12:14:36] Committing batch 2 consisting of 56 files                 base.py:274
[12:14:38] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-09-08-14-11">2023-09-08</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-09-08 14:11:05.965571</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-09-08 14:11:14.521512</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:11:05] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[14:11:06] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[14:11:07] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:11:08] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:11:11] Committing batch 1 consisting of 92 files                 base.py:274
[14:11:13] Committing batch 2 consisting of 56 files                 base.py:274
[14:11:14] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-09-07-14-06">2023-09-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-09-07 14:06:13.159160</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-09-07 14:06:22.413287</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:06:13] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:06:14] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:06:15] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:06:16] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:06:19] Committing batch 1 consisting of 92 files                 base.py:274
[14:06:21] Committing batch 2 consisting of 56 files                 base.py:274
[14:06:22] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-09-06-12-11">2023-09-06</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-09-06 12:11:32.395025</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-09-06 12:11:41.778689</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:11:32] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[12:11:33] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[12:11:34] Deleting batch no. 2 consisting of 49 files               base.py:216
[12:11:35] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[12:11:38] Committing batch 1 consisting of 92 files                 base.py:274
[12:11:40] Committing batch 2 consisting of 56 files                 base.py:274
[12:11:41] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-09-05-12-42">2023-09-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-09-05 12:42:06.728463</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-09-05 12:42:15.851155</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[12:42:06] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[12:42:07] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[12:42:08] ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
           Deleting batch no. 2 consisting of 49 files               base.py:216
[12:42:09] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[12:42:12] Committing batch 1 consisting of 92 files                 base.py:274
[12:42:14] Committing batch 2 consisting of 56 files                 base.py:274
[12:42:15] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-09-04-13-37">2023-09-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-09-04 13:37:10.253489</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-09-04 13:37:20.218521</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:37:10] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[13:37:11] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[13:37:12] Deleting batch no. 2 consisting of 49 files               base.py:216
[13:37:13] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[13:37:17] Committing batch 1 consisting of 92 files                 base.py:274
[13:37:18] Committing batch 2 consisting of 56 files                 base.py:274
[13:37:20] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-08-28-15-27">2023-08-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-28 15:27:14.834768</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-28 15:27:23.880378</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:27:14] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:27:15] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[15:27:16] ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:27:17] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:27:21] Committing batch 1 consisting of 92 files                 base.py:274
[15:27:22] Committing batch 2 consisting of 56 files                 base.py:274
[15:27:23] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-08-21-14-53">2023-08-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-21 14:53:00.255057</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-21 14:53:09.963365</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:53:00] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:53:01] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:53:02] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:53:03] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:53:07] Committing batch 1 consisting of 92 files                 base.py:274
[14:53:08] Committing batch 2 consisting of 56 files                 base.py:274
[14:53:09] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-08-14-14-52">2023-08-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-14 14:52:32.343455</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-14 14:52:40.138015</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:52:32] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:52:33] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[14:52:34] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:52:37] Committing batch 1 consisting of 92 files                 base.py:274
[14:52:38] Committing batch 2 consisting of 56 files                 base.py:274
[14:52:40] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-08-07-15-23">2023-08-07</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-08-07 15:23:41.825956</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-08-07 15:23:44.115956</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:23:41] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:23:42] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[15:23:43] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
[15:23:44] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-31-15-09">2023-07-31</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-31 15:09:52.850402</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-31 15:09:54.892506</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:09:52] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:09:53] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[15:09:54] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-24-15-08">2023-07-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-24 15:08:37.893142</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-24 15:08:40.375639</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:08:37] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[15:08:38] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
[15:08:39] ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
           ...data deleted.                                          base.py:246
[15:08:40] Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-17-14-48">2023-07-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-17 14:48:12.284908</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-17 14:48:14.386073</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:48:12] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[14:48:13] Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:48:14] HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-10-13-16">2023-07-10</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-10 13:16:06.987322</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-10 13:16:09.372152</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:16:06] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[13:16:07] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           ...found 1 files in Councillors                           base.py:207
           Deleting batch no. 1 consisting of 1 files                base.py:216
[13:16:08] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
           HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
[13:16:09] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-07-03-15-23">2023-07-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>3 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-07-03 15:23:35.957574</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-07-03 15:23:39.307961</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/opt/python/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 179, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 196, in get_councillors
    req = self.get(self.format_councillor_api_url(), verify=self.verify_requests)
  File "/var/task/lgsf/scrapers/base.py", line 48, in get
    response = self.requests_session.get(url, headers=headers, verify=verify)
  File "/opt/python/requests/sessions.py", line 600, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='shropshire.gov.uk', port=443): Max retries exceeded with url: /committee-services//mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:23:35] Fetching Scraper for: SHR                              handlers.py:23
[15:23:36] Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[15:23:37] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:23:38] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:23:39] HTTPSConnectionPool(host='shropshire.gov.uk',          handlers.py:36
           port=443): Max retries exceeded with url:                            
           /committee-services//mgWebService.asmx/GetCouncillorsB               
           yWard (Caused by SSLError(SSLCertVerificationError(1,                
           '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify                 
           failed: unable to get local issuer certificate                       
           (_ssl.c:1131)')))                                                    
           Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-26-13-55">2023-06-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>9 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-26 13:55:14.355580</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-26 13:55:23.376110</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[13:55:14] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[13:55:15] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[13:55:16] Deleting batch no. 2 consisting of 49 files               base.py:216
[13:55:17] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[13:55:20] Committing batch 1 consisting of 92 files                 base.py:274
[13:55:22] Committing batch 2 consisting of 56 files                 base.py:274
[13:55:23] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-19-15-19">2023-06-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-19 15:19:46.341827</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-19 15:19:57.244862</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:19:46] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[15:19:47] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:19:48] Deleting batch no. 2 consisting of 49 files               base.py:216
[15:19:49] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:19:54] Committing batch 1 consisting of 92 files                 base.py:274
[15:19:55] Committing batch 2 consisting of 56 files                 base.py:274
[15:19:57] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-12-14-41">2023-06-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-12 14:41:20.941556</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-12 14:41:31.739622</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:41:20] Fetching Scraper for: SHR                              handlers.py:23
[14:41:21] Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
[14:41:22] ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:41:23] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:41:24] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:41:29] Committing batch 1 consisting of 92 files                 base.py:274
[14:41:30] Committing batch 2 consisting of 56 files                 base.py:274
[14:41:31] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-06-05-15-32">2023-06-05</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>10 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-06-05 15:32:00.625782</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-06-05 15:32:11.036830</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:32:00] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
           Deleting existing data...                                 base.py:239
[15:32:01] Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
[15:32:02] ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[15:32:03] Deleting batch no. 2 consisting of 49 files               base.py:216
           ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[15:32:08] Committing batch 1 consisting of 92 files                 base.py:274
[15:32:09] Committing batch 2 consisting of 56 files                 base.py:274
[15:32:11] Finished attempting to scrape: SHR                        base.py:324
</pre>
  

  


  <h2 id="2023-05-29-14-41">2023-05-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2023-05-29 14:41:16.686147</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2023-05-29 14:41:25.234516</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[14:41:16] Fetching Scraper for: SHR                              handlers.py:23
           Begin attempting to scrape: SHR                        handlers.py:27
[14:41:17] Deleting existing data...                                 base.py:239
           Getting all files in Councillors...                       base.py:191
           Getting all files in Councillors/json...                  base.py:191
           ...found 74 files in Councillors/json                     base.py:207
           Getting all files in Councillors/raw...                   base.py:191
           ...found 74 files in Councillors/raw                      base.py:207
           ...found 149 files in Councillors                         base.py:207
           Deleting batch no. 1 consisting of 100 files              base.py:216
[14:41:18] Deleting batch no. 2 consisting of 49 files               base.py:216
[14:41:19] ...data deleted.                                          base.py:246
           Scraping from                                              base.py:42
           https://shropshire.gov.uk/committee-services//mgWebService           
           .asmx/GetCouncillorsByWard                                           
[14:41:22] Committing batch 1 consisting of 92 files                 base.py:274
[14:41:24] Committing batch 2 consisting of 56 files                 base.py:274
[14:41:25] Finished attempting to scrape: SHR                        base.py:324
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
