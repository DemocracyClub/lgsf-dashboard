<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2024-04-28-08-18">2024-04-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-28 08:18:54.117388</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-28 08:19:01.200070</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:18:54] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
[08:18:55] Getting all files in Councillors/json...                  base.py:209
           ...found 48 files in Councillors/json                     base.py:225
           Getting all files in Councillors/raw...                   base.py:209
           ...found 48 files in Councillors/raw                      base.py:225
           ...found 97 files in Councillors                          base.py:225
           Deleting batch no. 1 consisting of 97 files               base.py:236
[08:18:56] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:18:59] Committing batch 1 consisting of 92 files                 base.py:297
           Committing batch 2 consisting of 4 files                  base.py:297
[08:19:01] Finished attempting to scrape: WAE                        base.py:345
</pre>
  

  


  <h2 id="2024-04-27-16-03">2024-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>17 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-27 16:03:54.835379</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-27 16:04:12.538610</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[16:03:54] Fetching Scraper for: WAE                              handlers.py:23
[16:04:04] Begin attempting to scrape: WAE                        handlers.py:27
[16:04:06] Deleting existing data...                                 base.py:257
[16:04:07] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[16:04:10] Committing batch 1 consisting of 92 files                 base.py:297
[16:04:11] Committing batch 2 consisting of 4 files                  base.py:297
[16:04:12] Finished attempting to scrape: WAE                        base.py:345
</pre>
  

  


  <h2 id="2024-04-27-09-13">2024-04-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-27 09:13:41.843462</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-27 09:13:43.980352</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 154, in _connect
    stream = stream.start_tls(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 197, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 216, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers, timeout=30)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:13:41] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[09:13:42] Deleting existing data...                                 base.py:257
           Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[09:13:43] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)                                                        
           Finished attempting to scrape: WAE                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-16-00">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>1 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 16:00:41.240064</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 16:00:43.206915</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 154, in _connect
    stream = stream.start_tls(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 199, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 218, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[16:00:41] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:257
[16:00:42] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
           ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[16:00:43] [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)                                                        
           Finished attempting to scrape: WAE                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-10-55">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 10:55:08.232719</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 10:55:10.351898</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/opt/python/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/opt/python/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/opt/python/httpcore/_sync/connection.py", line 154, in _connect
    stream = stream.start_tls(**kwargs)
  File "/opt/python/httpcore/_backends/sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 199, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 218, in get_councillors
    req = self.get(self.format_councillor_api_url())
  File "/var/task/lgsf/scrapers/base.py", line 55, in get
    response = self.http_client.get(url, headers=headers)
  File "/opt/python/httpx/_client.py", line 1054, in get
    return self.request(
  File "/opt/python/httpx/_client.py", line 827, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/opt/python/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/opt/python/httpx/_transports/default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "/var/lang/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/python/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:55:08] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:257
[10:55:09] Getting all files in Councillors...                       base.py:209
           ...found 1 files in Councillors                           base.py:225
           Deleting batch no. 1 consisting of 1 files                base.py:236
[10:55:10] ...data deleted.                                          base.py:264
           Scraping from                                              base.py:49
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
           [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify    handlers.py:36
           failed: unable to get local issuer certificate                       
           (_ssl.c:1007)                                                        
           Finished attempting to scrape: WAE                        base.py:345
</pre>
  

  


  <h2 id="2024-04-26-08-18">2024-04-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-26 08:18:28.523068</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-26 08:18:30.656568</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='modgov.waverley.gov.uk', port=443): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='modgov.waverley.gov.uk', port=443): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:18:28] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:18:29] Getting all files in Councillors...                       base.py:203
           ...found 1 files in Councillors                           base.py:219
           Deleting batch no. 1 consisting of 1 files                base.py:230
[08:18:30] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
           HTTPSConnectionPool(host='modgov.waverley.gov.uk',     handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           SSLError(SSLCertVerificationError(1, '[SSL:                          
           CERTIFICATE_VERIFY_FAILED] certificate verify failed:                
           unable to get local issuer certificate                               
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-25-09-26">2024-04-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>2 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-25 09:26:28.860701</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-25 09:26:31.251996</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 468, in _make_request
    self._validate_conn(conn)
  File "/opt/python/urllib3/connectionpool.py", line 1097, in _validate_conn
    conn.connect()
  File "/opt/python/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/opt/python/urllib3/connection.py", line 783, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/opt/python/urllib3/util/ssl_.py", line 471, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/opt/python/urllib3/util/ssl_.py", line 515, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/var/lang/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/var/lang/lib/python3.10/ssl.py", line 1104, in _create
    self.do_handshake()
  File "/var/lang/lib/python3.10/ssl.py", line 1375, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/python/urllib3/connectionpool.py", line 791, in urlopen
    response = self._make_request(
  File "/opt/python/urllib3/connectionpool.py", line 492, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/python/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/opt/python/urllib3/connectionpool.py", line 845, in urlopen
    retries = retries.increment(
  File "/opt/python/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='modgov.waverley.gov.uk', port=443): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 200, in run
    wards = self.get_councillors()
  File "/var/task/lgsf/councillors/scrapers.py", line 219, in get_councillors
    req = self.get(
  File "/var/task/lgsf/scrapers/base.py", line 47, in get
    response = self.requests_session.get(
  File "/opt/python/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/opt/python/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/python/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/opt/python/requests/adapters.py", line 517, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='modgov.waverley.gov.uk', port=443): Max retries exceeded with url: /mgWebService.asmx/GetCouncillorsByWard (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:26:28] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[09:26:29] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[09:26:30] ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:26:31] HTTPSConnectionPool(host='modgov.waverley.gov.uk',     handlers.py:36
           port=443): Max retries exceeded with url:                            
           /mgWebService.asmx/GetCouncillorsByWard (Caused by                   
           SSLError(SSLCertVerificationError(1, '[SSL:                          
           CERTIFICATE_VERIFY_FAILED] certificate verify failed:                
           unable to get local issuer certificate                               
           (_ssl.c:1007)')))                                                    
           Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-24-10-33">2024-04-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-24 10:33:44.746156</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-24 10:33:51.679386</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:33:44] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[10:33:45] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[10:33:46] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[10:33:49] Committing batch 1 consisting of 92 files                 base.py:291
[10:33:50] Committing batch 2 consisting of 4 files                  base.py:291
[10:33:51] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-23-08-41">2024-04-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-23 08:41:47.790078</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-23 08:41:54.459653</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:41:47] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[08:41:48] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[08:41:49] ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[08:41:50] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:41:52] Committing batch 1 consisting of 92 files                 base.py:291
[08:41:53] Committing batch 2 consisting of 4 files                  base.py:291
[08:41:54] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-22-09-41">2024-04-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-22 09:41:12.175566</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-22 09:41:19.521323</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:41:12] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:41:13] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[09:41:14] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:41:17] Committing batch 1 consisting of 92 files                 base.py:291
[09:41:18] Committing batch 2 consisting of 4 files                  base.py:291
[09:41:19] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-21-10-24">2024-04-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-21 10:24:00.042733</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-21 10:24:06.769980</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:24:00] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
[10:24:01] Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[10:24:02] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[10:24:04] Committing batch 1 consisting of 92 files                 base.py:291
[10:24:05] Committing batch 2 consisting of 4 files                  base.py:291
[10:24:06] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-20-09-22">2024-04-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-20 09:22:19.926763</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-20 09:22:26.585269</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:22:19] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[09:22:20] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[09:22:21] ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[09:22:22] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:22:24] Committing batch 1 consisting of 92 files                 base.py:291
[09:22:25] Committing batch 2 consisting of 4 files                  base.py:291
[09:22:26] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-19-10-38">2024-04-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-19 10:38:02.939403</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-19 10:38:09.952426</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:38:02] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[10:38:03] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[10:38:04] ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[10:38:07] Committing batch 1 consisting of 92 files                 base.py:291
[10:38:08] Committing batch 2 consisting of 4 files                  base.py:291
[10:38:09] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-18-10-54">2024-04-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-18 10:54:51.289767</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-18 10:54:58.087908</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[10:54:51] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[10:54:52] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[10:54:53] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[10:54:56] Committing batch 1 consisting of 92 files                 base.py:291
[10:54:57] Committing batch 2 consisting of 4 files                  base.py:291
[10:54:58] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-17-08-29">2024-04-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-17 08:29:17.620750</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-17 08:29:26.117294</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:29:17] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:29:18] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[08:29:19] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:29:23] Committing batch 1 consisting of 92 files                 base.py:291
[08:29:25] Committing batch 2 consisting of 4 files                  base.py:291
[08:29:26] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-16-08-24">2024-04-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>7 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-16 08:24:04.755048</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-16 08:24:12.119037</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:24:04] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[08:24:05] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[08:24:06] ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:24:10] Committing batch 1 consisting of 92 files                 base.py:291
[08:24:11] Committing batch 2 consisting of 4 files                  base.py:291
[08:24:12] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-15-09-12">2024-04-15</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-15 09:12:13.696921</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-15 09:12:20.497122</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:12:13] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
[09:12:14] Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[09:12:15] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:12:18] Committing batch 1 consisting of 92 files                 base.py:291
[09:12:19] Committing batch 2 consisting of 4 files                  base.py:291
[09:12:20] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-14-08-57">2024-04-14</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-14 08:57:12.003283</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-14 08:57:18.948844</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:57:12] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
           Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
[08:57:13] ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[08:57:14] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:57:17] Committing batch 1 consisting of 92 files                 base.py:291
           Committing batch 2 consisting of 4 files                  base.py:291
[08:57:18] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-13-09-16">2024-04-13</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-13 09:16:59.646561</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-13 09:17:06.413906</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:16:59] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[09:17:00] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
[09:17:01] ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
           ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:17:04] Committing batch 1 consisting of 92 files                 base.py:291
[09:17:05] Committing batch 2 consisting of 4 files                  base.py:291
[09:17:06] Finished attempting to scrape: WAE                        base.py:339
</pre>
  

  


  <h2 id="2024-04-12-08-23">2024-04-12</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2024-04-12 08:23:21.538023</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2024-04-12 08:23:27.892747</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:23:21] Fetching Scraper for: WAE                              handlers.py:23
           Begin attempting to scrape: WAE                        handlers.py:27
           Deleting existing data...                                 base.py:251
[08:23:22] Getting all files in Councillors...                       base.py:203
           Getting all files in Councillors/json...                  base.py:203
           ...found 48 files in Councillors/json                     base.py:219
           Getting all files in Councillors/raw...                   base.py:203
           ...found 48 files in Councillors/raw                      base.py:219
           ...found 97 files in Councillors                          base.py:219
           Deleting batch no. 1 consisting of 97 files               base.py:230
[08:23:23] ...data deleted.                                          base.py:258
           Scraping from                                              base.py:41
           https://modgov.waverley.gov.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:23:26] Committing batch 1 consisting of 92 files                 base.py:291
[08:23:27] Committing batch 2 consisting of 4 files                  base.py:291
           Finished attempting to scrape: WAE                        base.py:339
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
