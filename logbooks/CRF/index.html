<!doctype html>
<html>
  <head>
    <title>LGSF Dashboard</title>
    <link rel="stylesheet"  href="/lgsf-dashboard/assets/css/styles.css">
    <link rel="shortcut icon" href="https://democracyclub.org.uk/static/images/logo_icon.png">
  </head>
  <body>
    <div class="ds-page">
      <a class="ds-skip-link" href="#main">skip to content</a>

      <header class="ds-header">
        <a class="ds-skip-link" href="#main">skip to content</a>
        <a class="ds-logo" href="/lgsf-dashboard/">
          <img src="https://DemocracyClub.github.io/design-system/images/logo_icon.svg" alt="" />
          <span>LGSF Logbooks</span>
        </a>

      </header>


      <main id="main" tabindex="-1" class="ds-stack">

        
<style>

    pre {
        height:400px;
        overflow-x: scroll;
        width:100%
    }
</style>




  


  <h2 id="2025-10-04-15-18">2025-10-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>13 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-04 15:18:56.983064</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-04 15:19:10.305104</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[15:18:56] Fetching Scraper for: CRF                              handlers.py:23
[15:18:57] Begin attempting to scrape: CRF                        handlers.py:27
[15:19:03] Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
</pre>
  

  


  <h2 id="2025-10-04-08-37">2025-10-04</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>8 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-04 08:37:35.253260</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-04 08:37:43.570351</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>0</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd></dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:37:35] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
</pre>
  

  


  <h2 id="2025-10-03-08-32">2025-10-03</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-03 08:32:11.540007</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-03 08:32:16.734579</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:32:11] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[08:32:12] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
[08:32:13] Deleting batch no. 1 consisting of 1 files                base.py:242
[08:32:14] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:32:16] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-10-02-08-28">2025-10-02</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-02 08:28:47.965213</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-02 08:28:52.536322</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:28:47] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[08:28:48] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:28:49] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:28:50] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:28:52] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-10-01-08-46">2025-10-01</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-10-01 08:46:10.534025</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-10-01 08:46:14.831870</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:46:10] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[08:46:11] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:46:12] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:46:14] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-30-09-10">2025-09-30</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-30 09:10:20.086591</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-30 09:10:24.860483</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:10:20] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[09:10:21] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[09:10:22] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:10:24] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-29-09-06">2025-09-29</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-29 09:06:41.801886</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-29 09:06:46.645413</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:06:41] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[09:06:42] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[09:06:43] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
           ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:06:46] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-28-08-44">2025-09-28</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-28 08:44:25.437540</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-28 08:44:30.809600</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:44:25] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:44:26] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:44:27] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:44:30] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-27-08-22">2025-09-27</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-27 08:22:55.865347</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-27 08:23:01.134407</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:22:55] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[08:22:56] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:22:57] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:22:58] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:23:00] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:23:01] Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-26-08-54">2025-09-26</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-26 08:54:03.288808</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-26 08:54:08.348535</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:54:03] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:54:04] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:54:05] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:54:07] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
[08:54:08] Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-25-08-48">2025-09-25</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-25 08:48:02.048779</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-25 08:48:07.522302</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:48:02] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
[08:48:03] ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:48:04] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:48:07] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-24-08-30">2025-09-24</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-24 08:30:39.048555</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-24 08:30:44.816583</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:30:39] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:30:40] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:30:41] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:30:44] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-23-08-44">2025-09-23</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>4 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-23 08:44:57.645183</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-23 08:45:01.980599</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:44:57] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[08:44:58] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:44:59] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:45:01] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-22-08-21">2025-09-22</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-22 08:21:45.089883</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-22 08:21:51.292926</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:21:45] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:21:46] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:21:47] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:21:51] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-21-08-22">2025-09-21</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-21 08:22:17.133834</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-21 08:22:29.728518</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 224, in get_councillors
    req = self.get(self.format_councillor_api_url(), extra_headers=self.extra_headers)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 57, in get
    response = self.http_client.get(url, headers=headers, timeout=self.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1053, in get
    return self.request(
           ^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:22:17] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:22:18] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:22:19] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:22:29] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-20-08-49">2025-09-20</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-20 08:49:03.551507</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-20 08:49:08.787527</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:49:03] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[08:49:04] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:49:05] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:49:08] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-19-08-28">2025-09-19</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-19 08:28:36.295313</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-19 08:28:41.352484</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:28:36] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:28:37] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:28:38] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:28:41] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-18-09-09">2025-09-18</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>5 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-18 09:09:14.615513</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-18 09:09:19.852263</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[09:09:14] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
[09:09:15] Deleting existing data...                                 base.py:263
           Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[09:09:16] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[09:09:19] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-17-08-39">2025-09-17</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>6 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-17 08:39:24.227639</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-17 08:39:30.333530</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 226, in get_councillors
    soup = BeautifulSoup(req.text, "lxml")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/bs4/__init__.py", line 364, in __init__
    raise FeatureNotFound(
bs4.exceptions.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:39:24] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:39:25] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:39:26] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:39:30] Couldn't find a tree builder with the features you     handlers.py:36
           requested: lxml. Do you need to install a parser                     
           library?                                                             
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  

  


  <h2 id="2025-09-16-08-17">2025-09-16</h2>
  <div class="ds-card">
  <div class="ds-card-body">
    <dl class="ds-descriptions">
      <div>
        <dt>Duration</dt>
        <dd>12 seconds</dd>
      </div>
      <div>
        <dt>Start</dt>
        <dd>2025-09-16 08:17:34.430283</dd>
      </div>
      <div>
        <dt>End</dt>
        <dd>2025-09-16 08:17:46.945323</dd>
      </div>
      <div>
        <dt>Status code</dt>
        <dd>1</dd>
      </div>
      <div>
        <dt>Error</dt>
        <dd>Traceback (most recent call last):
  File "/opt/python/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/opt/python/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/opt/python/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/opt/python/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/task/lgsf/aws_lambda/handlers.py", line 32, in scraper_worker_handler
    scraper.run(run_log)
  File "/var/task/lgsf/councillors/scrapers.py", line 205, in run
    wards = self.get_councillors()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/councillors/scrapers.py", line 224, in get_councillors
    req = self.get(self.format_councillor_api_url(), extra_headers=self.extra_headers)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/lgsf/scrapers/base.py", line 57, in get
    response = self.http_client.get(url, headers=headers, timeout=self.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1053, in get
    return self.request(
           ^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/python/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lang/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/opt/python/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
</dd>
      </div>
    </dl>
  </div>
  </div>

  <h3>Run log</h3>
  <pre>[08:17:34] Fetching Scraper for: CRF                              handlers.py:23
           Begin attempting to scrape: CRF                        handlers.py:27
           Deleting existing data...                                 base.py:263
[08:17:35] Getting all files in Councillors...                       base.py:215
           ...found 1 files in Councillors                           base.py:231
           Deleting batch no. 1 consisting of 1 files                base.py:242
[08:17:36] ...data deleted.                                          base.py:270
           Scraping from                                              base.py:52
           http://cardiff.moderngov.co.uk/mgWebService.asmx/GetCounci           
           llorsByWard                                                          
[08:17:46] The read operation timed out                           handlers.py:36
           Finished attempting to scrape: CRF                        base.py:351
</pre>
  


      </main>
      <footer class="ds-footer">
        <div class="ds-block-centered ds-text-centered ds-stack">
          <div class="ds-cluster-center">
            <ul>
              <li><a href="/lgsf-dashboard/api/failing.json">Failing JSON</a></li>
            </ul>
          </div>
          <div class="ds-copyright">
            <a href="https://democracyclub.org.uk/">
              <img src="https://DemocracyClub.github.io/design-system/images/logo_white_text.svg" alt="Democracy Club Home" />
            </a>
            <p>Copyright  2021 Democracy Club</p>
            <p>Community Interest Company</p>
            <p>Company No: <a href="https://beta.companieshouse.gov.uk/company/09461226">09461226</a></p>
          </div>
        </div>
      </footer>
    </div>
  </body>
